{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "#logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: six in /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages (from bert-tensorflow) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = [\n",
    "    (\"Over the whole area, the average level of damage rose to 30%, but further north it rose to 40% and in the south it was rarely above 15%.\",\"30\",\"damage\"),\n",
    "    (\"Over the whole area, the average level of damage rose to 30%, but further north it rose to 40% and in the south it was rarely above 15%.\",\"40\",\"damage\"),\n",
    "    (\"Over the whole area, the average level of damage rose to 30%, but further north it rose to 40% and in the south it was rarely above 15%.\",\"15\",\"damage\"),\n",
    "    (\"Over the whole area, the average level of damage rose to 30%, but further north it rose to 40% and in the south it was rarely above 15%.\",\"30\",\"whole area\"),\n",
    "    (\"Over the whole area, the average level of damage rose to 30%, but further north it rose to 40% and in the south it was rarely above 15%.\",\"15\",\"average\"),\n",
    "    (\"Productivity was increased by 35 % with plastic bags.\", \"35\", \"plastic bag\"),\n",
    "    (\"30% respondents were asked about jute sacks\", \"30\", \"jute sack\"),\n",
    "    (\"It took us 5 months to get used to plastic bags\", \"5\",\"plastic bag\"),\n",
    "    (\"At 120 days, relative to controls, ACK had reduced the final weevil population density by 76 to 82%, floating seeds by 86 to 98% and damaged sunken seeds by 36 to 53%, but increased undamaged sunken seeds by 358 to 572%.\",\"120\",\"ACK\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0511 18:05:57.129045 140611470010176 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started BERT\n",
      "Started tokenizer loading\n",
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0511 18:05:58.094728 140611470010176 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0511 18:05:59.268776 140611470010176 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from interventions_labeling_lib import measurements_labeler\n",
    "measurements_labeler = reload(measurements_labeler)\n",
    "\n",
    "_measurements_labeler = measurements_labeler.MeasurementsLabeler(\"bert_results_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = _measurements_labeler.prepare_datasets(\"../tmp/measurements_data/train.xlsx\", all_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence', 'Number', 'Word Expression', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started 0 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Training took time  0:12:21.052292\n",
      "[[2848   42]\n",
      " [  45 1654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2890\n",
      "           1       0.98      0.97      0.97      1699\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4589\n",
      "   macro avg       0.98      0.98      0.98      4589\n",
      "weighted avg       0.98      0.98      0.98      4589\n",
      "\n",
      "F1 score:  0.979664992384107\n",
      "[[282  40]\n",
      " [ 35 154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       322\n",
      "           1       0.79      0.81      0.80       189\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       511\n",
      "   macro avg       0.84      0.85      0.84       511\n",
      "weighted avg       0.85      0.85      0.85       511\n",
      "\n",
      "F1 score:  0.8434033268365633\n",
      "Started 1 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:19.974569\n",
      "[[2848   42]\n",
      " [  69 1630]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2890\n",
      "           1       0.97      0.96      0.97      1699\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4589\n",
      "   macro avg       0.98      0.97      0.97      4589\n",
      "weighted avg       0.98      0.98      0.98      4589\n",
      "\n",
      "F1 score:  0.9739786120301928\n",
      "[[291  31]\n",
      " [ 25 164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       322\n",
      "           1       0.84      0.87      0.85       189\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       511\n",
      "   macro avg       0.88      0.89      0.88       511\n",
      "weighted avg       0.89      0.89      0.89       511\n",
      "\n",
      "F1 score:  0.8831961859979103\n",
      "Started 2 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:20.242076\n",
      "[[2852   39]\n",
      " [  50 1649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      2891\n",
      "           1       0.98      0.97      0.97      1699\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4590\n",
      "   macro avg       0.98      0.98      0.98      4590\n",
      "weighted avg       0.98      0.98      0.98      4590\n",
      "\n",
      "F1 score:  0.9791798445850395\n",
      "[[295  26]\n",
      " [ 27 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       321\n",
      "           1       0.86      0.86      0.86       189\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       510\n",
      "   macro avg       0.89      0.89      0.89       510\n",
      "weighted avg       0.90      0.90      0.90       510\n",
      "\n",
      "F1 score:  0.888495159048063\n",
      "Started 3 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:18.021643\n",
      "[[2840   51]\n",
      " [  60 1639]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2891\n",
      "           1       0.97      0.96      0.97      1699\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4590\n",
      "   macro avg       0.97      0.97      0.97      4590\n",
      "weighted avg       0.98      0.98      0.98      4590\n",
      "\n",
      "F1 score:  0.9740396507660696\n",
      "[[291  30]\n",
      " [ 46 143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       321\n",
      "           1       0.83      0.76      0.79       189\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       510\n",
      "   macro avg       0.85      0.83      0.84       510\n",
      "weighted avg       0.85      0.85      0.85       510\n",
      "\n",
      "F1 score:  0.8372768644309728\n",
      "Started 4 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:19.451296\n",
      "[[2838   53]\n",
      " [  94 1605]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2891\n",
      "           1       0.97      0.94      0.96      1699\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4590\n",
      "   macro avg       0.97      0.96      0.97      4590\n",
      "weighted avg       0.97      0.97      0.97      4590\n",
      "\n",
      "F1 score:  0.9654830916873505\n",
      "[[290  31]\n",
      " [ 37 152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       321\n",
      "           1       0.83      0.80      0.82       189\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       510\n",
      "   macro avg       0.86      0.85      0.86       510\n",
      "weighted avg       0.87      0.87      0.87       510\n",
      "\n",
      "F1 score:  0.8561330147351653\n",
      "Started 5 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:19.863690\n",
      "[[2764  127]\n",
      " [ 229 1470]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      2891\n",
      "           1       0.92      0.87      0.89      1699\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      4590\n",
      "   macro avg       0.92      0.91      0.92      4590\n",
      "weighted avg       0.92      0.92      0.92      4590\n",
      "\n",
      "F1 score:  0.9157436160593482\n",
      "[[278  43]\n",
      " [ 61 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       321\n",
      "           1       0.75      0.68      0.71       189\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       510\n",
      "   macro avg       0.78      0.77      0.78       510\n",
      "weighted avg       0.79      0.80      0.79       510\n",
      "\n",
      "F1 score:  0.7767676767676767\n",
      "Started 6 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:18.253408\n",
      "[[2828   63]\n",
      " [ 128 1571]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      2891\n",
      "           1       0.96      0.92      0.94      1699\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4590\n",
      "   macro avg       0.96      0.95      0.96      4590\n",
      "weighted avg       0.96      0.96      0.96      4590\n",
      "\n",
      "F1 score:  0.9550139724080156\n",
      "[[293  28]\n",
      " [ 59 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       321\n",
      "           1       0.82      0.69      0.75       189\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       510\n",
      "   macro avg       0.83      0.80      0.81       510\n",
      "weighted avg       0.83      0.83      0.83       510\n",
      "\n",
      "F1 score:  0.8100038110572043\n",
      "Started 7 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:17.202581\n",
      "[[2833   58]\n",
      " [  67 1632]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2891\n",
      "           1       0.97      0.96      0.96      1699\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4590\n",
      "   macro avg       0.97      0.97      0.97      4590\n",
      "weighted avg       0.97      0.97      0.97      4590\n",
      "\n",
      "F1 score:  0.9707653724843126\n",
      "[[300  21]\n",
      " [ 36 153]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       321\n",
      "           1       0.88      0.81      0.84       189\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       510\n",
      "   macro avg       0.89      0.87      0.88       510\n",
      "weighted avg       0.89      0.89      0.89       510\n",
      "\n",
      "F1 score:  0.8781086078719951\n",
      "Started 8 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:20.924199\n",
      "[[2810   81]\n",
      " [  91 1609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2891\n",
      "           1       0.95      0.95      0.95      1700\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4591\n",
      "   macro avg       0.96      0.96      0.96      4591\n",
      "weighted avg       0.96      0.96      0.96      4591\n",
      "\n",
      "F1 score:  0.9597832021382355\n",
      "[[278  43]\n",
      " [ 46 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       321\n",
      "           1       0.77      0.76      0.76       188\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       509\n",
      "   macro avg       0.81      0.81      0.81       509\n",
      "weighted avg       0.82      0.83      0.82       509\n",
      "\n",
      "F1 score:  0.8117048028763223\n",
      "Started 9 cv block processing\n",
      "Started BERT\n",
      "Started tokenizer loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizrer loaded\n",
      "Config is done\n",
      "Beginning Training!\n",
      "Training took time  0:12:17.662186\n",
      "[[2830   61]\n",
      " [  45 1655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2891\n",
      "           1       0.96      0.97      0.97      1700\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4591\n",
      "   macro avg       0.97      0.98      0.98      4591\n",
      "weighted avg       0.98      0.98      0.98      4591\n",
      "\n",
      "F1 score:  0.9752929634350115\n",
      "[[295  26]\n",
      " [ 34 154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       321\n",
      "           1       0.86      0.82      0.84       188\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       509\n",
      "   macro avg       0.88      0.87      0.87       509\n",
      "weighted avg       0.88      0.88      0.88       509\n",
      "\n",
      "F1 score:  0.872324414715719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train = train[\"Label\"].values\n",
    "y_train_array = train[\"Label\"].values\n",
    "x_train = train.drop([\"Label\"], axis=1).values\n",
    "skfolds = StratifiedKFold(n_splits=10, random_state=42)\n",
    "scores = []\n",
    "ind = 0\n",
    "for train_index, test_index in skfolds.split(x_train,y_train):\n",
    "    print(\"Started %d cv block processing\"%ind)\n",
    "    x_train_folds = x_train[train_index]\n",
    "    y_train_folds = y_train_array[train_index]\n",
    "    x_test_folds = x_train[test_index]\n",
    "    y_test_folds = y_train_array[test_index]\n",
    "    train_fold = pd.DataFrame(x_train_folds, columns=['Sentence', 'Number', 'Word Expression'])\n",
    "    train_fold[\"Label\"] = y_train_folds\n",
    "    test_fold = pd.DataFrame(x_test_folds, columns=['Sentence', 'Number', 'Word Expression'])\n",
    "    test_fold[\"Label\"] = y_test_folds\n",
    "    _measurements_labeler = measurements_labeler.MeasurementsLabeler(\"bert_results_cv_%d\"%ind)\n",
    "    _measurements_labeler.train_model(train_fold, train_fold)\n",
    "    res_prob, res_label, res_y = _measurements_labeler.evaluate_model(test_fold)\n",
    "    scores.append(f1_score(res_y, res_label, average=\"macro\"))\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8434033268365633,\n",
       "  0.8831961859979103,\n",
       "  0.888495159048063,\n",
       "  0.8372768644309728,\n",
       "  0.8561330147351653,\n",
       "  0.7767676767676767,\n",
       "  0.8100038110572043,\n",
       "  0.8781086078719951,\n",
       "  0.8117048028763223,\n",
       "  0.872324414715719],\n",
       " 0.8457413864337593,\n",
       " 0.03516131117115266,\n",
       " (0.7754187640914539, 0.9160640087760646))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, np.average(scores), np.std(scores), (np.average(scores) - 2*np.std(scores), np.average(scores) + 2*np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 14:11:10.933947 139819477702464 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started BERT\n",
      "Started tokenizer loading\n",
      "Used gpu 0\n",
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 14:11:11.897800 139819477702464 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:11:13.071826 139819477702464 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "0\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'bert_results_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29694c5710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:11:14.015396 139819477702464 estimator.py:201] Using config: {'_model_dir': 'bert_results_6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29694c5710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config is done\n"
     ]
    }
   ],
   "source": [
    "from interventions_labeling_lib import measurements_labeler\n",
    "measurements_labeler = reload(measurements_labeler)\n",
    "\n",
    "_measurements_labeler = measurements_labeler.MeasurementsLabeler(\"../model/bert_measurements_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.484949 139819477702464 base_bert_model.py:424] Writing example 0 of 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.486989 139819477702464 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.488427 139819477702464 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the majority ( 60 % ) of the farmers in kenya perceived that insect ##icides were not effective in controlling fall army ##worm as compared to most farmers ( 46 % ) in ethiopia who perceived that chemical spray is effective for the control of fall army ##worm . [SEP] 46 insect ##icide [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.489785 139819477702464 base_bert_model.py:403] tokens: [CLS] the majority ( 60 % ) of the farmers in kenya perceived that insect ##icides were not effective in controlling fall army ##worm as compared to most farmers ( 46 % ) in ethiopia who perceived that chemical spray is effective for the control of fall army ##worm . [SEP] 46 insect ##icide [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 3484 1006 3438 1003 1007 1997 1996 6617 1999 7938 8690 2008 14211 22698 2020 2025 4621 1999 9756 2991 2390 22769 2004 4102 2000 2087 6617 1006 4805 1003 1007 1999 11154 2040 8690 2008 5072 12509 2003 4621 2005 1996 2491 1997 2991 2390 22769 1012 102 4805 14211 21752 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.490850 139819477702464 base_bert_model.py:404] input_ids: 101 1996 3484 1006 3438 1003 1007 1997 1996 6617 1999 7938 8690 2008 14211 22698 2020 2025 4621 1999 9756 2991 2390 22769 2004 4102 2000 2087 6617 1006 4805 1003 1007 1999 11154 2040 8690 2008 5072 12509 2003 4621 2005 1996 2491 1997 2991 2390 22769 1012 102 4805 14211 21752 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.492014 139819477702464 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.492843 139819477702464 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.493521 139819477702464 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.495738 139819477702464 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.496450 139819477702464 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] of the costs , rental value of land , and hired human and machine labour account for more than 50 % for rape ##see ##d / mustard followed by wheat and ba ##j ##ra . [SEP] 50 machine labour [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.497114 139819477702464 base_bert_model.py:403] tokens: [CLS] of the costs , rental value of land , and hired human and machine labour account for more than 50 % for rape ##see ##d / mustard followed by wheat and ba ##j ##ra . [SEP] 50 machine labour [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1997 1996 5366 1010 12635 3643 1997 2455 1010 1998 5086 2529 1998 3698 4428 4070 2005 2062 2084 2753 1003 2005 9040 19763 2094 1013 23187 2628 2011 10500 1998 8670 3501 2527 1012 102 2753 3698 4428 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.498407 139819477702464 base_bert_model.py:404] input_ids: 101 1997 1996 5366 1010 12635 3643 1997 2455 1010 1998 5086 2529 1998 3698 4428 4070 2005 2062 2084 2753 1003 2005 9040 19763 2094 1013 23187 2628 2011 10500 1998 8670 3501 2527 1012 102 2753 3698 4428 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.499120 139819477702464 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.499651 139819477702464 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.500154 139819477702464 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.501305 139819477702464 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.501816 139819477702464 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] bench ##marks , estimated as the means of the top five yielding farmer crops , were 4 . 0 t / ha grain yield , 40 kg fe ##rti ##lis ##er n input / ha , 95 % leg ##ume ##s prior to monsoon rice , 80 kg total ( fe ##rti ##lis ##er + leg ##ume ) n input / ha , 14 kg fe ##rti ##lis ##er p input / ha and 14 kg fe ##rti ##lis ##er k input / ha . [SEP] 95 rice [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.502338 139819477702464 base_bert_model.py:403] tokens: [CLS] bench ##marks , estimated as the means of the top five yielding farmer crops , were 4 . 0 t / ha grain yield , 40 kg fe ##rti ##lis ##er n input / ha , 95 % leg ##ume ##s prior to monsoon rice , 80 kg total ( fe ##rti ##lis ##er + leg ##ume ) n input / ha , 14 kg fe ##rti ##lis ##er p input / ha and 14 kg fe ##rti ##lis ##er k input / ha . [SEP] 95 rice [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6847 27373 1010 4358 2004 1996 2965 1997 1996 2327 2274 21336 7500 8765 1010 2020 1018 1012 1014 1056 1013 5292 8982 10750 1010 2871 4705 10768 28228 6856 2121 1050 7953 1013 5292 1010 5345 1003 4190 17897 2015 3188 2000 19183 5785 1010 3770 4705 2561 1006 10768 28228 6856 2121 1009 4190 17897 1007 1050 7953 1013 5292 1010 2403 4705 10768 28228 6856 2121 1052 7953 1013 5292 1998 2403 4705 10768 28228 6856 2121 1047 7953 1013 5292 1012 102 5345 5785 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.502864 139819477702464 base_bert_model.py:404] input_ids: 101 6847 27373 1010 4358 2004 1996 2965 1997 1996 2327 2274 21336 7500 8765 1010 2020 1018 1012 1014 1056 1013 5292 8982 10750 1010 2871 4705 10768 28228 6856 2121 1050 7953 1013 5292 1010 5345 1003 4190 17897 2015 3188 2000 19183 5785 1010 3770 4705 2561 1006 10768 28228 6856 2121 1009 4190 17897 1007 1050 7953 1013 5292 1010 2403 4705 10768 28228 6856 2121 1052 7953 1013 5292 1998 2403 4705 10768 28228 6856 2121 1047 7953 1013 5292 1012 102 5345 5785 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.503400 139819477702464 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.503934 139819477702464 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.504429 139819477702464 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.505264 139819477702464 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.505755 139819477702464 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] cross validation approaches have been implemented in most studies resulting in acc ##ura ##cies of 0 . 20 - 0 . 60 . [SEP] 0 . 60 cross validation approach [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.507605 139819477702464 base_bert_model.py:403] tokens: [CLS] cross validation approaches have been implemented in most studies resulting in acc ##ura ##cies of 0 . 20 - 0 . 60 . [SEP] 0 . 60 cross validation approach [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2892 27354 8107 2031 2042 7528 1999 2087 2913 4525 1999 16222 4648 9243 1997 1014 1012 2322 1011 1014 1012 3438 1012 102 1014 1012 3438 2892 27354 3921 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.508142 139819477702464 base_bert_model.py:404] input_ids: 101 2892 27354 8107 2031 2042 7528 1999 2087 2913 4525 1999 16222 4648 9243 1997 1014 1012 2322 1011 1014 1012 3438 1012 102 1014 1012 3438 2892 27354 3921 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.508652 139819477702464 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.509151 139819477702464 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.509642 139819477702464 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.511044 139819477702464 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.511521 139819477702464 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the actual field capacity of the plant ##er was 0 . 45 ha / h with a field efficiency of 58 . 6 % , when operated in low - i tractor gear and at 1800 engine rpm . [SEP] 0 . 45 actual field capacity [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.512086 139819477702464 base_bert_model.py:403] tokens: [CLS] the actual field capacity of the plant ##er was 0 . 45 ha / h with a field efficiency of 58 . 6 % , when operated in low - i tractor gear and at 1800 engine rpm . [SEP] 0 . 45 actual field capacity [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 5025 2492 3977 1997 1996 3269 2121 2001 1014 1012 3429 5292 1013 1044 2007 1037 2492 8122 1997 5388 1012 1020 1003 1010 2043 3498 1999 2659 1011 1045 16358 6718 1998 2012 9807 3194 11575 1012 102 1014 1012 3429 5025 2492 3977 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.512617 139819477702464 base_bert_model.py:404] input_ids: 101 1996 5025 2492 3977 1997 1996 3269 2121 2001 1014 1012 3429 5292 1013 1044 2007 1037 2492 8122 1997 5388 1012 1020 1003 1010 2043 3498 1999 2659 1011 1045 16358 6718 1998 2012 9807 3194 11575 1012 102 1014 1012 3429 5025 2492 3977 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.513666 139819477702464 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.514389 139819477702464 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.514886 139819477702464 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:43.750700 139819477702464 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:45.599220 139819477702464 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:45.681876 139819477702464 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:46.085626 139819477702464 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from bert_results_6/model.ckpt-956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:46.091621 139819477702464 saver.py:1270] Restoring parameters from bert_results_6/model.ckpt-956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:46.641094 139819477702464 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0625 14:25:46.705993 139819477702464 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150  42]\n",
      " [ 18  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       192\n",
      "           1       0.68      0.83      0.75       108\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       300\n",
      "   macro avg       0.79      0.81      0.79       300\n",
      "weighted avg       0.82      0.80      0.80       300\n",
      "\n",
      "F1 score:  0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "train, test = _measurements_labeler.prepare_datasets(\"../tmp/measurements_data/test.xlsx\", all_dataset=True)\n",
    "res = _measurements_labeler.evaluate_model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_measurements_labeler.getPredictions(pred_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with BERT classification for interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import excel_reader\n",
    "interventions_df = excel_reader.ExcelReader().read_df_from_excel(\"../hyponyms_for_train.xlsx\")\n",
    "test_interventions_df = excel_reader.ExcelReader().read_df_from_excel(\"../hyponyms_test_with_predicted_labels.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = {\n",
    "    \"Technology intervention\": 0,\n",
    "    \"Socioeconomic intervention\":    1,\n",
    "    \"Ecosystem intervention\":        2,\n",
    "    \"Mechanisation intervention\":    3,\n",
    "    \"Storage intervention\":          4,\n",
    "    \"Non-intervention\": 5\n",
    "}\n",
    "id2class = {value: item for item, value in class2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_df[\"label\"] = interventions_df[\"Label\"].map(lambda x: class2id[x])\n",
    "test_interventions_df[\"label\"] = test_interventions_df[\"Label\"].map(lambda x: class2id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 11:39:03.442067 140031605708608 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizer loading\n",
      "Used gpu 0\n",
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 11:39:04.198165 140031605708608 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:39:06.106757 140031605708608 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "0\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'interventions_model_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5b0d66f358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:39:07.088077 140031605708608 estimator.py:201] Using config: {'_model_dir': 'interventions_model_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5b0d66f358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config is done\n"
     ]
    }
   ],
   "source": [
    "from bert_models import base_bert_model_interventions\n",
    "inteventions_labels_model = base_bert_model_interventions.BaseBertModelInterventions(\"interventions_model_1\", list(range(6)), gpu_device_num_hub=1, gpu_device_num =1, \n",
    "                                                         batch_size = 64, max_seq_length = 64, label_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "interventions_df = shuffle(interventions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.197277 140029104518976 base_bert_model.py:424] Writing example 0 of 2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.198580 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.199653 140029104518976 base_bert_model.py:401] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] brasil ##ia [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.200929 140029104518976 base_bert_model.py:403] tokens: [CLS] brasil ##ia [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 21133 2401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.201819 140029104518976 base_bert_model.py:404] input_ids: 101 21133 2401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.202404 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.203160 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 5 (id = 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.203998 140029104518976 base_bert_model.py:407] label: 5 (id = 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.204807 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.205503 140029104518976 base_bert_model.py:401] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] tropical pasture [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.206284 140029104518976 base_bert_model.py:403] tokens: [CLS] tropical pasture [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5133 20787 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.207040 140029104518976 base_bert_model.py:404] input_ids: 101 5133 20787 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.207595 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.208499 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 5 (id = 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.210775 140029104518976 base_bert_model.py:407] label: 5 (id = 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.211789 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.212345 140029104518976 base_bert_model.py:401] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] machinery manufacture [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.212947 140029104518976 base_bert_model.py:403] tokens: [CLS] machinery manufacture [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10394 9922 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.213997 140029104518976 base_bert_model.py:404] input_ids: 101 10394 9922 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.214808 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.215642 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.216613 140029104518976 base_bert_model.py:407] label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.217660 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.218661 140029104518976 base_bert_model.py:401] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] orthogonal experiment [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.219524 140029104518976 base_bert_model.py:403] tokens: [CLS] orthogonal experiment [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 28721 7551 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.220458 140029104518976 base_bert_model.py:404] input_ids: 101 28721 7551 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.222579 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.223428 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 5 (id = 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.224273 140029104518976 base_bert_model.py:407] label: 5 (id = 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.225791 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.226739 140029104518976 base_bert_model.py:401] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ref ##orestation mod ##ality [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.227583 140029104518976 base_bert_model.py:403] tokens: [CLS] ref ##orestation mod ##ality [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25416 25794 16913 23732 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.228556 140029104518976 base_bert_model.py:404] input_ids: 101 25416 25794 16913 23732 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.229431 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.230256 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.231973 140029104518976 base_bert_model.py:407] label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'interventions_model_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5a774cbf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.423959 140029104518976 estimator.py:201] Using config: {'_model_dir': 'interventions_model_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5a774cbf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:19.919012 140029104518976 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:23.032156 140029104518976 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../src/bert_models/base_bert_model.py:151: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 10:53:23.143033 140029104518976 deprecation.py:506] From ../src/bert_models/base_bert_model.py:151: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 10:53:23.187580 140029104518976 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 10:53:23.259494 140029104518976 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 10:53:31.178169 140029104518976 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Used for model gpu 1\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:32.067146 140029104518976 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:32.069480 140029104518976 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:35.618503 140029104518976 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:40.656022 140029104518976 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:40.920233 140029104518976 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into interventions_model_1/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:48.632076 140029104518976 basic_session_run_hooks.py:594] Saving checkpoints for 0 into interventions_model_1/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.8565856, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:53:58.124426 140029104518976 basic_session_run_hooks.py:249] loss = 1.8565856, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 94 into interventions_model_1/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:34.400547 140029104518976 basic_session_run_hooks.py:594] Saving checkpoints for 94 into interventions_model_1/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.40422657.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.651197 140029104518976 estimator.py:359] Loss for final step: 0.40422657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:01:17.226585\n",
      "INFO:tensorflow:Writing example 0 of 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.660296 140029104518976 base_bert_model.py:424] Writing example 0 of 2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.661754 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.663021 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] brasil ##ia [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.663855 140029104518976 base_bert_model.py:403] tokens: [CLS] brasil ##ia [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 21133 2401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.665132 140029104518976 base_bert_model.py:404] input_ids: 101 21133 2401 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.666320 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.667198 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.668243 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.669311 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.670177 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] tropical pasture [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.671472 140029104518976 base_bert_model.py:403] tokens: [CLS] tropical pasture [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5133 20787 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.672448 140029104518976 base_bert_model.py:404] input_ids: 101 5133 20787 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.673474 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.674687 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.675654 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.676497 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.677560 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] machinery manufacture [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.678317 140029104518976 base_bert_model.py:403] tokens: [CLS] machinery manufacture [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10394 9922 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.679129 140029104518976 base_bert_model.py:404] input_ids: 101 10394 9922 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.679864 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.680615 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.681998 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.682868 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.683580 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] orthogonal experiment [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.684768 140029104518976 base_bert_model.py:403] tokens: [CLS] orthogonal experiment [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 28721 7551 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.685786 140029104518976 base_bert_model.py:404] input_ids: 101 28721 7551 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.686632 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.687597 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.688322 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.689292 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.689979 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ref ##orestation mod ##ality [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.690660 140029104518976 base_bert_model.py:403] tokens: [CLS] ref ##orestation mod ##ality [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 25416 25794 16913 23732 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.691889 140029104518976 base_bert_model.py:404] input_ids: 101 25416 25794 16913 23732 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.693059 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.694826 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:36.698659 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:37.413941 140029104518976 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:41.115398 140029104518976 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:41.255778 140029104518976 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:41.787793 140029104518976 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 10:54:41.789932 140029104518976 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:41.791996 140029104518976 saver.py:1270] Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:42.640921 140029104518976 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:42.741391 140029104518976 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[652   5   2   5   1  20]\n",
      " [  7 214   4   3   0   9]\n",
      " [  8   1 124   0   6   3]\n",
      " [  6   0   0 114   1   5]\n",
      " [  3   3   6   2 107   3]\n",
      " [ 24   6   5   3   1 655]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       685\n",
      "           1       0.93      0.90      0.92       237\n",
      "           2       0.88      0.87      0.88       142\n",
      "           3       0.90      0.90      0.90       126\n",
      "           4       0.92      0.86      0.89       124\n",
      "           5       0.94      0.94      0.94       694\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2008\n",
      "   macro avg       0.92      0.91      0.91      2008\n",
      "weighted avg       0.93      0.93      0.93      2008\n",
      "\n",
      "F1 score:  0.9120455428170927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([0.05809062, 0.01410394, 0.01226282, 0.01672174, 0.01141194,\n",
       "         0.8874089 ], dtype=float32),\n",
       "  array([0.11364584, 0.04742139, 0.14481889, 0.03429716, 0.05538703,\n",
       "         0.6044296 ], dtype=float32),\n",
       "  array([0.11917907, 0.01421885, 0.01893297, 0.7572563 , 0.05234072,\n",
       "         0.03807202], dtype=float32),\n",
       "  array([0.04358981, 0.01440416, 0.00664271, 0.00744928, 0.00554451,\n",
       "         0.92236954], dtype=float32),\n",
       "  array([0.07594933, 0.06497489, 0.71691483, 0.0350449 , 0.08880764,\n",
       "         0.01830838], dtype=float32),\n",
       "  array([0.04156075, 0.01204858, 0.02045236, 0.85479945, 0.04634505,\n",
       "         0.0247938 ], dtype=float32),\n",
       "  array([0.02220665, 0.01268258, 0.04032531, 0.1317339 , 0.7776963 ,\n",
       "         0.0153552 ], dtype=float32),\n",
       "  array([0.02324919, 0.84801865, 0.07866998, 0.00635613, 0.01167532,\n",
       "         0.03203079], dtype=float32),\n",
       "  array([0.0528361 , 0.01187389, 0.00912296, 0.01268792, 0.00875162,\n",
       "         0.9047275 ], dtype=float32),\n",
       "  array([0.9254624 , 0.00597457, 0.01428003, 0.03015859, 0.01628771,\n",
       "         0.00783653], dtype=float32),\n",
       "  array([0.02961284, 0.01388031, 0.00802029, 0.00917156, 0.00720922,\n",
       "         0.9321058 ], dtype=float32),\n",
       "  array([0.9550314 , 0.00376913, 0.00894431, 0.01146605, 0.00599878,\n",
       "         0.01479046], dtype=float32),\n",
       "  array([0.88468194, 0.01793254, 0.01214109, 0.00562183, 0.00752776,\n",
       "         0.07209475], dtype=float32),\n",
       "  array([0.16935022, 0.03261989, 0.14464407, 0.13776407, 0.18531927,\n",
       "         0.33030245], dtype=float32),\n",
       "  array([0.02716017, 0.02247921, 0.00767144, 0.00733459, 0.00542069,\n",
       "         0.92993385], dtype=float32),\n",
       "  array([0.96376336, 0.00392414, 0.00900479, 0.00825666, 0.00708164,\n",
       "         0.0079693 ], dtype=float32),\n",
       "  array([0.8362191 , 0.01690482, 0.03395119, 0.04313735, 0.0465739 ,\n",
       "         0.02321374], dtype=float32),\n",
       "  array([0.05827202, 0.01931393, 0.01127404, 0.00634225, 0.00545046,\n",
       "         0.8993473 ], dtype=float32),\n",
       "  array([0.0538272 , 0.02728956, 0.01387434, 0.02273976, 0.01607194,\n",
       "         0.8661972 ], dtype=float32),\n",
       "  array([0.96495616, 0.00391582, 0.00822428, 0.00862091, 0.00642558,\n",
       "         0.00785729], dtype=float32),\n",
       "  array([0.03467724, 0.01848459, 0.0089884 , 0.00720992, 0.00671318,\n",
       "         0.92392665], dtype=float32),\n",
       "  array([0.0850412 , 0.01869709, 0.00978029, 0.00725389, 0.00600653,\n",
       "         0.873221  ], dtype=float32),\n",
       "  array([0.539728  , 0.02251008, 0.17232077, 0.06549314, 0.13331221,\n",
       "         0.06663582], dtype=float32),\n",
       "  array([0.94293517, 0.00623819, 0.01984272, 0.01218672, 0.01188424,\n",
       "         0.00691306], dtype=float32),\n",
       "  array([0.07371821, 0.03098674, 0.01063799, 0.00561296, 0.00513697,\n",
       "         0.8739071 ], dtype=float32),\n",
       "  array([0.0628511 , 0.02478993, 0.01452728, 0.00795727, 0.00579364,\n",
       "         0.8840808 ], dtype=float32),\n",
       "  array([0.03033455, 0.01329821, 0.04445638, 0.08172665, 0.8190507 ,\n",
       "         0.01113341], dtype=float32),\n",
       "  array([0.95048803, 0.00459449, 0.01051901, 0.01172191, 0.00793128,\n",
       "         0.01474533], dtype=float32),\n",
       "  array([0.05704907, 0.15063453, 0.03976553, 0.00707976, 0.00536999,\n",
       "         0.74010116], dtype=float32),\n",
       "  array([0.89849526, 0.00871321, 0.01885482, 0.02070728, 0.02231213,\n",
       "         0.03091732], dtype=float32),\n",
       "  array([0.01416332, 0.85344845, 0.0731845 , 0.00666159, 0.01228729,\n",
       "         0.04025485], dtype=float32),\n",
       "  array([0.01827973, 0.8449645 , 0.09399959, 0.00955748, 0.01286774,\n",
       "         0.02033101], dtype=float32),\n",
       "  array([0.02245286, 0.02244691, 0.00739602, 0.00698573, 0.00575893,\n",
       "         0.9349596 ], dtype=float32),\n",
       "  array([0.9537847 , 0.00561811, 0.01504738, 0.00728824, 0.00881813,\n",
       "         0.00944331], dtype=float32),\n",
       "  array([0.9501613 , 0.00488273, 0.01382398, 0.01319618, 0.01138696,\n",
       "         0.00654885], dtype=float32),\n",
       "  array([0.02711842, 0.01740365, 0.00719022, 0.00751344, 0.00618643,\n",
       "         0.93458784], dtype=float32),\n",
       "  array([0.9631601 , 0.0048409 , 0.00632881, 0.00642777, 0.00584184,\n",
       "         0.0134006 ], dtype=float32),\n",
       "  array([0.0795385 , 0.0742213 , 0.73549277, 0.02590679, 0.05867851,\n",
       "         0.02616221], dtype=float32),\n",
       "  array([0.09883633, 0.01324385, 0.01374713, 0.026769  , 0.01592898,\n",
       "         0.8314747 ], dtype=float32),\n",
       "  array([0.95739067, 0.00490471, 0.00785554, 0.00801507, 0.00707282,\n",
       "         0.01476112], dtype=float32),\n",
       "  array([0.02706335, 0.02074436, 0.03973196, 0.04299519, 0.8453964 ,\n",
       "         0.02406876], dtype=float32),\n",
       "  array([0.941733  , 0.00475865, 0.01427841, 0.01592444, 0.0105544 ,\n",
       "         0.0127511 ], dtype=float32),\n",
       "  array([0.03903144, 0.02526243, 0.04550662, 0.03950405, 0.817382  ,\n",
       "         0.03331347], dtype=float32),\n",
       "  array([0.07701709, 0.01613593, 0.01070918, 0.04239672, 0.01596575,\n",
       "         0.8377753 ], dtype=float32),\n",
       "  array([0.05397334, 0.01565178, 0.00851259, 0.00732319, 0.00499545,\n",
       "         0.90954363], dtype=float32),\n",
       "  array([0.20072079, 0.10018425, 0.25668734, 0.01942657, 0.02902873,\n",
       "         0.39395225], dtype=float32),\n",
       "  array([0.05445982, 0.10340201, 0.50435716, 0.04922011, 0.03531614,\n",
       "         0.25324476], dtype=float32),\n",
       "  array([0.12926704, 0.04874147, 0.02139851, 0.02039167, 0.01109162,\n",
       "         0.7691097 ], dtype=float32),\n",
       "  array([0.03516247, 0.04245178, 0.00971558, 0.0080396 , 0.0067033 ,\n",
       "         0.8979273 ], dtype=float32),\n",
       "  array([0.01857286, 0.8801012 , 0.05493693, 0.00710429, 0.011682  ,\n",
       "         0.02760259], dtype=float32),\n",
       "  array([0.93048066, 0.00679398, 0.02317972, 0.01500022, 0.01328546,\n",
       "         0.01126002], dtype=float32),\n",
       "  array([0.961465  , 0.00372254, 0.00821769, 0.01089117, 0.00871337,\n",
       "         0.00699025], dtype=float32),\n",
       "  array([0.14392637, 0.04756492, 0.5802307 , 0.04621723, 0.15154329,\n",
       "         0.03051746], dtype=float32),\n",
       "  array([0.9567643 , 0.00384761, 0.00963101, 0.01069988, 0.00947359,\n",
       "         0.00958365], dtype=float32),\n",
       "  array([0.10820859, 0.012699  , 0.01147294, 0.02239423, 0.01192076,\n",
       "         0.83330446], dtype=float32),\n",
       "  array([0.04752076, 0.01186396, 0.02860068, 0.8267038 , 0.06201485,\n",
       "         0.02329595], dtype=float32),\n",
       "  array([0.26378283, 0.01723001, 0.02868426, 0.6190183 , 0.03661418,\n",
       "         0.03467037], dtype=float32),\n",
       "  array([0.09847055, 0.01924591, 0.05638423, 0.17050883, 0.63114256,\n",
       "         0.02424797], dtype=float32),\n",
       "  array([0.16811822, 0.05813513, 0.6479696 , 0.03215208, 0.07351184,\n",
       "         0.02011311], dtype=float32),\n",
       "  array([0.06018   , 0.03150253, 0.01044818, 0.00842996, 0.00671669,\n",
       "         0.8827227 ], dtype=float32),\n",
       "  array([0.03988818, 0.8080272 , 0.09658855, 0.00632707, 0.01248744,\n",
       "         0.0366815 ], dtype=float32),\n",
       "  array([0.9639586 , 0.00385407, 0.00699664, 0.00920751, 0.00640577,\n",
       "         0.00957731], dtype=float32),\n",
       "  array([0.96030676, 0.00381077, 0.00680264, 0.01234363, 0.00720725,\n",
       "         0.00952897], dtype=float32),\n",
       "  array([0.07139309, 0.0145463 , 0.01974635, 0.7978408 , 0.03943966,\n",
       "         0.05703392], dtype=float32),\n",
       "  array([0.8236943 , 0.02402943, 0.02872192, 0.02568185, 0.03828024,\n",
       "         0.05959222], dtype=float32),\n",
       "  array([0.9635005 , 0.00467234, 0.00626231, 0.00748894, 0.00648489,\n",
       "         0.01159104], dtype=float32),\n",
       "  array([0.06465079, 0.01174444, 0.01100705, 0.00979317, 0.00685607,\n",
       "         0.89594847], dtype=float32),\n",
       "  array([0.05470803, 0.01309826, 0.0200756 , 0.82938063, 0.05462286,\n",
       "         0.02811462], dtype=float32),\n",
       "  array([0.08085059, 0.76011705, 0.0932617 , 0.00792811, 0.01761123,\n",
       "         0.04023125], dtype=float32),\n",
       "  array([0.04514008, 0.01160456, 0.02264   , 0.844431  , 0.05504888,\n",
       "         0.02113539], dtype=float32),\n",
       "  array([0.0433645 , 0.7720313 , 0.07185284, 0.00705211, 0.00937382,\n",
       "         0.09632535], dtype=float32),\n",
       "  array([0.9569632 , 0.00431128, 0.00562569, 0.00894836, 0.00597723,\n",
       "         0.01817427], dtype=float32),\n",
       "  array([0.95779806, 0.00425525, 0.01121057, 0.01140051, 0.00848863,\n",
       "         0.00684701], dtype=float32),\n",
       "  array([0.0324368 , 0.785801  , 0.12982863, 0.00692083, 0.01855667,\n",
       "         0.02645613], dtype=float32),\n",
       "  array([0.04639013, 0.01274672, 0.0085821 , 0.01291684, 0.00825666,\n",
       "         0.91110754], dtype=float32),\n",
       "  array([0.02807815, 0.0176164 , 0.00719654, 0.00680054, 0.00562039,\n",
       "         0.93468803], dtype=float32),\n",
       "  array([0.94351405, 0.00505126, 0.00854995, 0.01166188, 0.00727364,\n",
       "         0.02394906], dtype=float32),\n",
       "  array([0.05820663, 0.03738744, 0.01363795, 0.01431976, 0.00980888,\n",
       "         0.8666394 ], dtype=float32),\n",
       "  array([0.88977385, 0.00779919, 0.04240924, 0.01221536, 0.02180638,\n",
       "         0.025996  ], dtype=float32),\n",
       "  array([0.11486168, 0.0112353 , 0.013168  , 0.02454082, 0.01276492,\n",
       "         0.8234292 ], dtype=float32),\n",
       "  array([0.7550062 , 0.11132773, 0.06087029, 0.00759255, 0.0072528 ,\n",
       "         0.05795052], dtype=float32),\n",
       "  array([0.9503869 , 0.00489138, 0.01317854, 0.01332864, 0.01105305,\n",
       "         0.00716139], dtype=float32),\n",
       "  array([0.40021688, 0.06560495, 0.43435663, 0.03090846, 0.05416396,\n",
       "         0.01474906], dtype=float32),\n",
       "  array([0.03801229, 0.01503083, 0.01670176, 0.85644954, 0.04899579,\n",
       "         0.02480978], dtype=float32),\n",
       "  array([0.95346826, 0.00640886, 0.01164158, 0.00533316, 0.00682962,\n",
       "         0.01631848], dtype=float32),\n",
       "  array([0.9639243 , 0.00376451, 0.00576624, 0.00876805, 0.00460608,\n",
       "         0.01317077], dtype=float32),\n",
       "  array([0.05909505, 0.01294972, 0.02795284, 0.8189167 , 0.06206195,\n",
       "         0.01902376], dtype=float32),\n",
       "  array([0.03469417, 0.537017  , 0.18474728, 0.02249638, 0.11687733,\n",
       "         0.10416789], dtype=float32),\n",
       "  array([0.02894824, 0.01671152, 0.00733276, 0.00899983, 0.00693624,\n",
       "         0.9310714 ], dtype=float32),\n",
       "  array([0.31652492, 0.01482175, 0.01793855, 0.07279319, 0.03015804,\n",
       "         0.5477636 ], dtype=float32),\n",
       "  array([0.13294017, 0.19216733, 0.58246034, 0.01641328, 0.04572644,\n",
       "         0.03029248], dtype=float32),\n",
       "  array([0.03681805, 0.02126543, 0.01294803, 0.00771691, 0.00655112,\n",
       "         0.91470045], dtype=float32),\n",
       "  array([0.9649577 , 0.00425599, 0.00669887, 0.0086927 , 0.00711364,\n",
       "         0.00828105], dtype=float32),\n",
       "  array([0.073131  , 0.01179961, 0.00892623, 0.00857326, 0.00626479,\n",
       "         0.8913051 ], dtype=float32),\n",
       "  array([0.08336351, 0.01697522, 0.02144882, 0.01195811, 0.00988841,\n",
       "         0.8563659 ], dtype=float32),\n",
       "  array([0.02775908, 0.02187127, 0.00747664, 0.00712569, 0.00551948,\n",
       "         0.9302479 ], dtype=float32),\n",
       "  array([0.04737831, 0.7604589 , 0.14213501, 0.00829119, 0.01604932,\n",
       "         0.02568733], dtype=float32),\n",
       "  array([0.94976777, 0.00403368, 0.00956194, 0.01685055, 0.00880698,\n",
       "         0.01097891], dtype=float32),\n",
       "  array([0.02612562, 0.14829774, 0.6952016 , 0.03046785, 0.0629968 ,\n",
       "         0.03691047], dtype=float32),\n",
       "  array([0.91378874, 0.01152307, 0.02019156, 0.00937094, 0.00525425,\n",
       "         0.03987149], dtype=float32),\n",
       "  array([0.02485003, 0.7472705 , 0.18035288, 0.01059341, 0.02134086,\n",
       "         0.01559226], dtype=float32),\n",
       "  array([0.23380649, 0.37186804, 0.21034072, 0.04162759, 0.07226116,\n",
       "         0.07009602], dtype=float32),\n",
       "  array([0.05576975, 0.01339209, 0.00902192, 0.01484221, 0.00722458,\n",
       "         0.89974946], dtype=float32),\n",
       "  array([0.05434006, 0.0170301 , 0.01359359, 0.01478001, 0.01121494,\n",
       "         0.8890413 ], dtype=float32),\n",
       "  array([0.02714282, 0.01779149, 0.05909541, 0.05792204, 0.8265838 ,\n",
       "         0.01146444], dtype=float32),\n",
       "  array([0.93561375, 0.00538186, 0.01689835, 0.01103758, 0.01210233,\n",
       "         0.01896615], dtype=float32),\n",
       "  array([0.3920225 , 0.0167191 , 0.0162543 , 0.00890999, 0.0066485 ,\n",
       "         0.55944556], dtype=float32),\n",
       "  array([0.04017405, 0.08974689, 0.7421977 , 0.03178439, 0.07724496,\n",
       "         0.01885194], dtype=float32),\n",
       "  array([0.14560379, 0.07730557, 0.06437161, 0.01222061, 0.01206244,\n",
       "         0.688436  ], dtype=float32),\n",
       "  array([0.07290912, 0.01616065, 0.0156797 , 0.02395023, 0.01260669,\n",
       "         0.8586936 ], dtype=float32),\n",
       "  array([0.14930472, 0.01495099, 0.01760379, 0.01940311, 0.01282868,\n",
       "         0.7859087 ], dtype=float32),\n",
       "  array([0.91090035, 0.00672968, 0.00986564, 0.0301089 , 0.01742568,\n",
       "         0.0249697 ], dtype=float32),\n",
       "  array([0.03963573, 0.82695013, 0.07764477, 0.00681912, 0.01350931,\n",
       "         0.03544095], dtype=float32),\n",
       "  array([0.0645319 , 0.0171074 , 0.00939185, 0.01226979, 0.00668412,\n",
       "         0.89001495], dtype=float32),\n",
       "  array([0.9652672 , 0.00402814, 0.00577329, 0.00808473, 0.0061956 ,\n",
       "         0.010651  ], dtype=float32),\n",
       "  array([0.9437215 , 0.00885511, 0.01340782, 0.00790524, 0.01427455,\n",
       "         0.01183581], dtype=float32),\n",
       "  array([0.0296416 , 0.862732  , 0.03791884, 0.00755424, 0.01102692,\n",
       "         0.05112644], dtype=float32),\n",
       "  array([0.94938904, 0.00483145, 0.00564124, 0.00717835, 0.00578721,\n",
       "         0.02717268], dtype=float32),\n",
       "  array([0.07274794, 0.02905736, 0.19963707, 0.08020497, 0.6010606 ,\n",
       "         0.01729197], dtype=float32),\n",
       "  array([0.9616583 , 0.00434961, 0.00780318, 0.00930598, 0.00851934,\n",
       "         0.00836341], dtype=float32),\n",
       "  array([0.9483233 , 0.00435426, 0.00943952, 0.01653673, 0.00887949,\n",
       "         0.01246673], dtype=float32),\n",
       "  array([0.9446264 , 0.00503653, 0.01293833, 0.01418887, 0.01382151,\n",
       "         0.00938838], dtype=float32),\n",
       "  array([0.08202878, 0.01231734, 0.02165605, 0.8198254 , 0.04163617,\n",
       "         0.02253627], dtype=float32),\n",
       "  array([0.25841635, 0.47326404, 0.05616999, 0.01117266, 0.01230863,\n",
       "         0.18866825], dtype=float32),\n",
       "  array([0.08532155, 0.05461249, 0.7406327 , 0.03322161, 0.06776626,\n",
       "         0.01844546], dtype=float32),\n",
       "  array([0.03037174, 0.01757213, 0.00773023, 0.00828032, 0.0066034 ,\n",
       "         0.92944217], dtype=float32),\n",
       "  array([0.9585452 , 0.00577903, 0.00817343, 0.00480399, 0.00507897,\n",
       "         0.01761926], dtype=float32),\n",
       "  array([0.9623179 , 0.00535134, 0.00743717, 0.00550466, 0.0052156 ,\n",
       "         0.01417332], dtype=float32),\n",
       "  array([0.86962336, 0.01234071, 0.01770302, 0.03716609, 0.0210618 ,\n",
       "         0.04210499], dtype=float32),\n",
       "  array([0.96473163, 0.00380701, 0.00762033, 0.00768411, 0.00535729,\n",
       "         0.01079961], dtype=float32),\n",
       "  array([0.08050499, 0.01227795, 0.02918018, 0.8027827 , 0.05501321,\n",
       "         0.02024098], dtype=float32),\n",
       "  array([0.04512328, 0.56687397, 0.31308588, 0.01242371, 0.02111835,\n",
       "         0.04137476], dtype=float32),\n",
       "  array([0.46647212, 0.22159344, 0.24421881, 0.00965695, 0.02146091,\n",
       "         0.03659774], dtype=float32),\n",
       "  array([0.6253208 , 0.0155269 , 0.01587148, 0.02857422, 0.01060375,\n",
       "         0.30410287], dtype=float32),\n",
       "  array([0.9368322 , 0.00688854, 0.02389663, 0.00860299, 0.01307785,\n",
       "         0.01070173], dtype=float32),\n",
       "  array([0.02400784, 0.04275016, 0.01021379, 0.0093377 , 0.00736178,\n",
       "         0.90632874], dtype=float32),\n",
       "  array([0.1645305 , 0.06703181, 0.67609805, 0.0217356 , 0.04876918,\n",
       "         0.02183488], dtype=float32),\n",
       "  array([0.18782964, 0.04891206, 0.6357574 , 0.02617314, 0.07865082,\n",
       "         0.0226769 ], dtype=float32),\n",
       "  array([0.9428052 , 0.00417204, 0.00955676, 0.02384943, 0.01193888,\n",
       "         0.00767772], dtype=float32),\n",
       "  array([0.02894916, 0.02027644, 0.04937539, 0.08199298, 0.8067174 ,\n",
       "         0.01268866], dtype=float32),\n",
       "  array([0.70778704, 0.03428981, 0.01465121, 0.01289043, 0.00604497,\n",
       "         0.22433656], dtype=float32),\n",
       "  array([0.9447945 , 0.00611879, 0.01674347, 0.00888681, 0.0122326 ,\n",
       "         0.01122393], dtype=float32),\n",
       "  array([0.02964782, 0.3148338 , 0.563122  , 0.01922034, 0.05319533,\n",
       "         0.01998075], dtype=float32),\n",
       "  array([0.05397104, 0.01245494, 0.01097521, 0.0151282 , 0.00998232,\n",
       "         0.89748836], dtype=float32),\n",
       "  array([0.04029124, 0.01252836, 0.00784209, 0.00894802, 0.00710453,\n",
       "         0.9232858 ], dtype=float32),\n",
       "  array([0.8669991 , 0.01450802, 0.02983812, 0.00770397, 0.00832973,\n",
       "         0.07262107], dtype=float32),\n",
       "  array([0.2629501 , 0.02945762, 0.18197802, 0.22437347, 0.14710099,\n",
       "         0.15413983], dtype=float32),\n",
       "  array([0.01642096, 0.83961076, 0.07688822, 0.00779126, 0.00949332,\n",
       "         0.04979559], dtype=float32),\n",
       "  array([0.0576723 , 0.7156839 , 0.16443579, 0.00877865, 0.01359642,\n",
       "         0.03983305], dtype=float32),\n",
       "  array([0.03673926, 0.8448348 , 0.0583288 , 0.00672142, 0.01091619,\n",
       "         0.04245949], dtype=float32),\n",
       "  array([0.07074007, 0.01511238, 0.02395773, 0.817796  , 0.04216664,\n",
       "         0.03022712], dtype=float32),\n",
       "  array([0.96272564, 0.00398884, 0.00829853, 0.0091928 , 0.00799327,\n",
       "         0.00780104], dtype=float32),\n",
       "  array([0.96217495, 0.00568106, 0.00863654, 0.00546244, 0.00596583,\n",
       "         0.01207904], dtype=float32),\n",
       "  array([0.9567197 , 0.00391935, 0.00703165, 0.0130396 , 0.00990012,\n",
       "         0.00938968], dtype=float32),\n",
       "  array([0.04675453, 0.01782947, 0.00895499, 0.00934457, 0.00615546,\n",
       "         0.910961  ], dtype=float32),\n",
       "  array([0.9541095 , 0.00789649, 0.00914593, 0.00521966, 0.00646164,\n",
       "         0.01716667], dtype=float32),\n",
       "  array([0.04035945, 0.01772276, 0.00714958, 0.01242279, 0.00725997,\n",
       "         0.9150855 ], dtype=float32),\n",
       "  array([0.03826383, 0.03280213, 0.01005796, 0.00599355, 0.00531613,\n",
       "         0.90756637], dtype=float32),\n",
       "  array([0.16016443, 0.01899206, 0.01463318, 0.01253892, 0.00889679,\n",
       "         0.7847746 ], dtype=float32),\n",
       "  array([0.10543723, 0.01343865, 0.00869375, 0.0119773 , 0.00679827,\n",
       "         0.8536548 ], dtype=float32),\n",
       "  array([0.92043674, 0.01141521, 0.0322866 , 0.0124077 , 0.01090353,\n",
       "         0.01255025], dtype=float32),\n",
       "  array([0.9647423 , 0.0045587 , 0.00666829, 0.00601868, 0.00575169,\n",
       "         0.01226033], dtype=float32),\n",
       "  array([0.02806329, 0.02388744, 0.00882985, 0.00974725, 0.00734042,\n",
       "         0.9221317 ], dtype=float32),\n",
       "  array([0.03055906, 0.01602186, 0.00706593, 0.00772109, 0.00590221,\n",
       "         0.9327298 ], dtype=float32),\n",
       "  array([0.04188117, 0.01637214, 0.00773742, 0.00691748, 0.00502936,\n",
       "         0.92206246], dtype=float32),\n",
       "  array([0.79532063, 0.00998289, 0.02111114, 0.13316016, 0.02920161,\n",
       "         0.01122346], dtype=float32),\n",
       "  array([0.9537923 , 0.00666812, 0.01439837, 0.00645263, 0.00873645,\n",
       "         0.00995216], dtype=float32),\n",
       "  array([0.04830664, 0.01271844, 0.00738878, 0.0090262 , 0.00597657,\n",
       "         0.9165834 ], dtype=float32),\n",
       "  array([0.04483783, 0.01289606, 0.01148158, 0.01443345, 0.01049895,\n",
       "         0.9058521 ], dtype=float32),\n",
       "  array([0.11912049, 0.04511662, 0.5598829 , 0.0535624 , 0.17351812,\n",
       "         0.04879947], dtype=float32),\n",
       "  array([0.01275805, 0.8382831 , 0.10385403, 0.00818412, 0.01398758,\n",
       "         0.02293311], dtype=float32),\n",
       "  array([0.96350336, 0.00434858, 0.00585068, 0.00851727, 0.00560504,\n",
       "         0.01217517], dtype=float32),\n",
       "  array([0.9649357 , 0.003863  , 0.00718278, 0.00855392, 0.00693706,\n",
       "         0.00852751], dtype=float32),\n",
       "  array([0.94480234, 0.00427076, 0.00736116, 0.02270902, 0.00805043,\n",
       "         0.01280642], dtype=float32),\n",
       "  array([0.9182368 , 0.00675429, 0.01820896, 0.01895567, 0.02033916,\n",
       "         0.01750506], dtype=float32),\n",
       "  array([0.949027  , 0.00533238, 0.00858294, 0.00654929, 0.00753985,\n",
       "         0.02296852], dtype=float32),\n",
       "  array([0.06212252, 0.01534144, 0.08800091, 0.22960053, 0.5900695 ,\n",
       "         0.01486521], dtype=float32),\n",
       "  array([0.03772243, 0.01922115, 0.00789469, 0.00722311, 0.00506258,\n",
       "         0.922876  ], dtype=float32),\n",
       "  array([0.02640229, 0.8298687 , 0.06134325, 0.00632588, 0.01187178,\n",
       "         0.06418815], dtype=float32),\n",
       "  array([0.12672381, 0.01202933, 0.01856037, 0.03678063, 0.01778653,\n",
       "         0.7881193 ], dtype=float32),\n",
       "  array([0.16840476, 0.01106201, 0.01619405, 0.01888887, 0.01146005,\n",
       "         0.7739903 ], dtype=float32),\n",
       "  array([0.04255644, 0.0432261 , 0.01228797, 0.00888349, 0.00723903,\n",
       "         0.885807  ], dtype=float32),\n",
       "  array([0.02351673, 0.0260738 , 0.00851451, 0.00691832, 0.00597319,\n",
       "         0.9290035 ], dtype=float32),\n",
       "  array([0.9642229 , 0.00414559, 0.00671514, 0.00924543, 0.00693252,\n",
       "         0.00873837], dtype=float32),\n",
       "  array([0.35368115, 0.01486452, 0.01224293, 0.02042188, 0.01013763,\n",
       "         0.5886519 ], dtype=float32),\n",
       "  array([0.02597094, 0.01575145, 0.00732991, 0.00845334, 0.00672849,\n",
       "         0.9357659 ], dtype=float32),\n",
       "  array([0.9558478 , 0.00504176, 0.0072398 , 0.01134202, 0.00892281,\n",
       "         0.0116059 ], dtype=float32),\n",
       "  array([0.03838672, 0.01806649, 0.00929593, 0.0100195 , 0.00760272,\n",
       "         0.91662866], dtype=float32),\n",
       "  array([0.937215  , 0.01047679, 0.0220465 , 0.00725424, 0.01015682,\n",
       "         0.01285066], dtype=float32),\n",
       "  array([0.06992958, 0.01234267, 0.00796841, 0.00984374, 0.00614211,\n",
       "         0.89377356], dtype=float32),\n",
       "  array([0.02481798, 0.84152395, 0.05956618, 0.01111079, 0.01585961,\n",
       "         0.04712151], dtype=float32),\n",
       "  array([0.02787893, 0.01665725, 0.00727785, 0.00804771, 0.00617241,\n",
       "         0.9339658 ], dtype=float32),\n",
       "  array([0.9499794 , 0.00449191, 0.01027971, 0.01833619, 0.0088829 ,\n",
       "         0.00802989], dtype=float32),\n",
       "  array([0.01639911, 0.8721897 , 0.06663513, 0.00759941, 0.01014514,\n",
       "         0.02703157], dtype=float32),\n",
       "  array([0.9577005 , 0.00572896, 0.00902585, 0.00696521, 0.00960402,\n",
       "         0.01097544], dtype=float32),\n",
       "  array([0.9554519 , 0.00433595, 0.01185707, 0.01161124, 0.00959457,\n",
       "         0.00714925], dtype=float32),\n",
       "  array([0.02737976, 0.07691157, 0.01524279, 0.00617125, 0.00536163,\n",
       "         0.868933  ], dtype=float32),\n",
       "  array([0.9521366 , 0.00616209, 0.00902547, 0.00702099, 0.0073717 ,\n",
       "         0.0182832 ], dtype=float32),\n",
       "  array([0.02591901, 0.02310555, 0.00844741, 0.00776898, 0.00653678,\n",
       "         0.92822224], dtype=float32),\n",
       "  array([0.72110444, 0.01440959, 0.1424724 , 0.03968551, 0.04558283,\n",
       "         0.03674519], dtype=float32),\n",
       "  array([0.9498769 , 0.00488494, 0.01459755, 0.00847164, 0.00749715,\n",
       "         0.01467191], dtype=float32),\n",
       "  array([0.14927638, 0.03002187, 0.01819934, 0.00643849, 0.00558924,\n",
       "         0.79047465], dtype=float32),\n",
       "  array([0.57898486, 0.01241017, 0.01275475, 0.01650659, 0.00771622,\n",
       "         0.37162745], dtype=float32),\n",
       "  array([0.958129  , 0.00484702, 0.01262322, 0.00684231, 0.0085081 ,\n",
       "         0.00905032], dtype=float32),\n",
       "  array([0.4170505 , 0.01197824, 0.01505455, 0.01302539, 0.00856026,\n",
       "         0.534331  ], dtype=float32),\n",
       "  array([0.9509856 , 0.00480389, 0.01158316, 0.01489786, 0.00963084,\n",
       "         0.00809862], dtype=float32),\n",
       "  array([0.9303164 , 0.00713843, 0.01671897, 0.02311154, 0.01381309,\n",
       "         0.00890154], dtype=float32),\n",
       "  array([0.06905008, 0.01133755, 0.02567301, 0.65746653, 0.21777038,\n",
       "         0.01870253], dtype=float32),\n",
       "  array([0.19029729, 0.04411058, 0.6017782 , 0.03830465, 0.09904565,\n",
       "         0.02646361], dtype=float32),\n",
       "  array([0.02498088, 0.80058897, 0.05788565, 0.00870775, 0.00747917,\n",
       "         0.10035753], dtype=float32),\n",
       "  array([0.95886266, 0.00371778, 0.00750624, 0.01172948, 0.00607603,\n",
       "         0.01210793], dtype=float32),\n",
       "  array([0.07558664, 0.07259197, 0.7497839 , 0.02406618, 0.0530639 ,\n",
       "         0.02490744], dtype=float32),\n",
       "  array([0.02253697, 0.02131538, 0.00768559, 0.00773888, 0.00597062,\n",
       "         0.9347526 ], dtype=float32),\n",
       "  array([0.03966293, 0.01536677, 0.00919791, 0.01117917, 0.00882967,\n",
       "         0.9157636 ], dtype=float32),\n",
       "  array([0.12907577, 0.7031245 , 0.07395561, 0.00954755, 0.01358766,\n",
       "         0.07070891], dtype=float32),\n",
       "  array([0.9628597 , 0.00417591, 0.00867961, 0.00516785, 0.00566887,\n",
       "         0.01344823], dtype=float32),\n",
       "  array([0.667719  , 0.05334254, 0.09782696, 0.01003964, 0.00750868,\n",
       "         0.16356313], dtype=float32),\n",
       "  array([0.09677951, 0.04905962, 0.66644657, 0.04141527, 0.11293051,\n",
       "         0.03336852], dtype=float32),\n",
       "  array([0.03104314, 0.23390836, 0.65300626, 0.01533487, 0.04318595,\n",
       "         0.02352135], dtype=float32),\n",
       "  array([0.41446224, 0.03545094, 0.06238873, 0.16062902, 0.25838876,\n",
       "         0.06868022], dtype=float32),\n",
       "  array([0.05170252, 0.8201395 , 0.04457592, 0.00778346, 0.00968988,\n",
       "         0.06610872], dtype=float32),\n",
       "  array([0.08467773, 0.01053766, 0.0252202 , 0.80561537, 0.05943862,\n",
       "         0.01451035], dtype=float32),\n",
       "  array([0.02081091, 0.8314409 , 0.06064682, 0.00542085, 0.00787263,\n",
       "         0.07380793], dtype=float32),\n",
       "  array([0.0558558 , 0.04506348, 0.02521826, 0.00859196, 0.00752098,\n",
       "         0.8577496 ], dtype=float32),\n",
       "  array([0.48239163, 0.01685411, 0.05447812, 0.19669202, 0.22743027,\n",
       "         0.0221538 ], dtype=float32),\n",
       "  array([0.02429278, 0.01571026, 0.04406802, 0.06481383, 0.8393305 ,\n",
       "         0.01178456], dtype=float32),\n",
       "  array([0.7891368 , 0.0129262 , 0.07851934, 0.0437629 , 0.05933322,\n",
       "         0.01632158], dtype=float32),\n",
       "  array([0.03864351, 0.01332489, 0.00793868, 0.01171663, 0.00772688,\n",
       "         0.92064947], dtype=float32),\n",
       "  array([0.12386341, 0.02455743, 0.10730729, 0.15038775, 0.57905906,\n",
       "         0.01482506], dtype=float32),\n",
       "  array([0.03575776, 0.02662859, 0.09539202, 0.07516246, 0.75413495,\n",
       "         0.01292418], dtype=float32),\n",
       "  array([0.04785615, 0.03012325, 0.00908131, 0.00631427, 0.00505356,\n",
       "         0.9015715 ], dtype=float32),\n",
       "  array([0.04690315, 0.13290069, 0.7291034 , 0.02074488, 0.05009519,\n",
       "         0.0202527 ], dtype=float32),\n",
       "  array([0.9489064 , 0.00747893, 0.01142459, 0.00776004, 0.01107347,\n",
       "         0.01335643], dtype=float32),\n",
       "  array([0.9335038 , 0.00842809, 0.02739918, 0.00734882, 0.01152848,\n",
       "         0.0117916 ], dtype=float32),\n",
       "  array([0.03073997, 0.02199194, 0.07497354, 0.04853677, 0.7995204 ,\n",
       "         0.02423742], dtype=float32),\n",
       "  array([0.9097095 , 0.00543684, 0.01157714, 0.03502373, 0.01967261,\n",
       "         0.01858014], dtype=float32),\n",
       "  array([0.0139827 , 0.8841304 , 0.03851041, 0.00608753, 0.00744857,\n",
       "         0.04984039], dtype=float32),\n",
       "  array([0.9371075 , 0.00475566, 0.01224562, 0.02420492, 0.01507065,\n",
       "         0.00661563], dtype=float32),\n",
       "  array([0.93301165, 0.00945072, 0.02745232, 0.00658276, 0.01090641,\n",
       "         0.01259619], dtype=float32),\n",
       "  array([0.44734368, 0.04554966, 0.03143996, 0.00688088, 0.00546364,\n",
       "         0.46332222], dtype=float32),\n",
       "  array([0.23436965, 0.04959703, 0.26591858, 0.03434208, 0.02527002,\n",
       "         0.39050263], dtype=float32),\n",
       "  array([0.03788859, 0.01793452, 0.00988643, 0.00834254, 0.00606566,\n",
       "         0.9198823 ], dtype=float32),\n",
       "  array([0.18527815, 0.01739468, 0.01396046, 0.00694612, 0.00571196,\n",
       "         0.7707087 ], dtype=float32),\n",
       "  array([0.05203933, 0.11162182, 0.73947334, 0.02170745, 0.04915904,\n",
       "         0.02599897], dtype=float32),\n",
       "  array([0.81902194, 0.01727882, 0.01508396, 0.00850138, 0.00618483,\n",
       "         0.13392907], dtype=float32),\n",
       "  array([0.94960064, 0.00958249, 0.01156618, 0.00634311, 0.00951801,\n",
       "         0.01338953], dtype=float32),\n",
       "  array([0.03465849, 0.01497056, 0.00814683, 0.00780537, 0.00641557,\n",
       "         0.9280032 ], dtype=float32),\n",
       "  array([0.05450092, 0.01200268, 0.02162213, 0.83817583, 0.04967166,\n",
       "         0.02402662], dtype=float32),\n",
       "  array([0.37783125, 0.02508148, 0.01505403, 0.01044672, 0.00679793,\n",
       "         0.5647886 ], dtype=float32),\n",
       "  array([0.05582853, 0.01347079, 0.01736503, 0.847984  , 0.03685846,\n",
       "         0.02849318], dtype=float32),\n",
       "  array([0.21755421, 0.02067884, 0.03357228, 0.62404466, 0.0653751 ,\n",
       "         0.03877491], dtype=float32),\n",
       "  array([0.03072158, 0.02288199, 0.00764036, 0.00623372, 0.00530691,\n",
       "         0.92721546], dtype=float32),\n",
       "  array([0.3139644 , 0.02393446, 0.02691051, 0.00760638, 0.00603784,\n",
       "         0.62154645], dtype=float32),\n",
       "  array([0.03150717, 0.01697797, 0.03558566, 0.04045807, 0.8564331 ,\n",
       "         0.01903807], dtype=float32),\n",
       "  array([0.02146824, 0.8664996 , 0.05672775, 0.00829467, 0.01783135,\n",
       "         0.02917829], dtype=float32),\n",
       "  array([0.9474079 , 0.00408632, 0.00796232, 0.01122848, 0.00556079,\n",
       "         0.02375424], dtype=float32),\n",
       "  array([0.17639898, 0.01786257, 0.02971768, 0.02000813, 0.01090533,\n",
       "         0.7451073 ], dtype=float32),\n",
       "  array([0.11390159, 0.026195  , 0.01598342, 0.0211849 , 0.0118961 ,\n",
       "         0.810839  ], dtype=float32),\n",
       "  array([0.9606057 , 0.00478697, 0.00767566, 0.00953022, 0.0067895 ,\n",
       "         0.01061189], dtype=float32),\n",
       "  array([0.9569788 , 0.0049774 , 0.00692122, 0.01126613, 0.00824028,\n",
       "         0.0116162 ], dtype=float32),\n",
       "  array([0.94273067, 0.00684879, 0.01153849, 0.00410873, 0.00475295,\n",
       "         0.03002029], dtype=float32),\n",
       "  array([0.16688669, 0.02360463, 0.25474766, 0.11941198, 0.42159364,\n",
       "         0.01375551], dtype=float32),\n",
       "  array([0.03549367, 0.52588385, 0.33868983, 0.01068396, 0.01656423,\n",
       "         0.0726845 ], dtype=float32),\n",
       "  array([0.03656941, 0.01907715, 0.00860689, 0.00523654, 0.00485962,\n",
       "         0.92565036], dtype=float32),\n",
       "  array([0.03166559, 0.10921934, 0.74358577, 0.02808783, 0.0640618 ,\n",
       "         0.0233797 ], dtype=float32),\n",
       "  array([0.05035608, 0.01546855, 0.01901975, 0.82537174, 0.04648737,\n",
       "         0.0432965 ], dtype=float32),\n",
       "  array([0.03119166, 0.8559021 , 0.03858505, 0.00674111, 0.00785121,\n",
       "         0.05972888], dtype=float32),\n",
       "  array([0.04526783, 0.012334  , 0.02130083, 0.8521578 , 0.04432847,\n",
       "         0.024611  ], dtype=float32),\n",
       "  array([0.9661619 , 0.00399672, 0.00642265, 0.00720825, 0.00517873,\n",
       "         0.01103176], dtype=float32),\n",
       "  array([0.02618414, 0.01808293, 0.00777678, 0.0070082 , 0.0055712 ,\n",
       "         0.9353767 ], dtype=float32),\n",
       "  array([0.10128598, 0.01364885, 0.01768905, 0.01173931, 0.00803499,\n",
       "         0.8476019 ], dtype=float32),\n",
       "  array([0.0315773 , 0.8637559 , 0.0454846 , 0.00720533, 0.01013771,\n",
       "         0.04183916], dtype=float32),\n",
       "  array([0.95890564, 0.00627071, 0.00878098, 0.00623482, 0.00711911,\n",
       "         0.01268874], dtype=float32),\n",
       "  array([0.96566963, 0.0039408 , 0.00718232, 0.00653656, 0.00514659,\n",
       "         0.01152394], dtype=float32),\n",
       "  array([0.11293579, 0.01218814, 0.02444199, 0.7831869 , 0.0463308 ,\n",
       "         0.02091636], dtype=float32),\n",
       "  array([0.08790189, 0.01368892, 0.01396988, 0.00778697, 0.00656431,\n",
       "         0.8700881 ], dtype=float32),\n",
       "  array([0.03530362, 0.01578684, 0.00878007, 0.00966674, 0.00782124,\n",
       "         0.92264146], dtype=float32),\n",
       "  array([0.06586191, 0.027376  , 0.0147348 , 0.01319686, 0.00871038,\n",
       "         0.87012005], dtype=float32),\n",
       "  array([0.94195867, 0.00516911, 0.00884337, 0.01223279, 0.00839542,\n",
       "         0.02340068], dtype=float32),\n",
       "  array([0.09307526, 0.02034025, 0.02140346, 0.00924076, 0.00725465,\n",
       "         0.8486856 ], dtype=float32),\n",
       "  array([0.03720394, 0.01453566, 0.00774306, 0.00929943, 0.0067985 ,\n",
       "         0.9244194 ], dtype=float32),\n",
       "  array([0.95561725, 0.006678  , 0.01012865, 0.00454047, 0.00525578,\n",
       "         0.01777994], dtype=float32),\n",
       "  array([0.12542713, 0.01378244, 0.02094103, 0.0559501 , 0.02303247,\n",
       "         0.76086676], dtype=float32),\n",
       "  array([0.0798225 , 0.68178266, 0.18146685, 0.01117213, 0.02330372,\n",
       "         0.02245214], dtype=float32),\n",
       "  array([0.95531523, 0.00515613, 0.01109559, 0.01075999, 0.01018872,\n",
       "         0.00748438], dtype=float32),\n",
       "  array([0.02175538, 0.02413519, 0.00833071, 0.00765682, 0.00621381,\n",
       "         0.9319081 ], dtype=float32),\n",
       "  array([0.22750844, 0.02428181, 0.01769663, 0.58406466, 0.0340111 ,\n",
       "         0.11243738], dtype=float32),\n",
       "  array([0.3154634 , 0.0270353 , 0.01603981, 0.00710743, 0.00572095,\n",
       "         0.6286331 ], dtype=float32),\n",
       "  array([0.04086678, 0.0161429 , 0.00843388, 0.00728843, 0.00578146,\n",
       "         0.92148656], dtype=float32),\n",
       "  array([0.9659024 , 0.00462435, 0.00696576, 0.00578283, 0.00492591,\n",
       "         0.01179888], dtype=float32),\n",
       "  array([0.10376053, 0.01366317, 0.01121546, 0.0077195 , 0.0059855 ,\n",
       "         0.8576558 ], dtype=float32),\n",
       "  array([0.06206311, 0.0639849 , 0.03485331, 0.01993138, 0.01525887,\n",
       "         0.80390847], dtype=float32),\n",
       "  array([0.33010826, 0.05093186, 0.03361729, 0.01175017, 0.0116975 ,\n",
       "         0.56189495], dtype=float32),\n",
       "  array([0.96046996, 0.00551975, 0.00847967, 0.00653918, 0.00780213,\n",
       "         0.01118931], dtype=float32),\n",
       "  array([0.95616657, 0.00485952, 0.00761432, 0.01047277, 0.01012332,\n",
       "         0.0107635 ], dtype=float32),\n",
       "  array([0.9478997 , 0.00416831, 0.0072961 , 0.02376311, 0.00872697,\n",
       "         0.00814588], dtype=float32),\n",
       "  array([0.05951454, 0.0498574 , 0.01277991, 0.01018203, 0.00833549,\n",
       "         0.85933065], dtype=float32),\n",
       "  array([0.04435702, 0.802329  , 0.05509654, 0.00816569, 0.01002218,\n",
       "         0.08002958], dtype=float32),\n",
       "  array([0.01971369, 0.85537046, 0.06632944, 0.00654145, 0.00893775,\n",
       "         0.04310723], dtype=float32),\n",
       "  array([0.0319002 , 0.12434626, 0.7375182 , 0.02667138, 0.05873377,\n",
       "         0.02083014], dtype=float32),\n",
       "  array([0.04269187, 0.01289766, 0.02083527, 0.8480998 , 0.04491802,\n",
       "         0.03055743], dtype=float32),\n",
       "  array([0.03712524, 0.01621743, 0.04264579, 0.20394304, 0.6800141 ,\n",
       "         0.02005441], dtype=float32),\n",
       "  array([0.94363844, 0.00435333, 0.01209138, 0.01850004, 0.01051219,\n",
       "         0.01090451], dtype=float32),\n",
       "  array([0.9544928 , 0.00431222, 0.0102991 , 0.01421454, 0.01021295,\n",
       "         0.00646837], dtype=float32),\n",
       "  array([0.22403035, 0.01493809, 0.01430769, 0.01032223, 0.00597005,\n",
       "         0.7304316 ], dtype=float32),\n",
       "  array([0.96110255, 0.0048745 , 0.0074514 , 0.0094509 , 0.00743139,\n",
       "         0.00968917], dtype=float32),\n",
       "  array([0.9619832 , 0.00480275, 0.00732069, 0.00942197, 0.0078821 ,\n",
       "         0.00858921], dtype=float32),\n",
       "  array([0.01900282, 0.8866704 , 0.0428436 , 0.00683207, 0.0082106 ,\n",
       "         0.03644043], dtype=float32),\n",
       "  array([0.22561562, 0.03285812, 0.01341232, 0.01398562, 0.00703892,\n",
       "         0.70708936], dtype=float32),\n",
       "  array([0.04727616, 0.01412387, 0.01138143, 0.02125082, 0.01195028,\n",
       "         0.89401746], dtype=float32),\n",
       "  array([0.04288256, 0.02605835, 0.04450529, 0.10622051, 0.760368  ,\n",
       "         0.01996532], dtype=float32),\n",
       "  array([0.35219648, 0.01110123, 0.01507947, 0.02444668, 0.01172417,\n",
       "         0.585452  ], dtype=float32),\n",
       "  array([0.0491192 , 0.02499882, 0.02183191, 0.01664078, 0.01074669,\n",
       "         0.87666255], dtype=float32),\n",
       "  array([0.9577613 , 0.00366207, 0.00774482, 0.01133255, 0.00766801,\n",
       "         0.01183129], dtype=float32),\n",
       "  array([0.9564493 , 0.00502646, 0.01270495, 0.01021193, 0.00901314,\n",
       "         0.00659436], dtype=float32),\n",
       "  array([0.92765766, 0.0059484 , 0.01446435, 0.03075897, 0.01356951,\n",
       "         0.00760112], dtype=float32),\n",
       "  array([0.08252241, 0.01461211, 0.01849183, 0.80589485, 0.04313243,\n",
       "         0.03534632], dtype=float32),\n",
       "  array([0.9659314 , 0.00460715, 0.00704414, 0.00669677, 0.00543833,\n",
       "         0.01028218], dtype=float32),\n",
       "  array([0.05838117, 0.03605021, 0.01518019, 0.00604797, 0.00504303,\n",
       "         0.8792974 ], dtype=float32),\n",
       "  array([0.9641876 , 0.00372741, 0.00750467, 0.01091678, 0.00696462,\n",
       "         0.00669888], dtype=float32),\n",
       "  array([0.05392026, 0.01233441, 0.00862972, 0.01306439, 0.00926691,\n",
       "         0.90278435], dtype=float32),\n",
       "  array([0.94948685, 0.00416891, 0.00740205, 0.02118732, 0.00854346,\n",
       "         0.00921127], dtype=float32),\n",
       "  array([0.11888863, 0.5122024 , 0.2693292 , 0.01259014, 0.03416285,\n",
       "         0.05282677], dtype=float32),\n",
       "  array([0.02381083, 0.0186343 , 0.09145766, 0.08054434, 0.7741437 ,\n",
       "         0.01140916], dtype=float32),\n",
       "  array([0.12454603, 0.6471648 , 0.16153039, 0.00899447, 0.0129307 ,\n",
       "         0.04483361], dtype=float32),\n",
       "  array([0.02757782, 0.01909437, 0.00748719, 0.00766787, 0.00588188,\n",
       "         0.9322909 ], dtype=float32),\n",
       "  array([0.02047099, 0.01222792, 0.03321256, 0.05617025, 0.86498773,\n",
       "         0.01293058], dtype=float32),\n",
       "  array([0.03371726, 0.01633158, 0.00800506, 0.00863133, 0.00669125,\n",
       "         0.9266235 ], dtype=float32),\n",
       "  array([0.9520099 , 0.00454549, 0.00741759, 0.01148337, 0.00668653,\n",
       "         0.01785718], dtype=float32),\n",
       "  array([0.09869954, 0.0239441 , 0.14504275, 0.20844033, 0.5074869 ,\n",
       "         0.0163864 ], dtype=float32),\n",
       "  array([0.9405496 , 0.00552858, 0.01680775, 0.00709363, 0.00674918,\n",
       "         0.0232711 ], dtype=float32),\n",
       "  array([0.02132649, 0.83959794, 0.08838685, 0.00781183, 0.01007656,\n",
       "         0.0328003 ], dtype=float32),\n",
       "  array([0.9628699 , 0.00458221, 0.00851436, 0.00580385, 0.00460267,\n",
       "         0.01362698], dtype=float32),\n",
       "  array([0.9603303 , 0.00541996, 0.00726324, 0.0068346 , 0.00583571,\n",
       "         0.01431619], dtype=float32),\n",
       "  array([0.957477  , 0.00604039, 0.0134393 , 0.00610247, 0.00725217,\n",
       "         0.0096887 ], dtype=float32),\n",
       "  array([0.13474427, 0.02070876, 0.01467324, 0.01101055, 0.00866979,\n",
       "         0.8101934 ], dtype=float32),\n",
       "  array([0.1464985 , 0.01426751, 0.01070959, 0.01289745, 0.00773961,\n",
       "         0.8078874 ], dtype=float32),\n",
       "  array([0.08205266, 0.01277907, 0.01065173, 0.01834554, 0.011296  ,\n",
       "         0.864875  ], dtype=float32),\n",
       "  array([0.02862644, 0.01710088, 0.0072833 , 0.00822978, 0.00681368,\n",
       "         0.93194586], dtype=float32),\n",
       "  array([0.05655059, 0.23092258, 0.21261312, 0.03025997, 0.04971609,\n",
       "         0.4199376 ], dtype=float32),\n",
       "  array([0.16021712, 0.49172205, 0.28244066, 0.00968594, 0.01992815,\n",
       "         0.03600609], dtype=float32),\n",
       "  array([0.03490868, 0.01806028, 0.00822462, 0.01115961, 0.00697482,\n",
       "         0.920672  ], dtype=float32),\n",
       "  array([0.31978062, 0.0467458 , 0.3856124 , 0.03250379, 0.14087667,\n",
       "         0.07448066], dtype=float32),\n",
       "  array([0.95867294, 0.00631849, 0.00676391, 0.00634722, 0.00643895,\n",
       "         0.01545844], dtype=float32),\n",
       "  array([0.3294696 , 0.01912982, 0.05966859, 0.10221136, 0.06430964,\n",
       "         0.42521098], dtype=float32),\n",
       "  array([0.8767628 , 0.01727054, 0.05403949, 0.00800491, 0.01729904,\n",
       "         0.02662317], dtype=float32),\n",
       "  array([0.03054621, 0.02459805, 0.00875384, 0.00648561, 0.00574718,\n",
       "         0.92386913], dtype=float32),\n",
       "  array([0.04127058, 0.05811716, 0.01623299, 0.02484849, 0.01043162,\n",
       "         0.84909916], dtype=float32),\n",
       "  array([0.02680168, 0.12156996, 0.72843   , 0.02858797, 0.0624338 ,\n",
       "         0.0321767 ], dtype=float32),\n",
       "  array([0.9598343 , 0.00407309, 0.00798243, 0.01188844, 0.0074734 ,\n",
       "         0.00874826], dtype=float32),\n",
       "  array([0.4407081 , 0.03346314, 0.0288144 , 0.01435453, 0.01159775,\n",
       "         0.4710621 ], dtype=float32),\n",
       "  array([0.02968948, 0.02217986, 0.01220652, 0.00583264, 0.00520242,\n",
       "         0.9248891 ], dtype=float32),\n",
       "  array([0.01182909, 0.8147208 , 0.09872644, 0.00938234, 0.01192621,\n",
       "         0.05341514], dtype=float32),\n",
       "  array([0.9551728 , 0.00518249, 0.01091272, 0.01097478, 0.01063996,\n",
       "         0.00711725], dtype=float32),\n",
       "  array([0.07976215, 0.02150744, 0.01608572, 0.773968  , 0.03755742,\n",
       "         0.07111923], dtype=float32),\n",
       "  array([0.28284648, 0.01184235, 0.01445612, 0.01939979, 0.00854686,\n",
       "         0.6629084 ], dtype=float32),\n",
       "  array([0.94579357, 0.00445333, 0.00794826, 0.01684805, 0.00766403,\n",
       "         0.01729285], dtype=float32),\n",
       "  array([0.96346116, 0.00477994, 0.00830129, 0.00747435, 0.00752343,\n",
       "         0.00845974], dtype=float32),\n",
       "  array([0.04730706, 0.01810358, 0.01931016, 0.00887844, 0.00919354,\n",
       "         0.89720714], dtype=float32),\n",
       "  array([0.10110187, 0.06520671, 0.7168741 , 0.02362737, 0.06966626,\n",
       "         0.0235237 ], dtype=float32),\n",
       "  array([0.22199422, 0.03373555, 0.02671892, 0.00947479, 0.00875247,\n",
       "         0.6993241 ], dtype=float32),\n",
       "  array([0.36407933, 0.01468891, 0.01943354, 0.01860583, 0.00882317,\n",
       "         0.57436925], dtype=float32),\n",
       "  array([0.95692474, 0.0072181 , 0.00806191, 0.00717435, 0.00767326,\n",
       "         0.01294776], dtype=float32),\n",
       "  array([0.04241847, 0.01519081, 0.02087492, 0.78988993, 0.08464757,\n",
       "         0.04697831], dtype=float32),\n",
       "  array([0.02632091, 0.01709853, 0.06875362, 0.08914916, 0.7862378 ,\n",
       "         0.01244003], dtype=float32),\n",
       "  array([0.10035791, 0.02486781, 0.01347972, 0.00833784, 0.00692962,\n",
       "         0.8460271 ], dtype=float32),\n",
       "  array([0.95542276, 0.00454352, 0.0110048 , 0.01147464, 0.00922798,\n",
       "         0.0083263 ], dtype=float32),\n",
       "  array([0.9639684 , 0.00419215, 0.0082738 , 0.00863903, 0.00725196,\n",
       "         0.00767466], dtype=float32),\n",
       "  array([0.05157433, 0.0110638 , 0.02388052, 0.8367047 , 0.05989788,\n",
       "         0.01687882], dtype=float32),\n",
       "  array([0.9470412 , 0.00538162, 0.00627216, 0.01202929, 0.0076956 ,\n",
       "         0.02158013], dtype=float32),\n",
       "  array([0.03467724, 0.01848459, 0.0089884 , 0.00720992, 0.00671318,\n",
       "         0.92392665], dtype=float32),\n",
       "  array([0.03037949, 0.7894109 , 0.12223433, 0.00637054, 0.01220015,\n",
       "         0.03940452], dtype=float32),\n",
       "  array([0.01517216, 0.86080056, 0.05836367, 0.00892154, 0.01091969,\n",
       "         0.04582229], dtype=float32),\n",
       "  array([0.95448405, 0.00511464, 0.00853624, 0.00611888, 0.0060497 ,\n",
       "         0.01969638], dtype=float32),\n",
       "  array([0.01582854, 0.85916406, 0.0757681 , 0.00735749, 0.01394407,\n",
       "         0.02793769], dtype=float32),\n",
       "  array([0.03519807, 0.01488624, 0.02691758, 0.8069467 , 0.08604095,\n",
       "         0.03001044], dtype=float32),\n",
       "  array([0.959946  , 0.00597775, 0.00874372, 0.0080654 , 0.00786845,\n",
       "         0.00939872], dtype=float32),\n",
       "  array([0.03429905, 0.01705166, 0.00925067, 0.00668112, 0.00540327,\n",
       "         0.9273142 ], dtype=float32),\n",
       "  array([0.05862483, 0.64604586, 0.21816449, 0.00856762, 0.01734768,\n",
       "         0.05124947], dtype=float32),\n",
       "  array([0.81869024, 0.01549364, 0.01348121, 0.00865564, 0.01064764,\n",
       "         0.13303152], dtype=float32),\n",
       "  array([0.08237644, 0.09327522, 0.7135995 , 0.01833858, 0.03897905,\n",
       "         0.05343128], dtype=float32),\n",
       "  array([0.02869591, 0.01232906, 0.02303248, 0.8250407 , 0.09007944,\n",
       "         0.02082245], dtype=float32),\n",
       "  array([0.05669758, 0.01584859, 0.01049364, 0.0157254 , 0.01063616,\n",
       "         0.8905986 ], dtype=float32),\n",
       "  array([0.2532844 , 0.0179923 , 0.01283734, 0.01314597, 0.00837644,\n",
       "         0.69436353], dtype=float32),\n",
       "  array([0.0251616 , 0.01716123, 0.01131092, 0.00931459, 0.00791335,\n",
       "         0.9291383 ], dtype=float32),\n",
       "  array([0.8907749 , 0.00808172, 0.0289041 , 0.02297244, 0.02883255,\n",
       "         0.02043426], dtype=float32),\n",
       "  array([0.9573007 , 0.00468114, 0.01002505, 0.01127302, 0.00823168,\n",
       "         0.00848845], dtype=float32),\n",
       "  array([0.20249704, 0.02584955, 0.02752754, 0.02841359, 0.01285215,\n",
       "         0.70286006], dtype=float32),\n",
       "  array([0.8191057 , 0.00957726, 0.01541393, 0.01178565, 0.0068222 ,\n",
       "         0.13729529], dtype=float32),\n",
       "  array([0.02802496, 0.0178562 , 0.00748405, 0.00919043, 0.00616363,\n",
       "         0.93128073], dtype=float32),\n",
       "  array([0.02701225, 0.01783707, 0.05517636, 0.05080874, 0.83609223,\n",
       "         0.01307335], dtype=float32),\n",
       "  array([0.946082  , 0.00455731, 0.00703327, 0.01756431, 0.00704451,\n",
       "         0.01771864], dtype=float32),\n",
       "  array([0.03633898, 0.01356454, 0.02415235, 0.8401246 , 0.06048219,\n",
       "         0.02533728], dtype=float32),\n",
       "  array([0.0430665 , 0.01226543, 0.02064238, 0.8301291 , 0.06441793,\n",
       "         0.02947873], dtype=float32),\n",
       "  array([0.10376053, 0.01366317, 0.01121546, 0.0077195 , 0.0059855 ,\n",
       "         0.8576558 ], dtype=float32),\n",
       "  array([0.03556319, 0.01770503, 0.00866548, 0.00912756, 0.00663662,\n",
       "         0.9223021 ], dtype=float32),\n",
       "  array([0.2736879 , 0.03614969, 0.5490576 , 0.04326833, 0.08197753,\n",
       "         0.015859  ], dtype=float32),\n",
       "  array([0.06696394, 0.08129646, 0.7492834 , 0.02169146, 0.05208644,\n",
       "         0.02867836], dtype=float32),\n",
       "  array([0.02350675, 0.83272374, 0.09445181, 0.00989818, 0.02008351,\n",
       "         0.01933613], dtype=float32),\n",
       "  array([0.02839471, 0.01955133, 0.00686997, 0.00620677, 0.00468154,\n",
       "         0.93429565], dtype=float32),\n",
       "  array([0.8115988 , 0.01091687, 0.02948909, 0.0980519 , 0.03292447,\n",
       "         0.01701889], dtype=float32),\n",
       "  array([0.95609486, 0.00363186, 0.0074572 , 0.01561508, 0.00782441,\n",
       "         0.00937662], dtype=float32),\n",
       "  array([0.0379894 , 0.01404141, 0.00880854, 0.00927964, 0.0070887 ,\n",
       "         0.9227924 ], dtype=float32),\n",
       "  array([0.95673984, 0.00462736, 0.00671998, 0.00913372, 0.00657662,\n",
       "         0.01620249], dtype=float32),\n",
       "  array([0.05225283, 0.01288042, 0.0188514 , 0.8482142 , 0.04242208,\n",
       "         0.02537901], dtype=float32),\n",
       "  array([0.0511005 , 0.07095405, 0.01490301, 0.00806034, 0.00682893,\n",
       "         0.8481532 ], dtype=float32),\n",
       "  array([0.02544462, 0.01577596, 0.04208155, 0.04908515, 0.8541523 ,\n",
       "         0.0134604 ], dtype=float32),\n",
       "  array([0.964473  , 0.00379474, 0.00718033, 0.00854515, 0.00681422,\n",
       "         0.00919269], dtype=float32),\n",
       "  array([0.9643217 , 0.00445281, 0.00831087, 0.0088037 , 0.00717485,\n",
       "         0.00693613], dtype=float32),\n",
       "  array([0.02582122, 0.37221172, 0.5030911 , 0.01854074, 0.04843746,\n",
       "         0.03189781], dtype=float32),\n",
       "  array([0.04294765, 0.76252544, 0.1335502 , 0.01265272, 0.02645317,\n",
       "         0.02187078], dtype=float32),\n",
       "  array([0.01412327, 0.85246944, 0.08724703, 0.00860421, 0.01488451,\n",
       "         0.02267153], dtype=float32),\n",
       "  array([0.9509547 , 0.00419112, 0.0095494 , 0.01871113, 0.01057341,\n",
       "         0.00602013], dtype=float32),\n",
       "  array([0.01512088, 0.8400126 , 0.09920109, 0.00779922, 0.01220766,\n",
       "         0.0256586 ], dtype=float32),\n",
       "  array([0.0208843 , 0.01553505, 0.0458962 , 0.07451004, 0.83038914,\n",
       "         0.01278524], dtype=float32),\n",
       "  array([0.15036814, 0.02194863, 0.03215465, 0.02209502, 0.01466323,\n",
       "         0.7587703 ], dtype=float32),\n",
       "  array([0.03906356, 0.01389718, 0.02036517, 0.84808713, 0.05601082,\n",
       "         0.02257615], dtype=float32),\n",
       "  array([0.03740057, 0.11336125, 0.74913377, 0.02316587, 0.05307607,\n",
       "         0.02386253], dtype=float32),\n",
       "  array([0.03740057, 0.11336125, 0.74913377, 0.02316587, 0.05307607,\n",
       "         0.02386253], dtype=float32),\n",
       "  array([0.03986778, 0.01498801, 0.00744206, 0.00705152, 0.00542328,\n",
       "         0.92522734], dtype=float32),\n",
       "  array([0.03089863, 0.01817655, 0.0687227 , 0.0879683 , 0.78333205,\n",
       "         0.01090182], dtype=float32),\n",
       "  array([0.02859286, 0.0214597 , 0.0103379 , 0.01133215, 0.00833387,\n",
       "         0.9199435 ], dtype=float32),\n",
       "  array([0.8649616 , 0.01322991, 0.01211766, 0.00970818, 0.00552412,\n",
       "         0.09445859], dtype=float32),\n",
       "  array([0.02847564, 0.02021258, 0.06832795, 0.04885461, 0.81757337,\n",
       "         0.01655587], dtype=float32),\n",
       "  array([0.02173545, 0.01332662, 0.0458866 , 0.05920947, 0.8477364 ,\n",
       "         0.0121054 ], dtype=float32),\n",
       "  array([0.8741723 , 0.01026539, 0.01898713, 0.00701749, 0.00753829,\n",
       "         0.08201939], dtype=float32),\n",
       "  array([0.0252845 , 0.01296703, 0.04821087, 0.06219203, 0.83893824,\n",
       "         0.01240737], dtype=float32),\n",
       "  array([0.95745754, 0.00516293, 0.0130326 , 0.00749579, 0.00824184,\n",
       "         0.00860931], dtype=float32),\n",
       "  array([0.9610213 , 0.00571246, 0.00988838, 0.00760006, 0.00771486,\n",
       "         0.00806296], dtype=float32),\n",
       "  array([0.95891196, 0.00653409, 0.00977981, 0.00685715, 0.00817174,\n",
       "         0.00974519], dtype=float32),\n",
       "  array([0.08343802, 0.01429306, 0.0138759 , 0.02721384, 0.01426214,\n",
       "         0.84691703], dtype=float32),\n",
       "  array([0.9489348 , 0.00632401, 0.00946447, 0.0086945 , 0.01052452,\n",
       "         0.01605781], dtype=float32),\n",
       "  array([0.02283071, 0.0130704 , 0.03786263, 0.0492225 , 0.86513406,\n",
       "         0.01187963], dtype=float32),\n",
       "  array([0.06968288, 0.24376631, 0.58060074, 0.01641528, 0.05958988,\n",
       "         0.02994495], dtype=float32),\n",
       "  array([0.04221345, 0.01184058, 0.0252865 , 0.83190167, 0.07122919,\n",
       "         0.01752867], dtype=float32),\n",
       "  array([0.07170951, 0.0465888 , 0.13116513, 0.02567325, 0.01718082,\n",
       "         0.7076825 ], dtype=float32),\n",
       "  array([0.9406086 , 0.00666345, 0.02238847, 0.00726672, 0.01190905,\n",
       "         0.01116374], dtype=float32),\n",
       "  array([0.9576335 , 0.00447207, 0.0075052 , 0.00622295, 0.00474448,\n",
       "         0.01942198], dtype=float32),\n",
       "  array([0.9584799 , 0.00462085, 0.01138354, 0.00663237, 0.00856443,\n",
       "         0.01031895], dtype=float32),\n",
       "  array([0.06976655, 0.0459675 , 0.04156284, 0.0133751 , 0.0121697 ,\n",
       "         0.8171583 ], dtype=float32),\n",
       "  array([0.9257062 , 0.00750878, 0.01345427, 0.00705053, 0.00915183,\n",
       "         0.03712841], dtype=float32),\n",
       "  array([0.16608374, 0.07703027, 0.6475463 , 0.01636549, 0.04262272,\n",
       "         0.05035148], dtype=float32),\n",
       "  array([0.9318107 , 0.00894154, 0.02968161, 0.00761202, 0.01180054,\n",
       "         0.01015364], dtype=float32),\n",
       "  array([0.95104223, 0.0052021 , 0.01359563, 0.00937682, 0.00979095,\n",
       "         0.01099226], dtype=float32),\n",
       "  array([0.04429229, 0.01356035, 0.02123368, 0.83082104, 0.06096368,\n",
       "         0.02912907], dtype=float32),\n",
       "  array([0.04165176, 0.06118584, 0.01252767, 0.00808601, 0.00719787,\n",
       "         0.86935085], dtype=float32),\n",
       "  array([0.55013674, 0.03673476, 0.11423745, 0.17610377, 0.07466305,\n",
       "         0.04812424], dtype=float32),\n",
       "  array([0.02624548, 0.13038361, 0.0199872 , 0.00781278, 0.00650658,\n",
       "         0.8090643 ], dtype=float32),\n",
       "  array([0.9516406 , 0.00764542, 0.01073705, 0.00769674, 0.00876208,\n",
       "         0.01351805], dtype=float32),\n",
       "  array([0.01929266, 0.02773104, 0.01160543, 0.00646063, 0.00596812,\n",
       "         0.9289421 ], dtype=float32),\n",
       "  array([0.07305375, 0.02530901, 0.0128873 , 0.00819046, 0.00679122,\n",
       "         0.87376827], dtype=float32),\n",
       "  array([0.0850412 , 0.01869709, 0.00978029, 0.00725389, 0.00600653,\n",
       "         0.873221  ], dtype=float32),\n",
       "  array([0.05636087, 0.01643405, 0.01100127, 0.00722015, 0.00546529,\n",
       "         0.9035184 ], dtype=float32),\n",
       "  array([0.9265413 , 0.00843308, 0.03311813, 0.00828886, 0.01290304,\n",
       "         0.01071549], dtype=float32),\n",
       "  array([0.0522277 , 0.47355992, 0.25335935, 0.03895703, 0.1438203 ,\n",
       "         0.03807577], dtype=float32),\n",
       "  array([0.30559066, 0.05798982, 0.02422098, 0.01092553, 0.01169802,\n",
       "         0.589575  ], dtype=float32),\n",
       "  array([0.0384382 , 0.012963  , 0.0244096 , 0.8332695 , 0.06785341,\n",
       "         0.02306633], dtype=float32),\n",
       "  array([0.96458864, 0.00421462, 0.00684462, 0.0087875 , 0.00538287,\n",
       "         0.01018173], dtype=float32),\n",
       "  array([0.27441546, 0.03657631, 0.02102326, 0.00668751, 0.00697809,\n",
       "         0.6543194 ], dtype=float32),\n",
       "  array([0.469845  , 0.02984481, 0.02892768, 0.01159274, 0.01393346,\n",
       "         0.4458562 ], dtype=float32),\n",
       "  array([0.0197742 , 0.8272166 , 0.0553808 , 0.00565705, 0.00883588,\n",
       "         0.08313544], dtype=float32),\n",
       "  array([0.02608391, 0.02198207, 0.00810765, 0.00733211, 0.00598213,\n",
       "         0.93051213], dtype=float32),\n",
       "  array([0.05238956, 0.01006335, 0.00836495, 0.01549508, 0.01050478,\n",
       "         0.90318227], dtype=float32),\n",
       "  array([0.05610311, 0.0260816 , 0.01049717, 0.01101838, 0.00773591,\n",
       "         0.8885639 ], dtype=float32),\n",
       "  array([0.9440418 , 0.00491028, 0.00783504, 0.0177241 , 0.0082786 ,\n",
       "         0.0172102 ], dtype=float32),\n",
       "  array([0.05306601, 0.051496  , 0.09998665, 0.0231826 , 0.01528984,\n",
       "         0.7569789 ], dtype=float32),\n",
       "  array([0.02655182, 0.02688727, 0.00777904, 0.00635282, 0.00505875,\n",
       "         0.9273703 ], dtype=float32),\n",
       "  array([0.06830176, 0.01401716, 0.01149748, 0.01346715, 0.01064828,\n",
       "         0.8820682 ], dtype=float32),\n",
       "  array([0.9625836 , 0.00395534, 0.00590635, 0.01163992, 0.00730453,\n",
       "         0.00861013], dtype=float32),\n",
       "  array([0.07437757, 0.02450706, 0.01354536, 0.00601219, 0.0044041 ,\n",
       "         0.87715375], dtype=float32),\n",
       "  array([0.95762   , 0.0044457 , 0.0083306 , 0.00949043, 0.00943384,\n",
       "         0.01067924], dtype=float32),\n",
       "  array([0.03767552, 0.09260803, 0.02457019, 0.010061  , 0.00865962,\n",
       "         0.8264257 ], dtype=float32),\n",
       "  array([0.95680034, 0.00446154, 0.01248548, 0.0075831 , 0.00964792,\n",
       "         0.00902154], dtype=float32),\n",
       "  array([0.05451666, 0.01678826, 0.04023422, 0.7800882 , 0.07572873,\n",
       "         0.03264394], dtype=float32),\n",
       "  array([0.9410006 , 0.00928898, 0.01694495, 0.00736219, 0.0069294 ,\n",
       "         0.01847376], dtype=float32),\n",
       "  array([0.9393417 , 0.00589075, 0.01040668, 0.01411491, 0.01163109,\n",
       "         0.01861493], dtype=float32),\n",
       "  array([0.02519063, 0.01528106, 0.03929258, 0.04898701, 0.8577952 ,\n",
       "         0.0134536 ], dtype=float32),\n",
       "  array([0.95432353, 0.00375727, 0.0067325 , 0.01471764, 0.00892124,\n",
       "         0.01154778], dtype=float32),\n",
       "  array([0.9498103 , 0.00622373, 0.00924169, 0.00686083, 0.00787664,\n",
       "         0.01998682], dtype=float32),\n",
       "  array([0.15904656, 0.08112202, 0.06487054, 0.02109601, 0.01324682,\n",
       "         0.660618  ], dtype=float32),\n",
       "  array([0.06472587, 0.01145657, 0.02273133, 0.8186485 , 0.05774809,\n",
       "         0.0246896 ], dtype=float32),\n",
       "  array([0.04025858, 0.01957857, 0.00960029, 0.00749921, 0.00621761,\n",
       "         0.9168458 ], dtype=float32),\n",
       "  array([0.02963989, 0.01886701, 0.04067546, 0.03914027, 0.8501464 ,\n",
       "         0.02153089], dtype=float32),\n",
       "  array([0.6113727 , 0.0466839 , 0.03023209, 0.00876311, 0.00596094,\n",
       "         0.29698727], dtype=float32),\n",
       "  array([0.08460338, 0.711634  , 0.10710146, 0.00954664, 0.01827807,\n",
       "         0.06883652], dtype=float32),\n",
       "  array([0.2612597 , 0.01671768, 0.01878171, 0.08105502, 0.02114737,\n",
       "         0.6010386 ], dtype=float32),\n",
       "  array([0.8641516 , 0.00939891, 0.07171391, 0.01581718, 0.01925459,\n",
       "         0.01966384], dtype=float32),\n",
       "  array([0.9600542 , 0.00626341, 0.0095512 , 0.00566943, 0.00692036,\n",
       "         0.01154143], dtype=float32),\n",
       "  array([0.05650402, 0.01331291, 0.02139195, 0.82394046, 0.04335432,\n",
       "         0.04149634], dtype=float32),\n",
       "  array([0.9633908 , 0.00446848, 0.007207  , 0.00829798, 0.00506807,\n",
       "         0.01156758], dtype=float32),\n",
       "  array([0.04046329, 0.01950139, 0.03572601, 0.12146109, 0.76306146,\n",
       "         0.01978664], dtype=float32),\n",
       "  array([0.08831475, 0.262479  , 0.15056539, 0.00953821, 0.01975056,\n",
       "         0.4693521 ], dtype=float32),\n",
       "  array([0.6794378 , 0.02627165, 0.21544081, 0.0230465 , 0.04168042,\n",
       "         0.0141228 ], dtype=float32),\n",
       "  array([0.32871285, 0.01212445, 0.01414678, 0.01406825, 0.00882557,\n",
       "         0.62212217], dtype=float32),\n",
       "  array([0.0432651 , 0.1493293 , 0.6895287 , 0.01991664, 0.04941534,\n",
       "         0.04854495], dtype=float32),\n",
       "  array([0.6627549 , 0.12251496, 0.06070652, 0.02505966, 0.04404435,\n",
       "         0.08491962], dtype=float32),\n",
       "  array([0.8334497 , 0.00972958, 0.01030691, 0.01264133, 0.00929341,\n",
       "         0.12457904], dtype=float32),\n",
       "  array([0.94365436, 0.00423142, 0.00725303, 0.02507933, 0.00879849,\n",
       "         0.01098335], dtype=float32),\n",
       "  array([0.26378283, 0.01723001, 0.02868426, 0.6190183 , 0.03661418,\n",
       "         0.03467037], dtype=float32),\n",
       "  array([0.8384117 , 0.0115557 , 0.0707557 , 0.01708439, 0.04029967,\n",
       "         0.02189285], dtype=float32),\n",
       "  array([0.9236011 , 0.00512231, 0.00856046, 0.03207332, 0.01198444,\n",
       "         0.01865837], dtype=float32),\n",
       "  array([0.95051783, 0.00710103, 0.01768886, 0.00752704, 0.00931372,\n",
       "         0.00785151], dtype=float32),\n",
       "  array([0.953584  , 0.00410246, 0.00863158, 0.01376525, 0.01061634,\n",
       "         0.00930041], dtype=float32),\n",
       "  array([0.03193894, 0.01677261, 0.00786762, 0.00765588, 0.00613898,\n",
       "         0.9296259 ], dtype=float32),\n",
       "  array([0.9628933 , 0.00448429, 0.00723126, 0.00815424, 0.00757959,\n",
       "         0.00965727], dtype=float32),\n",
       "  array([0.04578691, 0.09758019, 0.75902873, 0.02240488, 0.05641685,\n",
       "         0.01878236], dtype=float32),\n",
       "  array([0.92188656, 0.00566525, 0.00967512, 0.03293427, 0.01412231,\n",
       "         0.0157165 ], dtype=float32),\n",
       "  array([0.81992185, 0.00816629, 0.01585959, 0.11635297, 0.02078015,\n",
       "         0.0189192 ], dtype=float32),\n",
       "  array([0.0386998 , 0.10257273, 0.7591288 , 0.02195942, 0.05718828,\n",
       "         0.02045097], dtype=float32),\n",
       "  array([0.03214218, 0.02309091, 0.02969041, 0.01293526, 0.00997704,\n",
       "         0.89216423], dtype=float32),\n",
       "  array([0.0318989 , 0.01560476, 0.04078111, 0.74638265, 0.14602569,\n",
       "         0.01930695], dtype=float32),\n",
       "  array([0.93689007, 0.0091341 , 0.02705999, 0.00778592, 0.00852794,\n",
       "         0.010602  ], dtype=float32),\n",
       "  array([0.03869588, 0.02027502, 0.0146081 , 0.00643591, 0.00589698,\n",
       "         0.9140881 ], dtype=float32),\n",
       "  array([0.9643217 , 0.00445281, 0.00831087, 0.0088037 , 0.00717485,\n",
       "         0.00693613], dtype=float32),\n",
       "  array([0.05913843, 0.0732386 , 0.72887325, 0.0271435 , 0.08653346,\n",
       "         0.02507277], dtype=float32),\n",
       "  array([0.02810464, 0.40473345, 0.48847815, 0.0190015 , 0.03854364,\n",
       "         0.02113861], dtype=float32),\n",
       "  array([0.02613853, 0.7516529 , 0.15665941, 0.00875756, 0.01907908,\n",
       "         0.03771245], dtype=float32),\n",
       "  array([0.05223644, 0.0723883 , 0.01810585, 0.00607545, 0.00501291,\n",
       "         0.8461811 ], dtype=float32),\n",
       "  array([0.9521168 , 0.00576584, 0.01836434, 0.00555728, 0.00724716,\n",
       "         0.01094851], dtype=float32),\n",
       "  array([0.95707977, 0.00522404, 0.0063104 , 0.00639159, 0.00558685,\n",
       "         0.01940734], dtype=float32),\n",
       "  array([0.9603745 , 0.00442831, 0.00794017, 0.00642532, 0.0063069 ,\n",
       "         0.01452493], dtype=float32),\n",
       "  array([0.13786651, 0.01429346, 0.00989339, 0.00753419, 0.00605244,\n",
       "         0.82435995], dtype=float32),\n",
       "  array([0.9588551 , 0.0038922 , 0.00846222, 0.00987575, 0.007789  ,\n",
       "         0.01112575], dtype=float32),\n",
       "  array([0.03232352, 0.03399613, 0.00901816, 0.00713022, 0.00566041,\n",
       "         0.91187155], dtype=float32),\n",
       "  array([0.02909674, 0.8495163 , 0.06970458, 0.00915846, 0.01466597,\n",
       "         0.02785788], dtype=float32),\n",
       "  array([0.02141815, 0.01223389, 0.0409705 , 0.10009272, 0.8144565 ,\n",
       "         0.0108282 ], dtype=float32),\n",
       "  array([0.05050411, 0.09887715, 0.73348516, 0.03135357, 0.06999286,\n",
       "         0.01578716], dtype=float32),\n",
       "  array([0.9632584 , 0.00433559, 0.01001573, 0.00669111, 0.00731767,\n",
       "         0.00838147], dtype=float32),\n",
       "  array([0.05667662, 0.01292176, 0.01852218, 0.8446241 , 0.04392572,\n",
       "         0.0233296 ], dtype=float32),\n",
       "  array([0.9219723 , 0.00915358, 0.02253762, 0.00748752, 0.01498151,\n",
       "         0.02386747], dtype=float32),\n",
       "  array([0.02904194, 0.85765207, 0.05249685, 0.00758432, 0.01234799,\n",
       "         0.04087688], dtype=float32),\n",
       "  array([0.03492824, 0.01504853, 0.00803016, 0.01151537, 0.00823287,\n",
       "         0.92224485], dtype=float32),\n",
       "  array([0.03590753, 0.0129104 , 0.0196387 , 0.843705  , 0.06104662,\n",
       "         0.02679177], dtype=float32),\n",
       "  array([0.01089845, 0.8319565 , 0.10658559, 0.0085308 , 0.01398917,\n",
       "         0.02803946], dtype=float32),\n",
       "  array([0.05717268, 0.01628459, 0.01402434, 0.0189873 , 0.01304755,\n",
       "         0.88048357], dtype=float32),\n",
       "  array([0.03602462, 0.02398411, 0.00896874, 0.00769235, 0.00636438,\n",
       "         0.91696584], dtype=float32),\n",
       "  array([0.94758534, 0.00570871, 0.0103113 , 0.0134086 , 0.01381807,\n",
       "         0.00916798], dtype=float32),\n",
       "  array([0.06750154, 0.7144401 , 0.13497135, 0.00809351, 0.01137761,\n",
       "         0.06361591], dtype=float32),\n",
       "  array([0.02764645, 0.0148461 , 0.00719845, 0.00748641, 0.0063181 ,\n",
       "         0.9365045 ], dtype=float32),\n",
       "  array([0.02748339, 0.82670695, 0.09282134, 0.00631882, 0.01278549,\n",
       "         0.03388399], dtype=float32),\n",
       "  array([0.05617532, 0.01048343, 0.00850481, 0.01425534, 0.00933252,\n",
       "         0.9012486 ], dtype=float32),\n",
       "  array([0.05349478, 0.01355186, 0.01830247, 0.8322473 , 0.04863496,\n",
       "         0.03376866], dtype=float32),\n",
       "  array([0.04490829, 0.01455473, 0.00878766, 0.00793714, 0.00673763,\n",
       "         0.9170745 ], dtype=float32),\n",
       "  array([0.03679323, 0.02757187, 0.04699584, 0.07215991, 0.79651654,\n",
       "         0.01996252], dtype=float32),\n",
       "  array([0.03175906, 0.0142036 , 0.0516457 , 0.6333615 , 0.24802327,\n",
       "         0.02100685], dtype=float32),\n",
       "  array([0.16316152, 0.17716087, 0.04142722, 0.01789912, 0.02055311,\n",
       "         0.5797981 ], dtype=float32),\n",
       "  array([0.08216445, 0.11850438, 0.6881476 , 0.01430167, 0.04204137,\n",
       "         0.05484051], dtype=float32),\n",
       "  array([0.09748521, 0.1001121 , 0.67308205, 0.01992144, 0.07436763,\n",
       "         0.03503161], dtype=float32),\n",
       "  array([0.9044626 , 0.00560684, 0.00901024, 0.01582825, 0.00749664,\n",
       "         0.05759543], dtype=float32),\n",
       "  array([0.04125325, 0.1881505 , 0.67553777, 0.01609922, 0.038763  ,\n",
       "         0.04019629], dtype=float32),\n",
       "  array([0.9612184 , 0.00489343, 0.00968042, 0.00782714, 0.00798929,\n",
       "         0.00839125], dtype=float32),\n",
       "  array([0.03869588, 0.02027502, 0.0146081 , 0.00643591, 0.00589698,\n",
       "         0.9140881 ], dtype=float32),\n",
       "  array([0.934277  , 0.00486204, 0.0110453 , 0.02485638, 0.01535888,\n",
       "         0.00960033], dtype=float32),\n",
       "  array([0.02461149, 0.01556261, 0.05253978, 0.07997342, 0.8182997 ,\n",
       "         0.00901295], dtype=float32),\n",
       "  array([0.03774432, 0.01293353, 0.01003094, 0.01145361, 0.00818369,\n",
       "         0.9196539 ], dtype=float32),\n",
       "  array([0.03552556, 0.02439485, 0.01023529, 0.00598548, 0.00504123,\n",
       "         0.9188176 ], dtype=float32),\n",
       "  array([0.9442142 , 0.00495983, 0.00713566, 0.01162467, 0.00500459,\n",
       "         0.02706098], dtype=float32),\n",
       "  array([0.8985201 , 0.00661718, 0.01061332, 0.05571274, 0.013953  ,\n",
       "         0.01458356], dtype=float32),\n",
       "  array([0.04358448, 0.01714422, 0.01241075, 0.00608554, 0.00568777,\n",
       "         0.9150872 ], dtype=float32),\n",
       "  array([0.0997969 , 0.0180461 , 0.01032668, 0.00682353, 0.00553527,\n",
       "         0.8594715 ], dtype=float32),\n",
       "  array([0.08091733, 0.02696219, 0.02521664, 0.01738431, 0.01826001,\n",
       "         0.8312595 ], dtype=float32),\n",
       "  array([0.04703588, 0.01249352, 0.00854455, 0.00934612, 0.00661048,\n",
       "         0.9159694 ], dtype=float32),\n",
       "  array([0.01556366, 0.859089  , 0.07178939, 0.00848704, 0.01373193,\n",
       "         0.03133902], dtype=float32),\n",
       "  array([0.02815706, 0.01465604, 0.06708328, 0.11220878, 0.7685738 ,\n",
       "         0.00932096], dtype=float32),\n",
       "  array([0.05152365, 0.02977303, 0.01417391, 0.01285307, 0.00918467,\n",
       "         0.8824917 ], dtype=float32),\n",
       "  array([0.0309305 , 0.02242502, 0.04495203, 0.04137261, 0.82983845,\n",
       "         0.03048134], dtype=float32),\n",
       "  array([0.09638909, 0.01109832, 0.01205939, 0.00966651, 0.00715235,\n",
       "         0.86363435], dtype=float32),\n",
       "  array([0.29097983, 0.07090425, 0.02480519, 0.00724   , 0.00531269,\n",
       "         0.600758  ], dtype=float32),\n",
       "  array([0.9502102 , 0.00572335, 0.00680563, 0.00843643, 0.00736181,\n",
       "         0.02146253], dtype=float32),\n",
       "  array([0.9141491 , 0.012846  , 0.02900304, 0.00883963, 0.01894519,\n",
       "         0.01621702], dtype=float32),\n",
       "  array([0.94488937, 0.00627161, 0.01616904, 0.01194527, 0.00801099,\n",
       "         0.01271355], dtype=float32),\n",
       "  array([0.95756614, 0.00517454, 0.01011954, 0.00969363, 0.00954155,\n",
       "         0.00790454], dtype=float32),\n",
       "  array([0.95396715, 0.00399198, 0.006568  , 0.01525478, 0.00972161,\n",
       "         0.01049655], dtype=float32),\n",
       "  array([0.12596624, 0.01197567, 0.00987903, 0.01995999, 0.01010147,\n",
       "         0.82211757], dtype=float32),\n",
       "  array([0.9326374 , 0.00538586, 0.02097982, 0.01315389, 0.01888458,\n",
       "         0.00895845], dtype=float32),\n",
       "  array([0.02398436, 0.08052935, 0.01824333, 0.00754895, 0.00585429,\n",
       "         0.86383975], dtype=float32),\n",
       "  array([0.94637686, 0.00547386, 0.01285519, 0.01101568, 0.01229164,\n",
       "         0.01198682], dtype=float32),\n",
       "  array([0.33504027, 0.0480882 , 0.01939045, 0.007853  , 0.00579415,\n",
       "         0.58383393], dtype=float32),\n",
       "  array([0.03918571, 0.03898519, 0.21608874, 0.1027482 , 0.5842954 ,\n",
       "         0.01869673], dtype=float32),\n",
       "  array([0.03942506, 0.02560258, 0.02609525, 0.00921054, 0.00906482,\n",
       "         0.89060175], dtype=float32),\n",
       "  array([0.9511771 , 0.00469658, 0.01336137, 0.00969886, 0.01176466,\n",
       "         0.00930148], dtype=float32),\n",
       "  array([0.9629561 , 0.00443417, 0.0075962 , 0.00950611, 0.00794879,\n",
       "         0.00755868], dtype=float32),\n",
       "  array([0.07496592, 0.67921406, 0.04295868, 0.01295306, 0.01286224,\n",
       "         0.177046  ], dtype=float32),\n",
       "  array([0.03609378, 0.01521443, 0.01126213, 0.01194496, 0.01012525,\n",
       "         0.9153595 ], dtype=float32),\n",
       "  array([0.01659973, 0.7770307 , 0.15626541, 0.00969457, 0.01785278,\n",
       "         0.02255685], dtype=float32),\n",
       "  array([0.03467841, 0.06544701, 0.02839085, 0.02115505, 0.01611856,\n",
       "         0.8342101 ], dtype=float32),\n",
       "  array([0.02882047, 0.01752444, 0.00827337, 0.00786028, 0.0062917 ,\n",
       "         0.93122977], dtype=float32),\n",
       "  array([0.93968624, 0.0054535 , 0.00847116, 0.01762898, 0.01209824,\n",
       "         0.01666201], dtype=float32),\n",
       "  array([0.0293443 , 0.2093168 , 0.02149621, 0.01006438, 0.00728782,\n",
       "         0.7224905 ], dtype=float32),\n",
       "  array([0.44974232, 0.09287138, 0.15173602, 0.12010418, 0.07951377,\n",
       "         0.10603236], dtype=float32),\n",
       "  array([0.96024996, 0.00439991, 0.006588  , 0.01039223, 0.00699707,\n",
       "         0.01137285], dtype=float32),\n",
       "  array([0.029072  , 0.01889672, 0.00796989, 0.0087227 , 0.00650048,\n",
       "         0.9288382 ], dtype=float32),\n",
       "  array([0.03069522, 0.01471326, 0.00806517, 0.01078454, 0.00785081,\n",
       "         0.927891  ], dtype=float32),\n",
       "  array([0.04785541, 0.01247262, 0.02384687, 0.8315152 , 0.06401886,\n",
       "         0.02029102], dtype=float32),\n",
       "  array([0.9385803 , 0.0055383 , 0.00799608, 0.01029343, 0.00605328,\n",
       "         0.03153865], dtype=float32),\n",
       "  array([0.94211733, 0.00503878, 0.00765269, 0.01970966, 0.01152175,\n",
       "         0.01395968], dtype=float32),\n",
       "  array([0.0873944 , 0.01675977, 0.02840405, 0.7367127 , 0.09846813,\n",
       "         0.03226097], dtype=float32),\n",
       "  array([0.02879498, 0.77034056, 0.07275411, 0.00707986, 0.01304637,\n",
       "         0.10798421], dtype=float32),\n",
       "  array([0.8007762 , 0.02048623, 0.12650153, 0.01364479, 0.02276666,\n",
       "         0.01582473], dtype=float32),\n",
       "  array([0.0795271 , 0.58034724, 0.27686775, 0.01198422, 0.02579145,\n",
       "         0.02548213], dtype=float32),\n",
       "  array([0.9188402 , 0.00621032, 0.00852587, 0.0197647 , 0.00992342,\n",
       "         0.03673546], dtype=float32),\n",
       "  array([0.03594077, 0.02411729, 0.0080061 , 0.00758409, 0.00567043,\n",
       "         0.9186813 ], dtype=float32),\n",
       "  array([0.95929664, 0.00426653, 0.00682854, 0.01297618, 0.00829953,\n",
       "         0.0083325 ], dtype=float32),\n",
       "  array([0.9598292 , 0.00449592, 0.00626907, 0.0119394 , 0.00784873,\n",
       "         0.00961768], dtype=float32),\n",
       "  array([0.0453182 , 0.01065815, 0.02041281, 0.82835084, 0.07766787,\n",
       "         0.01759205], dtype=float32),\n",
       "  array([0.02702067, 0.02525606, 0.00919408, 0.00895235, 0.0067714 ,\n",
       "         0.9228055 ], dtype=float32),\n",
       "  array([0.9566162 , 0.0061655 , 0.01426765, 0.00572278, 0.00689526,\n",
       "         0.01033243], dtype=float32),\n",
       "  array([0.05320747, 0.01815428, 0.00889733, 0.01158699, 0.00871483,\n",
       "         0.8994391 ], dtype=float32),\n",
       "  array([0.09410504, 0.03842237, 0.01419358, 0.00945409, 0.00706004,\n",
       "         0.8367649 ], dtype=float32),\n",
       "  array([0.0334213 , 0.02275305, 0.00901439, 0.01012509, 0.00763734,\n",
       "         0.9170489 ], dtype=float32),\n",
       "  array([0.05336621, 0.06393401, 0.0265206 , 0.00856731, 0.00690544,\n",
       "         0.8407064 ], dtype=float32),\n",
       "  array([0.9663911 , 0.00363933, 0.00670211, 0.00726753, 0.006232  ,\n",
       "         0.00976781], dtype=float32),\n",
       "  array([0.962104  , 0.0048546 , 0.00912541, 0.00897226, 0.00723116,\n",
       "         0.00771262], dtype=float32),\n",
       "  array([0.9643138 , 0.00432907, 0.00973687, 0.00720428, 0.00609001,\n",
       "         0.00832611], dtype=float32),\n",
       "  array([0.9464953 , 0.00725759, 0.01675994, 0.00571764, 0.00925474,\n",
       "         0.01451483], dtype=float32),\n",
       "  array([0.9567067 , 0.00629858, 0.00676197, 0.00543636, 0.00577872,\n",
       "         0.01901778], dtype=float32),\n",
       "  array([0.9580642 , 0.00457858, 0.00764002, 0.01095386, 0.00857724,\n",
       "         0.01018616], dtype=float32),\n",
       "  array([0.02982876, 0.01583492, 0.01276621, 0.01061156, 0.00881832,\n",
       "         0.9221402 ], dtype=float32),\n",
       "  array([0.02391393, 0.8680494 , 0.06055787, 0.00725927, 0.01310599,\n",
       "         0.02711355], dtype=float32),\n",
       "  array([0.9437757 , 0.00776486, 0.00913983, 0.0070683 , 0.00892111,\n",
       "         0.0233301 ], dtype=float32),\n",
       "  array([0.04804976, 0.01373568, 0.01691181, 0.85127944, 0.03919822,\n",
       "         0.03082512], dtype=float32),\n",
       "  array([0.05438742, 0.07413503, 0.7568239 , 0.02582158, 0.0535995 ,\n",
       "         0.0352326 ], dtype=float32),\n",
       "  array([0.22185658, 0.5619847 , 0.10229281, 0.01377762, 0.01993311,\n",
       "         0.08015513], dtype=float32),\n",
       "  array([0.04204639, 0.01452855, 0.03152354, 0.81359464, 0.06634765,\n",
       "         0.03195921], dtype=float32),\n",
       "  array([0.95725113, 0.00479223, 0.01232699, 0.00706357, 0.00979005,\n",
       "         0.00877609], dtype=float32),\n",
       "  array([0.03445452, 0.8229907 , 0.09221875, 0.00756697, 0.01118093,\n",
       "         0.03158822], dtype=float32),\n",
       "  array([0.32595685, 0.03433698, 0.32507592, 0.08797019, 0.19569162,\n",
       "         0.03096844], dtype=float32),\n",
       "  array([0.0407812 , 0.02036122, 0.00863022, 0.00711025, 0.00521457,\n",
       "         0.9179026 ], dtype=float32),\n",
       "  array([0.94078285, 0.00602194, 0.01859255, 0.01465326, 0.01295644,\n",
       "         0.00699287], dtype=float32),\n",
       "  array([0.02800731, 0.7418707 , 0.17072648, 0.01165207, 0.02691905,\n",
       "         0.02082439], dtype=float32),\n",
       "  array([0.36604258, 0.01876807, 0.02935258, 0.01357346, 0.01026931,\n",
       "         0.561994  ], dtype=float32),\n",
       "  array([0.17446348, 0.01871398, 0.02672099, 0.04385277, 0.03435753,\n",
       "         0.7018913 ], dtype=float32),\n",
       "  array([0.95143473, 0.00468527, 0.00773021, 0.01218448, 0.00692428,\n",
       "         0.01704102], dtype=float32),\n",
       "  array([0.03053414, 0.01897028, 0.00725447, 0.00630524, 0.00552276,\n",
       "         0.93141305], dtype=float32),\n",
       "  array([0.92389905, 0.00595837, 0.00907743, 0.03184582, 0.01115727,\n",
       "         0.01806216], dtype=float32),\n",
       "  array([0.0427613 , 0.05379527, 0.09979051, 0.0200997 , 0.01493204,\n",
       "         0.76862115], dtype=float32),\n",
       "  array([0.06920605, 0.01341848, 0.02264554, 0.8210013 , 0.04948438,\n",
       "         0.02424428], dtype=float32),\n",
       "  array([0.02472116, 0.03060705, 0.01320564, 0.00685849, 0.00643731,\n",
       "         0.91817033], dtype=float32),\n",
       "  array([0.7287447 , 0.01147248, 0.05192867, 0.11371015, 0.07531986,\n",
       "         0.0188241 ], dtype=float32),\n",
       "  array([0.953662  , 0.00411687, 0.00681947, 0.01033803, 0.00587888,\n",
       "         0.01918481], dtype=float32),\n",
       "  array([0.9511775 , 0.00579759, 0.01586795, 0.00570864, 0.00883928,\n",
       "         0.01260915], dtype=float32),\n",
       "  array([0.94820386, 0.0067881 , 0.0103923 , 0.00681965, 0.00783275,\n",
       "         0.01996345], dtype=float32),\n",
       "  array([0.05507244, 0.01477127, 0.01087844, 0.01269574, 0.00913524,\n",
       "         0.8974469 ], dtype=float32),\n",
       "  array([0.02187749, 0.8268126 , 0.04157455, 0.00983168, 0.01132107,\n",
       "         0.08858261], dtype=float32),\n",
       "  array([0.03818728, 0.13934553, 0.02359695, 0.0106761 , 0.0087983 ,\n",
       "         0.7793959 ], dtype=float32),\n",
       "  array([0.02191265, 0.0125337 , 0.03967178, 0.05494371, 0.8599094 ,\n",
       "         0.01102872], dtype=float32),\n",
       "  array([0.07394309, 0.01431655, 0.01909045, 0.7963856 , 0.04406877,\n",
       "         0.05219556], dtype=float32),\n",
       "  array([0.0312658 , 0.01945241, 0.00936783, 0.00764455, 0.00556365,\n",
       "         0.9267057 ], dtype=float32),\n",
       "  array([0.03607643, 0.1263978 , 0.02053127, 0.01021337, 0.007797  ,\n",
       "         0.79898417], dtype=float32),\n",
       "  array([0.23271154, 0.01953448, 0.01131073, 0.00896542, 0.00601834,\n",
       "         0.7214595 ], dtype=float32),\n",
       "  array([0.95910436, 0.00423789, 0.00696302, 0.01160184, 0.0052195 ,\n",
       "         0.01287334], dtype=float32),\n",
       "  array([0.9007635 , 0.00954837, 0.02313244, 0.02961625, 0.0231334 ,\n",
       "         0.01380613], dtype=float32),\n",
       "  array([0.95923436, 0.00370511, 0.00740898, 0.01506454, 0.00787556,\n",
       "         0.00671142], dtype=float32),\n",
       "  array([0.09883226, 0.01550251, 0.01361644, 0.02643585, 0.01631689,\n",
       "         0.82929605], dtype=float32),\n",
       "  array([0.12065035, 0.02601764, 0.01493112, 0.00774354, 0.00599656,\n",
       "         0.8246608 ], dtype=float32),\n",
       "  array([0.07739063, 0.01435323, 0.01871538, 0.8084835 , 0.04280722,\n",
       "         0.03825011], dtype=float32),\n",
       "  array([0.03466545, 0.01215064, 0.00761348, 0.01097428, 0.00793496,\n",
       "         0.9266612 ], dtype=float32),\n",
       "  array([0.08412548, 0.01271159, 0.01033634, 0.00814032, 0.00677786,\n",
       "         0.8779084 ], dtype=float32),\n",
       "  array([0.02579388, 0.01554452, 0.00758322, 0.00785566, 0.00632114,\n",
       "         0.93690157], dtype=float32),\n",
       "  array([0.03881904, 0.01938774, 0.008009  , 0.0068617 , 0.00516024,\n",
       "         0.9217622 ], dtype=float32),\n",
       "  array([0.03862678, 0.84326744, 0.04867943, 0.00746582, 0.0098687 ,\n",
       "         0.05209193], dtype=float32),\n",
       "  array([0.9624316 , 0.00365576, 0.00700268, 0.0093555 , 0.00630414,\n",
       "         0.01125027], dtype=float32),\n",
       "  array([0.06916166, 0.7680871 , 0.09289355, 0.00902369, 0.01338493,\n",
       "         0.047449  ], dtype=float32),\n",
       "  array([0.13565403, 0.05268606, 0.01588267, 0.00976536, 0.00683937,\n",
       "         0.77917254], dtype=float32),\n",
       "  array([0.9651318 , 0.00476362, 0.00652815, 0.00712618, 0.0060583 ,\n",
       "         0.01039185], dtype=float32),\n",
       "  array([0.95944554, 0.00560121, 0.01141573, 0.00719488, 0.00771462,\n",
       "         0.00862808], dtype=float32),\n",
       "  array([0.03123904, 0.02345475, 0.01024093, 0.01257882, 0.00813239,\n",
       "         0.9143541 ], dtype=float32),\n",
       "  array([0.06529464, 0.01678904, 0.02028316, 0.80928564, 0.04119336,\n",
       "         0.04715412], dtype=float32),\n",
       "  array([0.13631968, 0.05638536, 0.6924864 , 0.02615982, 0.06838372,\n",
       "         0.020265  ], dtype=float32),\n",
       "  array([0.13906778, 0.02062755, 0.03024402, 0.03053336, 0.01795547,\n",
       "         0.7615718 ], dtype=float32),\n",
       "  array([0.01531508, 0.80320555, 0.06860308, 0.00661004, 0.01200884,\n",
       "         0.09425743], dtype=float32),\n",
       "  array([0.01161036, 0.84797704, 0.06218994, 0.00940249, 0.01151955,\n",
       "         0.05730063], dtype=float32),\n",
       "  array([0.96125555, 0.00356536, 0.00580565, 0.01317672, 0.00744801,\n",
       "         0.00874863], dtype=float32),\n",
       "  array([0.9463161 , 0.00706012, 0.02008637, 0.00767156, 0.01011523,\n",
       "         0.00875072], dtype=float32),\n",
       "  array([0.04543062, 0.8040308 , 0.07877426, 0.00642773, 0.01110055,\n",
       "         0.05423612], dtype=float32),\n",
       "  array([0.9577495 , 0.0042468 , 0.01249854, 0.00927582, 0.00883092,\n",
       "         0.00739838], dtype=float32),\n",
       "  array([0.06515977, 0.01277956, 0.02059368, 0.82607734, 0.04256263,\n",
       "         0.03282701], dtype=float32),\n",
       "  array([0.02664091, 0.01893573, 0.00880597, 0.00712506, 0.00604289,\n",
       "         0.93244946], dtype=float32),\n",
       "  array([0.03365198, 0.48416144, 0.41406608, 0.01367765, 0.02929794,\n",
       "         0.0251449 ], dtype=float32),\n",
       "  array([0.03539123, 0.8351957 , 0.03679112, 0.00931082, 0.00953903,\n",
       "         0.07377207], dtype=float32),\n",
       "  array([0.06755444, 0.06275195, 0.01835351, 0.00529286, 0.00528103,\n",
       "         0.84076625], dtype=float32),\n",
       "  array([0.03019486, 0.01736655, 0.00977431, 0.01088572, 0.00782828,\n",
       "         0.92395025], dtype=float32),\n",
       "  array([0.02309906, 0.02549787, 0.01113585, 0.00758654, 0.0063457 ,\n",
       "         0.926335  ], dtype=float32),\n",
       "  array([0.03653035, 0.01679959, 0.00941578, 0.01122593, 0.00823185,\n",
       "         0.91779655], dtype=float32),\n",
       "  array([0.9468065 , 0.0043993 , 0.01260111, 0.01490415, 0.01206103,\n",
       "         0.00922782], dtype=float32),\n",
       "  array([0.1981245 , 0.05332959, 0.6026868 , 0.02139728, 0.06455211,\n",
       "         0.05990975], dtype=float32),\n",
       "  array([0.936564  , 0.00826193, 0.02577348, 0.01032145, 0.01023345,\n",
       "         0.00884566], dtype=float32),\n",
       "  array([0.03960202, 0.01285707, 0.00842668, 0.00902249, 0.00695396,\n",
       "         0.9231377 ], dtype=float32),\n",
       "  array([0.02510284, 0.0225931 , 0.00896053, 0.00757771, 0.00626847,\n",
       "         0.9294974 ], dtype=float32),\n",
       "  array([0.93023604, 0.01385537, 0.01946846, 0.0131796 , 0.01219423,\n",
       "         0.01106627], dtype=float32),\n",
       "  array([0.8235644 , 0.01137909, 0.01327471, 0.03804561, 0.02238534,\n",
       "         0.09135091], dtype=float32),\n",
       "  array([0.06047554, 0.01805002, 0.01731697, 0.807661  , 0.05630437,\n",
       "         0.04019209], dtype=float32),\n",
       "  array([0.95646966, 0.00672893, 0.01247793, 0.00649263, 0.0078658 ,\n",
       "         0.0099651 ], dtype=float32),\n",
       "  array([0.02579171, 0.83440506, 0.06375978, 0.00583057, 0.01163488,\n",
       "         0.05857804], dtype=float32),\n",
       "  array([0.02635757, 0.0803145 , 0.01347711, 0.0086032 , 0.0063629 ,\n",
       "         0.86488473], dtype=float32),\n",
       "  array([0.95963025, 0.00445114, 0.01059795, 0.00609426, 0.00821749,\n",
       "         0.01100885], dtype=float32),\n",
       "  array([0.02694663, 0.01851709, 0.0086411 , 0.0083371 , 0.00664958,\n",
       "         0.93090844], dtype=float32),\n",
       "  array([0.0795145 , 0.01674351, 0.02846671, 0.7735312 , 0.06017183,\n",
       "         0.04157227], dtype=float32),\n",
       "  array([0.07163037, 0.01465096, 0.01243627, 0.01408344, 0.00962191,\n",
       "         0.87757707], dtype=float32),\n",
       "  array([0.26089942, 0.09142257, 0.06652413, 0.01047635, 0.01243567,\n",
       "         0.5582419 ], dtype=float32),\n",
       "  array([0.05063029, 0.02627333, 0.01038836, 0.00617077, 0.00499079,\n",
       "         0.9015465 ], dtype=float32),\n",
       "  array([0.02513697, 0.02947169, 0.01189581, 0.00635258, 0.00470908,\n",
       "         0.92243385], dtype=float32),\n",
       "  array([0.02971371, 0.01905954, 0.00841158, 0.00753119, 0.00560836,\n",
       "         0.9296756 ], dtype=float32),\n",
       "  array([0.12693845, 0.01293074, 0.02028411, 0.76831555, 0.04039252,\n",
       "         0.03113869], dtype=float32),\n",
       "  array([0.0609599 , 0.01102482, 0.00946397, 0.01448409, 0.00921175,\n",
       "         0.8948555 ], dtype=float32),\n",
       "  array([0.03060004, 0.01467073, 0.00801892, 0.00794253, 0.00581134,\n",
       "         0.93295646], dtype=float32),\n",
       "  array([0.9632925 , 0.00458794, 0.00864897, 0.00737352, 0.00660133,\n",
       "         0.00949578], dtype=float32),\n",
       "  array([0.02598138, 0.01862702, 0.00735256, 0.00762146, 0.00562945,\n",
       "         0.9347881 ], dtype=float32),\n",
       "  array([0.02650459, 0.09453374, 0.01486843, 0.00874857, 0.00648341,\n",
       "         0.8488612 ], dtype=float32),\n",
       "  array([0.2197445 , 0.05559827, 0.0807722 , 0.01091525, 0.01797597,\n",
       "         0.6149938 ], dtype=float32),\n",
       "  array([0.03349624, 0.01240945, 0.0182362 , 0.8504798 , 0.06014319,\n",
       "         0.02523515], dtype=float32),\n",
       "  array([0.05919861, 0.01737541, 0.01250183, 0.00788693, 0.00686325,\n",
       "         0.896174  ], dtype=float32),\n",
       "  array([0.9628704 , 0.00437779, 0.00711986, 0.00790174, 0.00709995,\n",
       "         0.0106302 ], dtype=float32),\n",
       "  array([0.02809219, 0.01591826, 0.00752787, 0.00820493, 0.00675914,\n",
       "         0.93349755], dtype=float32),\n",
       "  array([0.02827276, 0.01710637, 0.00751837, 0.00646524, 0.00506705,\n",
       "         0.93557024], dtype=float32),\n",
       "  array([0.91335815, 0.02216441, 0.02051074, 0.00612146, 0.01403886,\n",
       "         0.02380631], dtype=float32),\n",
       "  array([0.8659586 , 0.01655528, 0.01514351, 0.00699767, 0.01013026,\n",
       "         0.08521472], dtype=float32),\n",
       "  array([0.10293357, 0.01182492, 0.00779956, 0.00901999, 0.00549557,\n",
       "         0.86292636], dtype=float32),\n",
       "  array([0.04227734, 0.01302713, 0.00964692, 0.01183302, 0.00826593,\n",
       "         0.91494966], dtype=float32),\n",
       "  array([0.02649425, 0.03147101, 0.00836281, 0.006772  , 0.00602645,\n",
       "         0.9208735 ], dtype=float32),\n",
       "  array([0.96344405, 0.0039325 , 0.00792   , 0.01015685, 0.00680419,\n",
       "         0.00774238], dtype=float32),\n",
       "  array([0.04273305, 0.7639428 , 0.14084896, 0.00775617, 0.01492809,\n",
       "         0.02979094], dtype=float32),\n",
       "  array([0.02107041, 0.86112845, 0.05379068, 0.0090817 , 0.01073834,\n",
       "         0.0441903 ], dtype=float32),\n",
       "  array([0.9629739 , 0.00403694, 0.00659174, 0.01071145, 0.00739825,\n",
       "         0.00828779], dtype=float32),\n",
       "  array([0.06083328, 0.01122402, 0.00856325, 0.00775915, 0.00616307,\n",
       "         0.90545726], dtype=float32),\n",
       "  array([0.92161316, 0.02070661, 0.02162511, 0.00564256, 0.00646104,\n",
       "         0.02395139], dtype=float32),\n",
       "  array([0.12810831, 0.01483144, 0.02292792, 0.74565   , 0.04464019,\n",
       "         0.04384207], dtype=float32),\n",
       "  array([0.85208535, 0.01154847, 0.05928901, 0.01884238, 0.03280443,\n",
       "         0.02543052], dtype=float32),\n",
       "  array([0.04260644, 0.01490433, 0.00868628, 0.00694855, 0.00563271,\n",
       "         0.92122173], dtype=float32),\n",
       "  array([0.18383789, 0.03702078, 0.01449033, 0.0084193 , 0.00649982,\n",
       "         0.7497319 ], dtype=float32),\n",
       "  array([0.04641759, 0.0131536 , 0.01720914, 0.84198594, 0.05318422,\n",
       "         0.0280495 ], dtype=float32),\n",
       "  array([0.06231449, 0.01839193, 0.01114671, 0.01480152, 0.00924033,\n",
       "         0.884105  ], dtype=float32),\n",
       "  array([0.9585562 , 0.00527457, 0.01219729, 0.00615325, 0.00755881,\n",
       "         0.01026002], dtype=float32),\n",
       "  array([0.95550394, 0.0051315 , 0.01334093, 0.00863815, 0.00814395,\n",
       "         0.00924153], dtype=float32),\n",
       "  array([0.01962977, 0.0407668 , 0.01934969, 0.0090168 , 0.00727112,\n",
       "         0.9039658 ], dtype=float32),\n",
       "  array([0.94362617, 0.00426511, 0.01007448, 0.01021879, 0.00738233,\n",
       "         0.02443306], dtype=float32),\n",
       "  array([0.01048299, 0.823362  , 0.09047315, 0.0075434 , 0.01247981,\n",
       "         0.05565867], dtype=float32),\n",
       "  array([0.05788947, 0.6189129 , 0.26087785, 0.01140296, 0.02199993,\n",
       "         0.02891692], dtype=float32),\n",
       "  array([0.454739  , 0.01652494, 0.03287483, 0.01146943, 0.00932385,\n",
       "         0.47506788], dtype=float32),\n",
       "  array([0.95947385, 0.00392197, 0.01112747, 0.01017614, 0.00795079,\n",
       "         0.00734982], dtype=float32),\n",
       "  array([0.03273626, 0.01308059, 0.02062026, 0.86166865, 0.05123364,\n",
       "         0.02066053], dtype=float32),\n",
       "  array([0.04495332, 0.01450407, 0.0316321 , 0.81646013, 0.05982671,\n",
       "         0.03262368], dtype=float32),\n",
       "  array([0.8741723 , 0.01026539, 0.01898713, 0.00701749, 0.00753829,\n",
       "         0.08201939], dtype=float32),\n",
       "  array([0.9378857 , 0.00731311, 0.01744674, 0.01015071, 0.01350779,\n",
       "         0.0136958 ], dtype=float32),\n",
       "  array([0.07618126, 0.01627828, 0.01934166, 0.79298276, 0.04225123,\n",
       "         0.05296472], dtype=float32),\n",
       "  array([0.02711404, 0.01381084, 0.03846107, 0.04319524, 0.8621973 ,\n",
       "         0.01522148], dtype=float32),\n",
       "  array([0.03867512, 0.03334209, 0.01108108, 0.00974831, 0.00659843,\n",
       "         0.90055496], dtype=float32),\n",
       "  array([0.06123056, 0.01241692, 0.01054505, 0.02016917, 0.01128097,\n",
       "         0.8843573 ], dtype=float32),\n",
       "  array([0.05838633, 0.01454203, 0.02272023, 0.8269534 , 0.04663836,\n",
       "         0.03075963], dtype=float32),\n",
       "  array([0.83367556, 0.01227982, 0.06003914, 0.02610486, 0.05015866,\n",
       "         0.017742  ], dtype=float32),\n",
       "  array([0.11782503, 0.05514641, 0.02252518, 0.01458391, 0.00695544,\n",
       "         0.78296405], dtype=float32),\n",
       "  array([0.9458042 , 0.00556371, 0.01449579, 0.01241342, 0.01378609,\n",
       "         0.00793685], dtype=float32),\n",
       "  array([0.81967235, 0.01531909, 0.06592868, 0.01725902, 0.05220785,\n",
       "         0.02961297], dtype=float32),\n",
       "  array([0.05067911, 0.01574551, 0.00975234, 0.00962953, 0.00801472,\n",
       "         0.90617883], dtype=float32),\n",
       "  array([0.01147267, 0.7867919 , 0.09364994, 0.01104133, 0.01510166,\n",
       "         0.08194249], dtype=float32),\n",
       "  array([0.940742  , 0.00501844, 0.00985548, 0.0093919 , 0.00631957,\n",
       "         0.02867262], dtype=float32),\n",
       "  array([0.08681805, 0.01430027, 0.01846996, 0.8129362 , 0.04297217,\n",
       "         0.0245033 ], dtype=float32),\n",
       "  array([0.96087337, 0.00459092, 0.00672456, 0.0099179 , 0.0061515 ,\n",
       "         0.01174172], dtype=float32),\n",
       "  array([0.06744595, 0.0144768 , 0.02267293, 0.01707688, 0.01185981,\n",
       "         0.8664676 ], dtype=float32),\n",
       "  array([0.96422935, 0.00371322, 0.00697936, 0.00870067, 0.00648722,\n",
       "         0.00989021], dtype=float32),\n",
       "  array([0.01764135, 0.8563934 , 0.05889828, 0.00710772, 0.00793102,\n",
       "         0.05202815], dtype=float32),\n",
       "  array([0.07555261, 0.01070846, 0.01139836, 0.01263009, 0.00869103,\n",
       "         0.8810194 ], dtype=float32),\n",
       "  array([0.3151883 , 0.02143626, 0.01902797, 0.00959233, 0.00611939,\n",
       "         0.6286358 ], dtype=float32),\n",
       "  array([0.12414759, 0.04143139, 0.4139865 , 0.09602748, 0.2517736 ,\n",
       "         0.07263336], dtype=float32),\n",
       "  array([0.01671351, 0.83096415, 0.09601319, 0.00726569, 0.01213937,\n",
       "         0.03690419], dtype=float32),\n",
       "  array([0.0986139 , 0.17790507, 0.02719487, 0.00759626, 0.00743822,\n",
       "         0.6812517 ], dtype=float32),\n",
       "  array([0.15777719, 0.01931047, 0.04453693, 0.04069766, 0.01787154,\n",
       "         0.7198062 ], dtype=float32),\n",
       "  array([0.9425153 , 0.00402929, 0.00800244, 0.02017866, 0.00976953,\n",
       "         0.0155046 ], dtype=float32),\n",
       "  array([0.03712712, 0.03193051, 0.01481181, 0.00716239, 0.00622414,\n",
       "         0.902744  ], dtype=float32),\n",
       "  array([0.9645465 , 0.00415849, 0.00605303, 0.00561691, 0.00443076,\n",
       "         0.01519433], dtype=float32),\n",
       "  array([0.9599004 , 0.00448523, 0.00974029, 0.00728551, 0.00689147,\n",
       "         0.01169705], dtype=float32),\n",
       "  array([0.9479942 , 0.00845924, 0.01681811, 0.00872044, 0.00935094,\n",
       "         0.0086571 ], dtype=float32),\n",
       "  array([0.93689907, 0.00720331, 0.02390973, 0.0056146 , 0.00975259,\n",
       "         0.01662065], dtype=float32),\n",
       "  array([0.96311384, 0.00394653, 0.00869601, 0.00879766, 0.00617904,\n",
       "         0.00926687], dtype=float32),\n",
       "  array([0.03831569, 0.0140607 , 0.05080595, 0.10648315, 0.778544  ,\n",
       "         0.01179042], dtype=float32),\n",
       "  array([0.9411996 , 0.00491134, 0.01023268, 0.01494689, 0.00744333,\n",
       "         0.0212661 ], dtype=float32),\n",
       "  array([0.0576209 , 0.01594312, 0.00864604, 0.01082361, 0.00808844,\n",
       "         0.89887786], dtype=float32),\n",
       "  array([0.02339941, 0.01242749, 0.03986283, 0.07068764, 0.8428967 ,\n",
       "         0.01072595], dtype=float32),\n",
       "  array([0.02838619, 0.01634034, 0.00811497, 0.0077844 , 0.00618792,\n",
       "         0.9331861 ], dtype=float32),\n",
       "  array([0.9405163 , 0.00521425, 0.01241549, 0.01274426, 0.00829959,\n",
       "         0.02081004], dtype=float32),\n",
       "  array([0.0300703 , 0.04143946, 0.01410815, 0.00568442, 0.00499679,\n",
       "         0.9037009 ], dtype=float32),\n",
       "  array([0.03434731, 0.01512444, 0.00789446, 0.00814296, 0.00626842,\n",
       "         0.9282224 ], dtype=float32),\n",
       "  array([0.05510084, 0.03647787, 0.00958762, 0.01630731, 0.00727596,\n",
       "         0.8752504 ], dtype=float32),\n",
       "  array([0.03438064, 0.02232803, 0.10908985, 0.07501116, 0.743083  ,\n",
       "         0.01610737], dtype=float32),\n",
       "  array([0.03354223, 0.01536164, 0.00712296, 0.01004468, 0.00705749,\n",
       "         0.926871  ], dtype=float32),\n",
       "  array([0.03661654, 0.03302527, 0.01350625, 0.0074302 , 0.00680254,\n",
       "         0.9026192 ], dtype=float32),\n",
       "  array([0.9321885 , 0.0045423 , 0.01246801, 0.02036992, 0.01346053,\n",
       "         0.01697078], dtype=float32),\n",
       "  array([0.96672374, 0.00373345, 0.00677264, 0.00698767, 0.0055942 ,\n",
       "         0.01018827], dtype=float32),\n",
       "  array([0.06032711, 0.0225976 , 0.0099036 , 0.03495584, 0.01115567,\n",
       "         0.86106014], dtype=float32),\n",
       "  array([0.95336324, 0.00535079, 0.00833208, 0.01261852, 0.009003  ,\n",
       "         0.01133238], dtype=float32),\n",
       "  array([0.03611505, 0.0144311 , 0.00724353, 0.00872643, 0.00685508,\n",
       "         0.92662877], dtype=float32),\n",
       "  array([0.05645267, 0.04321477, 0.2869933 , 0.07936978, 0.5024435 ,\n",
       "         0.03152601], dtype=float32),\n",
       "  array([0.03765764, 0.01649688, 0.01036294, 0.01120353, 0.00897856,\n",
       "         0.9153005 ], dtype=float32),\n",
       "  array([0.02410076, 0.01623953, 0.03955644, 0.04081602, 0.8604699 ,\n",
       "         0.0188174 ], dtype=float32),\n",
       "  array([0.02033471, 0.13836305, 0.01964729, 0.00782872, 0.00603952,\n",
       "         0.8077867 ], dtype=float32),\n",
       "  array([0.95582205, 0.00510757, 0.0143539 , 0.0085733 , 0.00901538,\n",
       "         0.00712764], dtype=float32),\n",
       "  array([0.07962425, 0.05442868, 0.7473018 , 0.02970686, 0.06261063,\n",
       "         0.02632781], dtype=float32),\n",
       "  array([0.96617126, 0.00342665, 0.00658788, 0.00738524, 0.00546914,\n",
       "         0.01095989], dtype=float32),\n",
       "  array([0.9570379 , 0.00639957, 0.01384377, 0.00694828, 0.00655478,\n",
       "         0.00921565], dtype=float32),\n",
       "  array([0.02365458, 0.01531633, 0.0482086 , 0.06300338, 0.836078  ,\n",
       "         0.01373907], dtype=float32),\n",
       "  array([0.43718675, 0.01353658, 0.02973351, 0.26776022, 0.04509166,\n",
       "         0.20669132], dtype=float32),\n",
       "  array([0.9664767 , 0.00353051, 0.00650412, 0.00929374, 0.0061858 ,\n",
       "         0.00800913], dtype=float32),\n",
       "  array([0.04017971, 0.02026964, 0.00917705, 0.00788498, 0.00653825,\n",
       "         0.9159504 ], dtype=float32),\n",
       "  array([0.3357163 , 0.01700186, 0.02080825, 0.01078078, 0.00850572,\n",
       "         0.6071871 ], dtype=float32),\n",
       "  array([0.04198326, 0.09451016, 0.71731305, 0.02930932, 0.07424158,\n",
       "         0.04264265], dtype=float32),\n",
       "  array([0.0272587 , 0.0194777 , 0.04913386, 0.03807541, 0.8468155 ,\n",
       "         0.01923881], dtype=float32),\n",
       "  array([0.02375542, 0.02454961, 0.00807567, 0.00930948, 0.00666277,\n",
       "         0.927647  ], dtype=float32),\n",
       "  array([0.94882816, 0.00683343, 0.00857088, 0.00782336, 0.00551118,\n",
       "         0.0224332 ], dtype=float32),\n",
       "  array([0.07307655, 0.05599051, 0.07407791, 0.01036098, 0.00961888,\n",
       "         0.7768752 ], dtype=float32),\n",
       "  array([0.0209773 , 0.7463988 , 0.0643013 , 0.00610207, 0.00923013,\n",
       "         0.1529904 ], dtype=float32),\n",
       "  array([0.03166035, 0.01820869, 0.00721372, 0.00842015, 0.00641488,\n",
       "         0.92808217], dtype=float32),\n",
       "  array([0.09555855, 0.06734663, 0.08503104, 0.04379531, 0.5828449 ,\n",
       "         0.12542355], dtype=float32),\n",
       "  array([0.9365797 , 0.00604127, 0.008801  , 0.00670758, 0.00505264,\n",
       "         0.03681782], dtype=float32),\n",
       "  array([0.04874977, 0.03308402, 0.06761507, 0.02234165, 0.0158882 ,\n",
       "         0.8123213 ], dtype=float32),\n",
       "  array([0.9454625 , 0.00891179, 0.0107759 , 0.00919492, 0.0112819 ,\n",
       "         0.01437288], dtype=float32),\n",
       "  array([0.02252663, 0.01555742, 0.05289226, 0.06632651, 0.83287925,\n",
       "         0.00981803], dtype=float32),\n",
       "  array([0.9185871 , 0.00895085, 0.03880331, 0.00936745, 0.014718  ,\n",
       "         0.00957324], dtype=float32),\n",
       "  array([0.95721585, 0.00513554, 0.00935878, 0.00715762, 0.00826663,\n",
       "         0.01286552], dtype=float32),\n",
       "  array([0.9619607 , 0.00400596, 0.00750426, 0.00733282, 0.00805255,\n",
       "         0.01114365], dtype=float32),\n",
       "  array([0.22946988, 0.1455519 , 0.04379896, 0.01247852, 0.0074843 ,\n",
       "         0.5612165 ], dtype=float32),\n",
       "  array([0.93384194, 0.01699321, 0.01925452, 0.00747767, 0.00891909,\n",
       "         0.01351369], dtype=float32),\n",
       "  array([0.03773669, 0.02399809, 0.02377466, 0.01029683, 0.00895971,\n",
       "         0.89523405], dtype=float32),\n",
       "  array([0.02730562, 0.03824724, 0.01028101, 0.00629348, 0.00518342,\n",
       "         0.9126892 ], dtype=float32),\n",
       "  array([0.95430106, 0.0045049 , 0.00696607, 0.01007617, 0.0093874 ,\n",
       "         0.01476446], dtype=float32),\n",
       "  array([0.01454927, 0.7426954 , 0.18543611, 0.01147599, 0.02152061,\n",
       "         0.02432262], dtype=float32),\n",
       "  array([0.04634237, 0.01703461, 0.01179681, 0.00680365, 0.00646266,\n",
       "         0.9115599 ], dtype=float32),\n",
       "  array([0.02711842, 0.01740365, 0.00719022, 0.00751344, 0.00618643,\n",
       "         0.93458784], dtype=float32),\n",
       "  array([0.03200843, 0.74565935, 0.10165714, 0.00802678, 0.01582731,\n",
       "         0.09682094], dtype=float32),\n",
       "  array([0.03736605, 0.01231565, 0.00904222, 0.01144692, 0.00842636,\n",
       "         0.9214028 ], dtype=float32),\n",
       "  array([0.03258675, 0.01670321, 0.00738795, 0.00854175, 0.00653007,\n",
       "         0.92825025], dtype=float32),\n",
       "  array([0.4048179 , 0.01131538, 0.02039   , 0.49324146, 0.04660694,\n",
       "         0.02362826], dtype=float32),\n",
       "  array([0.94713116, 0.00478521, 0.01210098, 0.00967131, 0.01249375,\n",
       "         0.0138176 ], dtype=float32),\n",
       "  array([0.13003032, 0.01113288, 0.01220657, 0.01198794, 0.00785965,\n",
       "         0.82678264], dtype=float32),\n",
       "  array([0.05929155, 0.01278834, 0.01169234, 0.0085833 , 0.006869  ,\n",
       "         0.90077543], dtype=float32),\n",
       "  array([0.04237314, 0.6885591 , 0.19535974, 0.00879906, 0.01778737,\n",
       "         0.0471216 ], dtype=float32),\n",
       "  array([0.05605147, 0.02219221, 0.01537435, 0.00817846, 0.00614917,\n",
       "         0.8920544 ], dtype=float32),\n",
       "  array([0.11245888, 0.02363318, 0.01664559, 0.10463165, 0.02321626,\n",
       "         0.7194144 ], dtype=float32),\n",
       "  array([0.07102305, 0.01918343, 0.01728336, 0.00747433, 0.00629936,\n",
       "         0.87873644], dtype=float32),\n",
       "  array([0.03799226, 0.01292295, 0.00803851, 0.00749746, 0.00591566,\n",
       "         0.92763317], dtype=float32),\n",
       "  array([0.08209705, 0.05251766, 0.7474811 , 0.03001417, 0.06236248,\n",
       "         0.02552755], dtype=float32),\n",
       "  array([0.95011383, 0.00720794, 0.00991629, 0.00605826, 0.00558996,\n",
       "         0.02111377], dtype=float32),\n",
       "  array([0.9065331 , 0.00528085, 0.01113603, 0.04923444, 0.01795734,\n",
       "         0.00985835], dtype=float32),\n",
       "  array([0.03194593, 0.01716793, 0.0075293 , 0.00785885, 0.00654741,\n",
       "         0.9289506 ], dtype=float32),\n",
       "  array([0.02588788, 0.01589194, 0.00738411, 0.00800346, 0.00659008,\n",
       "         0.9362426 ], dtype=float32),\n",
       "  array([0.02898982, 0.02919714, 0.01159226, 0.00889571, 0.00818565,\n",
       "         0.9131394 ], dtype=float32),\n",
       "  array([0.20459542, 0.0344854 , 0.02013901, 0.0102753 , 0.00859162,\n",
       "         0.7219132 ], dtype=float32),\n",
       "  array([0.03237636, 0.02612911, 0.00945956, 0.00728807, 0.00612124,\n",
       "         0.9186256 ], dtype=float32),\n",
       "  array([0.14591262, 0.04578439, 0.06529176, 0.02037991, 0.02757295,\n",
       "         0.69505835], dtype=float32),\n",
       "  array([0.1449629 , 0.0412228 , 0.18655735, 0.09935091, 0.43084124,\n",
       "         0.09706472], dtype=float32),\n",
       "  array([0.95436656, 0.00598806, 0.01388558, 0.0081628 , 0.00743907,\n",
       "         0.01015806], dtype=float32),\n",
       "  array([0.96128386, 0.0038117 , 0.00553985, 0.01163449, 0.00719932,\n",
       "         0.01053076], dtype=float32),\n",
       "  array([0.0614159 , 0.06735554, 0.76482224, 0.02327677, 0.057945  ,\n",
       "         0.02518448], dtype=float32),\n",
       "  array([0.03575844, 0.01521036, 0.01682651, 0.84161186, 0.05289599,\n",
       "         0.03769682], dtype=float32),\n",
       "  array([0.96441734, 0.0047865 , 0.00810419, 0.00708257, 0.00696   ,\n",
       "         0.0086495 ], dtype=float32),\n",
       "  array([0.9503322 , 0.00401982, 0.01059012, 0.01584646, 0.00907864,\n",
       "         0.01013281], dtype=float32),\n",
       "  array([0.06860978, 0.02986036, 0.01317665, 0.01227081, 0.00810654,\n",
       "         0.86797583], dtype=float32),\n",
       "  array([0.02946025, 0.01894972, 0.0787805 , 0.05293973, 0.80620646,\n",
       "         0.01366336], dtype=float32),\n",
       "  array([0.42455336, 0.02662366, 0.01626768, 0.09691508, 0.01672486,\n",
       "         0.4189153 ], dtype=float32),\n",
       "  array([0.9481125 , 0.00690695, 0.01826706, 0.00700456, 0.00939495,\n",
       "         0.01031394], dtype=float32),\n",
       "  array([0.03469479, 0.02405216, 0.00847352, 0.00599899, 0.00453196,\n",
       "         0.9222486 ], dtype=float32),\n",
       "  array([0.83740455, 0.01343837, 0.0568798 , 0.0211063 , 0.04914522,\n",
       "         0.02202577], dtype=float32),\n",
       "  array([0.02575231, 0.02852533, 0.00887375, 0.00692891, 0.00579115,\n",
       "         0.9241286 ], dtype=float32),\n",
       "  array([0.02818495, 0.02492285, 0.00781542, 0.00639327, 0.00574836,\n",
       "         0.9269352 ], dtype=float32),\n",
       "  array([0.18415238, 0.5318203 , 0.17004253, 0.01099177, 0.01453439,\n",
       "         0.08845864], dtype=float32),\n",
       "  array([0.0473281 , 0.01252938, 0.02121464, 0.8496904 , 0.0487449 ,\n",
       "         0.02049271], dtype=float32),\n",
       "  array([0.02523808, 0.01808153, 0.00760829, 0.00945554, 0.00724934,\n",
       "         0.93236715], dtype=float32),\n",
       "  array([0.0461104 , 0.01398672, 0.00955274, 0.01366193, 0.009412  ,\n",
       "         0.9072762 ], dtype=float32),\n",
       "  array([0.05066731, 0.01331777, 0.02748454, 0.8093205 , 0.07862706,\n",
       "         0.02058273], dtype=float32),\n",
       "  array([0.02014935, 0.8546526 , 0.05597635, 0.00870497, 0.01723544,\n",
       "         0.04328133], dtype=float32),\n",
       "  array([0.96245337, 0.00417115, 0.00788355, 0.00992941, 0.00689977,\n",
       "         0.00866287], dtype=float32),\n",
       "  array([0.6298066 , 0.01573314, 0.04954747, 0.13277146, 0.0722004 ,\n",
       "         0.09994088], dtype=float32),\n",
       "  array([0.9087464 , 0.01353283, 0.02835717, 0.01162724, 0.01218937,\n",
       "         0.0255469 ], dtype=float32),\n",
       "  array([0.8961942 , 0.01046575, 0.04855342, 0.0073834 , 0.01837475,\n",
       "         0.0190285 ], dtype=float32),\n",
       "  array([0.03492925, 0.74538904, 0.16664334, 0.00710629, 0.01602283,\n",
       "         0.02990928], dtype=float32),\n",
       "  array([0.03213312, 0.76837367, 0.14433122, 0.00875888, 0.01495978,\n",
       "         0.03144336], dtype=float32),\n",
       "  array([0.08843666, 0.06328262, 0.72207034, 0.03360436, 0.07649236,\n",
       "         0.01611361], dtype=float32),\n",
       "  array([0.02308085, 0.01610783, 0.03940756, 0.03984692, 0.8654902 ,\n",
       "         0.01606664], dtype=float32),\n",
       "  array([0.0188031 , 0.81818694, 0.11559574, 0.00685503, 0.01384564,\n",
       "         0.02671357], dtype=float32),\n",
       "  array([0.02602637, 0.02752585, 0.00819267, 0.0066125 , 0.00555394,\n",
       "         0.92608875], dtype=float32),\n",
       "  array([0.0187135 , 0.8232261 , 0.11446259, 0.00698815, 0.0134965 ,\n",
       "         0.02311315], dtype=float32),\n",
       "  array([0.11390159, 0.026195  , 0.01598342, 0.0211849 , 0.0118961 ,\n",
       "         0.810839  ], dtype=float32),\n",
       "  array([0.38912305, 0.01297912, 0.01924824, 0.02158369, 0.01067705,\n",
       "         0.54638886], dtype=float32),\n",
       "  array([0.957207  , 0.00459499, 0.00859036, 0.0080289 , 0.00593364,\n",
       "         0.01564516], dtype=float32),\n",
       "  array([0.02300568, 0.01636206, 0.03557684, 0.0458839 , 0.8632714 ,\n",
       "         0.01590008], dtype=float32),\n",
       "  array([0.07548962, 0.01329239, 0.00895202, 0.00716626, 0.00531429,\n",
       "         0.88978547], dtype=float32),\n",
       "  array([0.04371555, 0.01286509, 0.00783826, 0.01128225, 0.00770517,\n",
       "         0.9165936 ], dtype=float32),\n",
       "  array([0.962958  , 0.00512326, 0.00864891, 0.00642157, 0.00743445,\n",
       "         0.00941388], dtype=float32),\n",
       "  array([0.9534469 , 0.00371416, 0.0070299 , 0.01760133, 0.00984923,\n",
       "         0.00835853], dtype=float32),\n",
       "  array([0.03615662, 0.07654941, 0.01755228, 0.01456126, 0.00970477,\n",
       "         0.8454756 ], dtype=float32),\n",
       "  array([0.03304966, 0.0144694 , 0.00837722, 0.00758319, 0.00566695,\n",
       "         0.9308536 ], dtype=float32),\n",
       "  array([0.03883292, 0.02177486, 0.00976648, 0.01001875, 0.00738991,\n",
       "         0.9122171 ], dtype=float32),\n",
       "  array([0.03522947, 0.01916139, 0.00829737, 0.00730007, 0.00537338,\n",
       "         0.9246383 ], dtype=float32),\n",
       "  array([0.9657835 , 0.00427151, 0.00672043, 0.00847942, 0.00589693,\n",
       "         0.00884827], dtype=float32),\n",
       "  array([0.02320594, 0.01113963, 0.03629887, 0.07619252, 0.84155375,\n",
       "         0.01160922], dtype=float32),\n",
       "  array([0.04656952, 0.82149315, 0.0642499 , 0.0079671 , 0.0136043 ,\n",
       "         0.04611615], dtype=float32),\n",
       "  array([0.05748603, 0.13457769, 0.45709145, 0.02576654, 0.0238436 ,\n",
       "         0.30123466], dtype=float32),\n",
       "  array([0.06055142, 0.01542535, 0.00793214, 0.00698334, 0.00590043,\n",
       "         0.9032073 ], dtype=float32),\n",
       "  array([0.9652564 , 0.00464132, 0.00736435, 0.00773865, 0.00659275,\n",
       "         0.00840645], dtype=float32),\n",
       "  array([0.09261199, 0.7282749 , 0.12094552, 0.00999717, 0.01554259,\n",
       "         0.03262777], dtype=float32),\n",
       "  array([0.8593253 , 0.01514991, 0.04822079, 0.01203187, 0.01238323,\n",
       "         0.05288905], dtype=float32),\n",
       "  array([0.9493463 , 0.00583595, 0.01499824, 0.00548666, 0.00913618,\n",
       "         0.01519667], dtype=float32),\n",
       "  array([0.91586196, 0.00841074, 0.00856708, 0.00717723, 0.00663303,\n",
       "         0.05334994], dtype=float32),\n",
       "  array([0.17693369, 0.07907356, 0.63176656, 0.02712107, 0.06764923,\n",
       "         0.01745581], dtype=float32),\n",
       "  array([0.02304608, 0.84904414, 0.08127379, 0.00771365, 0.01420716,\n",
       "         0.02471518], dtype=float32),\n",
       "  array([0.02521785, 0.01744217, 0.00756534, 0.0076444 , 0.00573293,\n",
       "         0.9363974 ], dtype=float32),\n",
       "  array([0.02570248, 0.01948764, 0.00748726, 0.00682956, 0.00571116,\n",
       "         0.93478185], dtype=float32),\n",
       "  array([0.9507381 , 0.00696732, 0.01197305, 0.0090838 , 0.01184504,\n",
       "         0.00939275], dtype=float32),\n",
       "  array([0.03005293, 0.01595813, 0.00724743, 0.00654713, 0.00535231,\n",
       "         0.93484205], dtype=float32),\n",
       "  array([0.04562233, 0.07723558, 0.7532643 , 0.02666927, 0.06325443,\n",
       "         0.0339541 ], dtype=float32),\n",
       "  array([0.0425873 , 0.01240907, 0.01599474, 0.8595653 , 0.04260605,\n",
       "         0.02683759], dtype=float32),\n",
       "  array([0.42075863, 0.01258236, 0.01656651, 0.01688622, 0.00892862,\n",
       "         0.5242777 ], dtype=float32),\n",
       "  array([0.93398774, 0.00784374, 0.01072947, 0.01811362, 0.0145851 ,\n",
       "         0.01474028], dtype=float32),\n",
       "  array([0.9555665 , 0.0040947 , 0.00827714, 0.01452858, 0.0095351 ,\n",
       "         0.0079979 ], dtype=float32),\n",
       "  array([0.0430224 , 0.0150663 , 0.0075274 , 0.01186576, 0.00818384,\n",
       "         0.91433436], dtype=float32),\n",
       "  array([0.5806239 , 0.01074523, 0.01694673, 0.02298156, 0.01199811,\n",
       "         0.3567045 ], dtype=float32),\n",
       "  array([0.96251214, 0.00471128, 0.00744142, 0.00908325, 0.00824585,\n",
       "         0.0080062 ], dtype=float32),\n",
       "  array([0.9589856 , 0.0042457 , 0.00986955, 0.0084793 , 0.00903563,\n",
       "         0.00938405], dtype=float32),\n",
       "  array([0.04564907, 0.01480996, 0.00846895, 0.0120334 , 0.0088267 ,\n",
       "         0.910212  ], dtype=float32),\n",
       "  array([0.93886906, 0.00849705, 0.0096912 , 0.0126784 , 0.01387338,\n",
       "         0.016391  ], dtype=float32),\n",
       "  array([0.02906027, 0.7921004 , 0.08224983, 0.00970045, 0.01319264,\n",
       "         0.07369643], dtype=float32),\n",
       "  array([0.06216226, 0.02446822, 0.00858013, 0.00787308, 0.00542351,\n",
       "         0.89149284], dtype=float32),\n",
       "  array([0.96044594, 0.00455883, 0.01047581, 0.0085786 , 0.00799757,\n",
       "         0.00794329], dtype=float32),\n",
       "  array([0.05508181, 0.07697054, 0.08812898, 0.01308317, 0.00938713,\n",
       "         0.75734836], dtype=float32),\n",
       "  array([0.96280843, 0.00444063, 0.0088177 , 0.00807183, 0.00793172,\n",
       "         0.0079297 ], dtype=float32),\n",
       "  array([0.5890243 , 0.15451702, 0.06855916, 0.01531475, 0.0413704 ,\n",
       "         0.13121442], dtype=float32),\n",
       "  array([0.03203886, 0.01256008, 0.01769506, 0.83873284, 0.07511361,\n",
       "         0.02385956], dtype=float32),\n",
       "  array([0.90638405, 0.01655878, 0.01574563, 0.0055622 , 0.01381194,\n",
       "         0.04193748], dtype=float32),\n",
       "  array([0.06632237, 0.7639541 , 0.07981613, 0.00993482, 0.02336906,\n",
       "         0.05660352], dtype=float32),\n",
       "  array([0.9627619 , 0.004639  , 0.00872834, 0.00811441, 0.00756921,\n",
       "         0.00818718], dtype=float32),\n",
       "  array([0.95787877, 0.00452481, 0.0091389 , 0.01152464, 0.00922165,\n",
       "         0.00771118], dtype=float32),\n",
       "  array([0.9523404 , 0.00757135, 0.01577527, 0.00628978, 0.0084662 ,\n",
       "         0.00955685], dtype=float32),\n",
       "  array([0.02748387, 0.01780215, 0.00789556, 0.0077554 , 0.00629097,\n",
       "         0.932772  ], dtype=float32),\n",
       "  array([0.07536698, 0.17778997, 0.48297343, 0.02360177, 0.02210434,\n",
       "         0.21816355], dtype=float32),\n",
       "  array([0.15036814, 0.02194863, 0.03215465, 0.02209502, 0.01466323,\n",
       "         0.7587703 ], dtype=float32),\n",
       "  array([0.03297731, 0.77108526, 0.05197849, 0.00992579, 0.01564747,\n",
       "         0.11838569], dtype=float32),\n",
       "  array([0.0225985 , 0.031836  , 0.00952361, 0.00577245, 0.00470744,\n",
       "         0.92556196], dtype=float32),\n",
       "  array([0.01830815, 0.83184594, 0.04362269, 0.00681657, 0.00851356,\n",
       "         0.090893  ], dtype=float32),\n",
       "  array([0.04720839, 0.01287956, 0.01725307, 0.8554246 , 0.04148013,\n",
       "         0.02575443], dtype=float32),\n",
       "  array([0.03612458, 0.03773462, 0.01269336, 0.00913628, 0.00752896,\n",
       "         0.89678216], dtype=float32),\n",
       "  array([0.05801847, 0.07451463, 0.7352057 , 0.03130173, 0.08425335,\n",
       "         0.0167061 ], dtype=float32),\n",
       "  array([0.9583109 , 0.00444463, 0.00984983, 0.00801902, 0.00727727,\n",
       "         0.01209826], dtype=float32),\n",
       "  array([0.05459191, 0.01068216, 0.01000238, 0.01386521, 0.00946252,\n",
       "         0.90139586], dtype=float32),\n",
       "  array([0.04224633, 0.348008  , 0.38397184, 0.02109974, 0.04994293,\n",
       "         0.1547313 ], dtype=float32),\n",
       "  array([0.0555695 , 0.01192245, 0.01115173, 0.01213035, 0.00898043,\n",
       "         0.90024555], dtype=float32),\n",
       "  array([0.05402707, 0.01308573, 0.01233973, 0.02113307, 0.01356997,\n",
       "         0.8858444 ], dtype=float32),\n",
       "  array([0.03590548, 0.01725501, 0.01001069, 0.01265195, 0.00910934,\n",
       "         0.91506755], dtype=float32),\n",
       "  array([0.03515321, 0.1545689 , 0.69490945, 0.02519487, 0.06946635,\n",
       "         0.02070719], dtype=float32),\n",
       "  array([0.0185301 , 0.46759018, 0.42438146, 0.01252644, 0.02519231,\n",
       "         0.05177948], dtype=float32),\n",
       "  array([0.95410985, 0.00793992, 0.01159823, 0.00611172, 0.00844228,\n",
       "         0.01179797], dtype=float32),\n",
       "  array([0.9625353 , 0.00401178, 0.0078013 , 0.00858808, 0.00681153,\n",
       "         0.01025205], dtype=float32),\n",
       "  array([0.8479727 , 0.01252649, 0.07987188, 0.01248726, 0.02745481,\n",
       "         0.01968689], dtype=float32),\n",
       "  array([0.01751696, 0.86518395, 0.07334205, 0.00636558, 0.01118922,\n",
       "         0.02640233], dtype=float32),\n",
       "  array([0.9471368 , 0.00376421, 0.00794159, 0.02210222, 0.01113772,\n",
       "         0.00791739], dtype=float32),\n",
       "  array([0.04109605, 0.08374918, 0.01449742, 0.00670483, 0.00514513,\n",
       "         0.8488074 ], dtype=float32),\n",
       "  array([0.07697629, 0.06849585, 0.72865134, 0.03522847, 0.07597952,\n",
       "         0.01466857], dtype=float32),\n",
       "  array([0.9593674 , 0.00514247, 0.007302  , 0.01116989, 0.00825392,\n",
       "         0.00876444], dtype=float32),\n",
       "  array([0.06617271, 0.08001609, 0.74079895, 0.0253754 , 0.06168137,\n",
       "         0.02595549], dtype=float32),\n",
       "  array([0.8431592 , 0.01902989, 0.09267691, 0.00875689, 0.01722492,\n",
       "         0.01915226], dtype=float32),\n",
       "  array([0.0323122 , 0.05165847, 0.01072905, 0.00662049, 0.00538267,\n",
       "         0.8932971 ], dtype=float32),\n",
       "  array([0.01488384, 0.8807633 , 0.06003837, 0.00567132, 0.00902604,\n",
       "         0.02961724], dtype=float32),\n",
       "  array([0.81368095, 0.01412589, 0.09582285, 0.02760078, 0.03648904,\n",
       "         0.01228062], dtype=float32),\n",
       "  array([0.8236943 , 0.02402943, 0.02872192, 0.02568185, 0.03828024,\n",
       "         0.05959222], dtype=float32),\n",
       "  array([0.93645203, 0.00728493, 0.02690859, 0.00722871, 0.01106345,\n",
       "         0.01106235], dtype=float32),\n",
       "  array([0.9617198 , 0.00461344, 0.00893763, 0.0061361 , 0.00729989,\n",
       "         0.01129311], dtype=float32),\n",
       "  array([0.02038546, 0.02569694, 0.00851234, 0.00811492, 0.00681648,\n",
       "         0.93047386], dtype=float32),\n",
       "  array([0.9519191 , 0.00490265, 0.00618737, 0.01567362, 0.0098091 ,\n",
       "         0.01150813], dtype=float32),\n",
       "  array([0.9126523 , 0.02076871, 0.01873337, 0.00679404, 0.00784747,\n",
       "         0.03320409], dtype=float32),\n",
       "  array([0.9376588 , 0.00584502, 0.01669675, 0.01420795, 0.01836254,\n",
       "         0.00722887], dtype=float32),\n",
       "  array([0.95377755, 0.00461331, 0.01219677, 0.01090393, 0.00869319,\n",
       "         0.00981515], dtype=float32),\n",
       "  array([0.0311185 , 0.34982303, 0.52645147, 0.01793783, 0.04883941,\n",
       "         0.02582975], dtype=float32),\n",
       "  array([0.9378736 , 0.00840844, 0.01678218, 0.01183747, 0.01344976,\n",
       "         0.01164832], dtype=float32),\n",
       "  array([0.9582054 , 0.00513039, 0.00785065, 0.00603327, 0.00526914,\n",
       "         0.01751126], dtype=float32),\n",
       "  array([0.0220108 , 0.01292217, 0.04175465, 0.05712494, 0.8553041 ,\n",
       "         0.0108833 ], dtype=float32),\n",
       "  array([0.96333724, 0.00413202, 0.00747706, 0.00896651, 0.00687279,\n",
       "         0.00921449], dtype=float32),\n",
       "  array([0.9552823 , 0.00446683, 0.00725996, 0.00662726, 0.00481817,\n",
       "         0.02154541], dtype=float32),\n",
       "  array([0.9625353 , 0.00401178, 0.0078013 , 0.00858808, 0.00681153,\n",
       "         0.01025205], dtype=float32),\n",
       "  array([0.03138603, 0.8522928 , 0.04945575, 0.00647433, 0.0080665 ,\n",
       "         0.05232463], dtype=float32),\n",
       "  array([0.04705374, 0.01280504, 0.00926219, 0.01540308, 0.0095079 ,\n",
       "         0.905968  ], dtype=float32),\n",
       "  array([0.02264097, 0.75928205, 0.04890733, 0.00931393, 0.01270543,\n",
       "         0.14715031], dtype=float32),\n",
       "  array([0.04148255, 0.01430946, 0.0101771 , 0.01346428, 0.00951745,\n",
       "         0.9110491 ], dtype=float32),\n",
       "  array([0.8236943 , 0.02402943, 0.02872192, 0.02568185, 0.03828024,\n",
       "         0.05959222], dtype=float32),\n",
       "  array([0.9419991 , 0.00516303, 0.01233784, 0.01719112, 0.01476717,\n",
       "         0.00854178], dtype=float32),\n",
       "  array([0.96333605, 0.00454761, 0.00663029, 0.00686965, 0.00632765,\n",
       "         0.01228871], dtype=float32),\n",
       "  array([0.03534043, 0.01887809, 0.0080465 , 0.00795744, 0.0070443 ,\n",
       "         0.9227332 ], dtype=float32),\n",
       "  array([0.04697949, 0.0197239 , 0.00906461, 0.01003938, 0.00755735,\n",
       "         0.9066352 ], dtype=float32),\n",
       "  array([0.9630945 , 0.0048666 , 0.00620253, 0.00708063, 0.0059225 ,\n",
       "         0.01283329], dtype=float32),\n",
       "  array([0.0808912 , 0.7204884 , 0.11795594, 0.0097815 , 0.01507589,\n",
       "         0.05580695], dtype=float32),\n",
       "  array([0.89059746, 0.0135655 , 0.01129411, 0.00598933, 0.00549847,\n",
       "         0.0730551 ], dtype=float32),\n",
       "  array([0.9621082 , 0.00425521, 0.01157776, 0.00760335, 0.00629043,\n",
       "         0.00816507], dtype=float32),\n",
       "  array([0.02574037, 0.09979739, 0.01551821, 0.00770405, 0.00619952,\n",
       "         0.84504044], dtype=float32),\n",
       "  array([0.93826723, 0.0085741 , 0.02222932, 0.01187535, 0.01229727,\n",
       "         0.0067568 ], dtype=float32),\n",
       "  array([0.03162053, 0.02949632, 0.00940638, 0.00826609, 0.00634913,\n",
       "         0.91486156], dtype=float32),\n",
       "  array([0.6247294 , 0.02339509, 0.13026509, 0.08672173, 0.10249739,\n",
       "         0.03239122], dtype=float32),\n",
       "  array([0.1083585 , 0.01312177, 0.01057089, 0.01035559, 0.00892518,\n",
       "         0.8486681 ], dtype=float32),\n",
       "  array([0.04639998, 0.01179351, 0.00738334, 0.00801863, 0.00606349,\n",
       "         0.9203411 ], dtype=float32),\n",
       "  array([0.02508436, 0.570302  , 0.3197783 , 0.01244256, 0.01944491,\n",
       "         0.05294798], dtype=float32),\n",
       "  array([0.02181609, 0.8381005 , 0.08792671, 0.0096268 , 0.01915547,\n",
       "         0.02337447], dtype=float32),\n",
       "  array([0.09503902, 0.05910854, 0.7409022 , 0.0248581 , 0.05473443,\n",
       "         0.02535774], dtype=float32),\n",
       "  array([0.9617954 , 0.00355008, 0.00647404, 0.01236098, 0.00710309,\n",
       "         0.00871653], dtype=float32),\n",
       "  array([0.04627024, 0.02405546, 0.01175029, 0.01416134, 0.01054232,\n",
       "         0.8932203 ], dtype=float32),\n",
       "  ...],\n",
       " [5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  ...],\n",
       " [5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inteventions_labels_model.train_model(interventions_df, interventions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.032526 140029104518976 base_bert_model.py:424] Writing example 0 of 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.033796 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.034743 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] che ##mis ##or ##ption [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.035679 140029104518976 base_bert_model.py:403] tokens: [CLS] che ##mis ##or ##ption [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 18178 15630 2953 16790 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.036793 140029104518976 base_bert_model.py:404] input_ids: 101 18178 15630 2953 16790 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.037799 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.038380 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.038874 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.039826 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.040695 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] multi ##no ##de cutting [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.041447 140029104518976 base_bert_model.py:403] tokens: [CLS] multi ##no ##de cutting [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4800 3630 3207 6276 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.042226 140029104518976 base_bert_model.py:404] input_ids: 101 4800 3630 3207 6276 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.043085 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.044028 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.044747 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.045825 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.048342 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] pu ##lver ##ization crop residue [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.049125 140029104518976 base_bert_model.py:403] tokens: [CLS] pu ##lver ##ization crop residue [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 16405 26229 3989 10416 21755 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.049974 140029104518976 base_bert_model.py:404] input_ids: 101 16405 26229 3989 10416 21755 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.050677 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.051244 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.051766 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.053122 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.054093 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] layer ch ##rom ##ato ##graphy [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.054870 140029104518976 base_bert_model.py:403] tokens: [CLS] layer ch ##rom ##ato ##graphy [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6741 10381 21716 10610 12565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.055639 140029104518976 base_bert_model.py:404] input_ids: 101 6741 10381 21716 10610 12565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.056957 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.057629 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.058496 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.059924 140029104518976 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.060843 140029104518976 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] partial ni ##tri ##tation ana ##mm ##ox [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.061635 140029104518976 base_bert_model.py:403] tokens: [CLS] partial ni ##tri ##tation ana ##mm ##ox [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7704 9152 18886 12516 9617 7382 11636 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.062389 140029104518976 base_bert_model.py:404] input_ids: 101 7704 9152 18886 12516 9617 7382 11636 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.063104 140029104518976 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.063998 140029104518976 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.065573 140029104518976 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:47.221413 140029104518976 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:50.609883 140029104518976 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:50.772314 140029104518976 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:51.250241 140029104518976 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:51.252453 140029104518976 saver.py:1270] Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:52.166684 140029104518976 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 10:54:52.266193 140029104518976 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112   2  10   2   1   8]\n",
      " [  3  35   2   0   0   7]\n",
      " [  8   0  18   0   0   2]\n",
      " [  5   0   0  21   1   0]\n",
      " [  4   0   0   0  20   0]\n",
      " [ 43   5   1   6   3  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72       135\n",
      "           1       0.83      0.74      0.79        47\n",
      "           2       0.58      0.64      0.61        28\n",
      "           3       0.72      0.78      0.75        27\n",
      "           4       0.80      0.83      0.82        24\n",
      "           5       0.83      0.58      0.68       139\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       400\n",
      "   macro avg       0.73      0.74      0.73       400\n",
      "weighted avg       0.74      0.72      0.72       400\n",
      "\n",
      "F1 score:  0.7281896375048352\n"
     ]
    }
   ],
   "source": [
    "res = inteventions_labels_model.evaluate_model(test_interventions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01571067 0.8379847  0.05253926 0.00792936 0.00825082 0.07758525] 1 Socioeconomic intervention private sector\n",
      "[0.01771423 0.8335716  0.09434523 0.00740228 0.01137348 0.03559314] 1 Socioeconomic intervention health policy highlight role worker education\n",
      "[0.01284049 0.85629463 0.07896289 0.00879947 0.01383512 0.02926752] 1 Socioeconomic intervention private sector farmer trainer\n",
      "[0.01270589 0.82621646 0.11102252 0.00902549 0.01552711 0.02550257] 1 Socioeconomic intervention social technology benefit family farmer\n",
      "[0.18822783 0.5615814  0.1188187  0.02100698 0.03369654 0.07666864] 1 Socioeconomic intervention hired human labour\n",
      "[0.12892666 0.5602191  0.0760889  0.01462096 0.01289417 0.2072502 ] 1 Socioeconomic intervention PDO scheme # provision DO\n",
      "[0.4825499  0.10342997 0.34748745 0.01835041 0.0313118  0.01687042] 0 Technology intervention improving performance participatory irrigation management reform\n",
      "[0.02593041 0.67483234 0.04948941 0.0087673  0.00661365 0.23436691] 1 Socioeconomic intervention foreign aid\n",
      "[0.01626195 0.8472821  0.08777186 0.00999775 0.01841582 0.02027048] 1 Socioeconomic intervention rural income generating initiative\n",
      "[0.03162001 0.10579606 0.01623772 0.00810997 0.00553372 0.83270246] 5 Non-intervention entrepreneurship\n",
      "[0.01304545 0.84372824 0.08624181 0.00689221 0.01044783 0.03964438] 1 Socioeconomic intervention public good tradable service\n",
      "[0.01829864 0.8646392  0.06892303 0.00573051 0.00917132 0.03323717] 1 Socioeconomic intervention subsidy food\n",
      "[0.02160316 0.84261465 0.08052959 0.00941321 0.0187587  0.02708078] 1 Socioeconomic intervention price stabilization mechanism\n",
      "[0.03701022 0.82390267 0.04064187 0.00887263 0.00701893 0.08255363] 1 Socioeconomic intervention farmer education\n",
      "[0.05715571 0.10508547 0.01858825 0.00775295 0.00600472 0.8054129 ] 5 Non-intervention technical communication\n"
     ]
    }
   ],
   "source": [
    "for i in range(45, 60):\n",
    "    print(res[0][i], res[1][i], id2class[res[1][i]], test_interventions_df[\"Narrow concept\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def cross_validation(clf, x_train,y_train,kfolds=10):\n",
    "    y_train_array = np.asarray(y_train)\n",
    "    skfolds = StratifiedKFold(n_splits=kfolds, random_state=42)\n",
    "    scores = []\n",
    "    for train_index, test_index in skfolds.split(x_train,y_train):\n",
    "        clone_clf = clone(clf)\n",
    "        x_train_folds = x_train[train_index]\n",
    "        y_train_folds = y_train_array[train_index]\n",
    "        x_test_folds = x_train[test_index]\n",
    "        y_test_folds = y_train_array[test_index]\n",
    "\n",
    "        clone_clf.fit(x_train_folds, y_train_folds)\n",
    "        y_pred = clone_clf.predict(x_test_folds)\n",
    "        scores.append(f1_score(y_test_folds, y_pred, average=\"macro\"))\n",
    "    return np.asarray(scores)\n",
    "\n",
    "def train_svm(train_x, train_y, test_x, test_y):\n",
    "    svclassifier = SVC(kernel='rbf', probability=True, class_weight={0:2, 1:3,2:4, 3:4, 4:4, 5:3 })  \n",
    "    svclassifier.fit(train_x, train_y)\n",
    "\n",
    "    scores = cross_validation(svclassifier, np.concatenate((train_x,test_x),axis=0), train_y+test_y)\n",
    "    print(scores)\n",
    "    print(\"Cross validation score(F1): %f\"%(scores.mean()))\n",
    "    print(\"Test accuracy : %f\" %(svclassifier.score(test_x,test_y)))\n",
    "    return svclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "google_model = gensim.models.Word2Vec.load(os.path.join(\"../model/synonyms_retrained_new\",\"google_plus_our_dataset/\", \"google_plus_our_dataset.model\"))\n",
    "fast_text_model = gensim.models.Word2Vec.load(os.path.join(\"../model/synonyms_retrained_new\",\"fast_text_our_dataset/\", \"fast_text_our_dataset.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser \n",
    "phrases = Phraser.load(os.path.join(\"../model/synonyms_retrained_new\",\"phrases_3gram.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('serogroups O26', 0.4490981101989746),\n",
       " ('serogroups', 0.4481642246246338),\n",
       " ('O157 serogroups', 0.43964269757270813),\n",
       " ('serological assay', 0.4087376892566681),\n",
       " ('mitis', 0.4040156304836273),\n",
       " ('serovar enteritidis', 0.4038276970386505),\n",
       " ('serotype enteritidis', 0.40310582518577576),\n",
       " ('antigen ELISA', 0.4030936360359192),\n",
       " ('serovars', 0.39805352687835693),\n",
       " ('viral antigen', 0.3973124027252197)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_model.most_similar(\"CSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing import text_normalizer\n",
    "def get_word_expression_embedding(sentence, filter_apply = False):\n",
    "    word_expressions = set()\n",
    "    for sent in sentence.split(\";\"):\n",
    "        for phr in phrases[text_normalizer.get_stemmed_words_inverted_index(text_normalizer.normalize_text(sent.strip()))]:\n",
    "            if not filter_apply:\n",
    "                word_expressions.add(phr.replace(\"_\", \" \"))\n",
    "    vec = np.zeros(300)\n",
    "    for word in word_expressions:\n",
    "        #if word in google_model.wv:\n",
    "        #    vec += google_model.wv[word]\n",
    "        if word in fast_text_model.wv:\n",
    "            vec += fast_text_model.wv[word]\n",
    "        else:\n",
    "            print(\"%s is not found (%s)\"%(word, sentence))\n",
    "    return vec if len(word_expressions) == 0 else vec/(len(word_expressions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = interventions_df.values\n",
    "test_data = test_interventions_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6868582  0.69481831 0.70105906 0.68207892 0.70524057 0.73227655\n",
      " 0.63851446 0.62117397 0.83326245 0.78933149]\n",
      "Cross validation score(F1): 0.708461\n",
      "Test accuracy : 0.822500\n",
      "[[112   2   1   3   0  17]\n",
      " [  1  41   0   0   0   5]\n",
      " [  2   0  25   0   0   1]\n",
      " [  3   0   0  22   0   2]\n",
      " [  0   0   0   0  24   0]\n",
      " [ 28   1   1   4   0 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       135\n",
      "           1       0.93      0.87      0.90        47\n",
      "           2       0.93      0.89      0.91        28\n",
      "           3       0.76      0.81      0.79        27\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       0.81      0.76      0.78       139\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       400\n",
      "   macro avg       0.87      0.86      0.86       400\n",
      "weighted avg       0.83      0.82      0.82       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "train_x, train_y = [np.concatenate((get_word_expression_embedding(data[0]), get_word_expression_embedding(data[0]+\";\"+data[1]))) for data in train_data], [data[-1] for data in train_data]\n",
    "test_x, test_y = [np.concatenate((get_word_expression_embedding(data[0]), get_word_expression_embedding(data[0]+\";\"+data[1]))) for data in test_data], [data[-1] for data in test_data]\n",
    "svclassifier = train_svm(train_x, train_y, test_x, test_y)\n",
    "y_pred = svclassifier.predict(test_x)\n",
    "print(confusion_matrix(test_y,y_pred))  \n",
    "print(classification_report(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N is not found (biogas residue;test impact application various N containing organic substrate OS)\n",
      "K is not found (NPK # nitrogen phosphoruspotassium;management practice MP;K application)\n",
      "K is not found (NK # natural killer;balanced application;K application)\n",
      "N is not found (soil N storage)\n",
      "N is not found (soil N storage;soil water storage ; storage intervention)\n",
      "P is not found (P truncatus # )\n",
      "P is not found (P truncatus # ;P truncatus;storage intervention)\n",
      "N is not found (tropical pasture;N isotope dilution technique)\n",
      "L is not found (reduced level L dopa)\n",
      "L is not found (reduced level L dopa;processing technique)\n",
      "W is not found (programme;programme;programme;certification programme;programme;PBB programme;reintroduction programme;programme;W salutaris reintroduction programme;programme;major cocoa intervention programme;programme;redistributive land reform programme;programme;fast track land reform programme;programme;homestead food garden programme;programme;SMS programme;programme;agriculture input support programme;input programme;programme target;programme;programme;SAFE programme;SAFE training programme;programme;cassava research programme;programme;agroforestry technology;food security programme;year programme FS FSP;programme;P4P programme;programme;portfolio based programme;programme;formal ALUS programme alternative land use service;programme;genetic resource conservation programme GR CRP;programme;horticulture programme;programme;postgraduate programme;programme;entire programme;LTR programme;programme;LTR programme implementation;land tenure reform programme land tenure reform;programme;LHF programme;program;capacity building program;programme coordinator;programme PC;programme;counterfactual approach;ACRE programme;programme;direct payment programme average crop revenue election DP DPP;SERVIR programme;programme;capacity building programme CB CBP;programme;management practice programme;PSNP programme;programme;OFSP HABP programme productive safety net programme household asset building programme;programme;IPM programme staff;programme period;IPM programme;programme;hour training programme;programme;sterile insect technique SIT;programme;farm deliberative learning demonstration programme;programme;FFR programme;programme;state programme;programme based approach;programme;programme;high bush blueberry breeding programme;programme household;programme;backyard poultry improvement technology programme;programme;programme;NGO programme;NGO school garden programme;long term programme PW;programme LT;programme;promotional programme;programme;empowerment programme;programme;national conservation programme;input programme;NSPFS programme;programme;SPFS programme national special programme food security;national IPM programme;programme;IPM programme integrated pest management;programme;organized programme;project demonstration programme;programme;wine sector environmental programme;programme;monitoring programme;oblast level programme;programme;monitoring programme;AE programme;agri environmental AE programme;national monitoring programme agronomic efficiency AEM;programme;long term agricultural programme;emergency programme;programme;entire programme;programme;SWITCH programme;programme;ALV programme;programme site;programme;programme;eradication programme;programme;training programme;programme intervention;programme;programme;USDA disaster assistance programme;orchestrated agricultural intervention programme;programme;programme;GRP programme;programme;community based organic agriculture programme;programme;governmental programme;programme;generic advertising programme;subsidized fertilizer programme;programme;government programme;programme;farm investment support programme;water wastewater utility regulatory compliance sustainability initiative;tight innovation bottleneck;programme;programme;government agricultural programme;programme;adaptation programme;programme;insurance programme;entire programme;livestock insurance programme;programme;MNREGA programme)\n",
      "N is not found (basin;N input;excess phosphorus input PTI)\n",
      "N is not found (LI # low input;input;intervention;organic low input;confirm applicability digital imagery technique extract green leaf area estimating light interception;interviewed using standardized listeria initiative;adapted genetic material low input;non certified low input;N ha year low input)\n",
      "C is not found (KC # knudson C)\n",
      "C is not found (KC # knudson C;polycrystalline PV technology)\n",
      "E is not found (E learning agent)\n",
      "E is not found (E learning agent;following design approach)\n",
      "C is not found (soil C input)\n",
      "C is not found (soil C input;soil C input)\n",
      "N is not found (N fertilizer replacement)\n",
      "N is not found (N fertilizer replacement;approach)\n",
      "N is not found (N fi xation rate)\n",
      "N is not found (N fi xation rate;input)\n",
      "E is not found (developing country biodiesel;renewable energy policy RES E)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76054001 0.68365907 0.70723898 0.71808305 0.67094814 0.67084935\n",
      " 0.6862152  0.6894261  0.82469537 0.76044485]\n",
      "Cross validation score(F1): 0.717210\n",
      "Test accuracy : 0.750000\n",
      "[[ 91   1   5   3   0  35]\n",
      " [  0  40   0   0   0   7]\n",
      " [  3   1  21   0   0   3]\n",
      " [  4   0   0  20   0   3]\n",
      " [  0   0   0   0  21   3]\n",
      " [ 26   2   2   2   0 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       135\n",
      "           1       0.91      0.85      0.88        47\n",
      "           2       0.75      0.75      0.75        28\n",
      "           3       0.80      0.74      0.77        27\n",
      "           4       1.00      0.88      0.93        24\n",
      "           5       0.68      0.77      0.72       139\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       400\n",
      "   macro avg       0.81      0.78      0.79       400\n",
      "weighted avg       0.76      0.75      0.75       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "train_x, train_y = [np.concatenate((get_word_expression_embedding(data[0]), get_word_expression_embedding(data[0]+\";\"+data[1]))) for data in train_data], [data[-1] for data in train_data]\n",
    "test_x, test_y = [np.concatenate((get_word_expression_embedding(data[0]), get_word_expression_embedding(data[0]+\";\"+data[1]))) for data in test_data], [data[-1] for data in test_data]\n",
    "svclassifier = train_svm(train_x, train_y, test_x, test_y)\n",
    "y_pred = svclassifier.predict(test_x)\n",
    "print(confusion_matrix(test_y,y_pred))  \n",
    "print(classification_report(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66896899 0.70016271 0.68699353 0.67177482 0.57250327 0.64002391\n",
      " 0.45791393 0.54588504 0.71300007 0.81116551]\n",
      "Cross validation score(F1): 0.646839\n",
      "Test accuracy : 0.825000\n",
      "[[113   0   2   4   1  15]\n",
      " [  2  44   0   0   0   1]\n",
      " [  4   0  22   1   0   1]\n",
      " [  1   0   0  23   0   3]\n",
      " [  0   0   0   0  24   0]\n",
      " [ 31   0   1   3   0 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       135\n",
      "           1       1.00      0.94      0.97        47\n",
      "           2       0.88      0.79      0.83        28\n",
      "           3       0.74      0.85      0.79        27\n",
      "           4       0.96      1.00      0.98        24\n",
      "           5       0.84      0.75      0.79       139\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.83      0.82      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = [get_word_expression_embedding(data[0]) for data in train_data], [data[-1] for data in train_data]\n",
    "test_x, test_y = [get_word_expression_embedding(data[0]) for data in test_data], [data[-1] for data in test_data]\n",
    "svclassifier = train_svm(train_x, train_y, test_x, test_y)\n",
    "y_pred = svclassifier.predict(test_x)\n",
    "print(confusion_matrix(test_y,y_pred))  \n",
    "print(classification_report(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.431395 140031605708608 base_bert_model.py:424] Writing example 0 of 2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.433030 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.434014 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] fe ##rti ##lizer [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.435069 140031605708608 base_bert_model.py:403] tokens: [CLS] fe ##rti ##lizer [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10768 28228 28863 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.436490 140031605708608 base_bert_model.py:404] input_ids: 101 10768 28228 28863 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.437480 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.438616 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.439546 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.440616 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.441499 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] conservation measure [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.442330 140031605708608 base_bert_model.py:403] tokens: [CLS] conservation measure [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5680 5468 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.443315 140031605708608 base_bert_model.py:404] input_ids: 101 5680 5468 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.444989 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.445806 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.446653 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.448319 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.449156 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] irrigation [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.450796 140031605708608 base_bert_model.py:403] tokens: [CLS] irrigation [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 12442 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.451545 140031605708608 base_bert_model.py:404] input_ids: 101 12442 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.452339 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.452977 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.453639 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.454410 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.455127 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] sole maize [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.455754 140031605708608 base_bert_model.py:403] tokens: [CLS] sole maize [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7082 21154 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.456766 140031605708608 base_bert_model.py:404] input_ids: 101 7082 21154 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.457521 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.458829 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.460516 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.464669 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.466870 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] breed dairy cow [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.467354 140031605708608 base_bert_model.py:403] tokens: [CLS] breed dairy cow [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 8843 11825 11190 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.468486 140031605708608 base_bert_model.py:404] input_ids: 101 8843 11825 11190 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.469450 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.470598 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:00.471444 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:01.354815 140031605708608 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:04.376575 140031605708608 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:04.522037 140031605708608 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:05.055284 140031605708608 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 11:50:05.057170 140031605708608 deprecation.py:323] From /home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:05.058663 140031605708608 saver.py:1270] Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:06.030470 140031605708608 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:06.129127 140031605708608 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.892004 140031605708608 base_bert_model.py:424] Writing example 0 of 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.893232 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.894566 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] che ##mis ##or ##ption [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.898114 140031605708608 base_bert_model.py:403] tokens: [CLS] che ##mis ##or ##ption [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 18178 15630 2953 16790 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.899964 140031605708608 base_bert_model.py:404] input_ids: 101 18178 15630 2953 16790 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.903455 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.904205 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.905182 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.906430 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.907539 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] multi ##no ##de cutting [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.908806 140031605708608 base_bert_model.py:403] tokens: [CLS] multi ##no ##de cutting [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4800 3630 3207 6276 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.909816 140031605708608 base_bert_model.py:404] input_ids: 101 4800 3630 3207 6276 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.910479 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.911001 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.911498 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.912447 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.913470 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] pu ##lver ##ization crop residue [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.914360 140031605708608 base_bert_model.py:403] tokens: [CLS] pu ##lver ##ization crop residue [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 16405 26229 3989 10416 21755 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.915348 140031605708608 base_bert_model.py:404] input_ids: 101 16405 26229 3989 10416 21755 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.916314 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.917213 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.919707 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.920935 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.921959 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] layer ch ##rom ##ato ##graphy [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.922858 140031605708608 base_bert_model.py:403] tokens: [CLS] layer ch ##rom ##ato ##graphy [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6741 10381 21716 10610 12565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.923726 140031605708608 base_bert_model.py:404] input_ids: 101 6741 10381 21716 10610 12565 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.925457 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.926427 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.927447 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.928972 140031605708608 base_bert_model.py:400] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.929916 140031605708608 base_bert_model.py:401] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] partial ni ##tri ##tation ana ##mm ##ox [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.930816 140031605708608 base_bert_model.py:403] tokens: [CLS] partial ni ##tri ##tation ana ##mm ##ox [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7704 9152 18886 12516 9617 7382 11636 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.931771 140031605708608 base_bert_model.py:404] input_ids: 101 7704 9152 18886 12516 9617 7382 11636 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.932688 140031605708608 base_bert_model.py:405] input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.934186 140031605708608 base_bert_model.py:406] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:10.935126 140031605708608 base_bert_model.py:407] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:11.096248 140031605708608 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used for model gpu 1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:13.959781 140031605708608 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:14.106096 140031605708608 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:14.898720 140031605708608 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:14.901948 140031605708608 saver.py:1270] Restoring parameters from interventions_model_1/model.ckpt-94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:15.752493 140031605708608 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0611 11:50:15.845058 140031605708608 session_manager.py:493] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "train_pred = inteventions_labels_model.predict_for_df(interventions_df)\n",
    "test_pred = inteventions_labels_model.predict_for_df(test_interventions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_pred = svclassifier.predict_proba(train_x)\n",
    "svc_test_pred = svclassifier.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_x = np.concatenate([train_pred[0], svc_train_pred],axis=1)\n",
    "ada_boost_test_x = np.concatenate([test_pred[0], svc_test_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325\n",
      "0.9825697211155379\n",
      "[0.97416767 0.97545397 0.96636475 0.97370356 0.98386272 1.\n",
      " 0.96877609 0.93511161 0.95004567 0.8233722 ]\n",
      "Cross validation score(F1): 0.955086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n",
    "boost = GradientBoostingClassifier(n_estimators  = 50, max_depth=1)\n",
    "boost.fit(ada_boost_x, train_y)\n",
    "print(boost.score(ada_boost_test_x, test_y))\n",
    "print(boost.score(ada_boost_x, train_y))\n",
    "\n",
    "scores = cross_validation(boost, np.concatenate((ada_boost_x,ada_boost_test_x),axis=0), train_y+test_y)\n",
    "print(scores)\n",
    "print(\"Cross validation score(F1): %f\"%(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_train = boost.predict(ada_boost_x)\n",
    "adaboost_test = boost.predict(ada_boost_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   0   3   3   1   8]\n",
      " [  2  45   0   0   0   0]\n",
      " [  6   0  21   0   0   1]\n",
      " [  3   0   0  21   0   3]\n",
      " [  0   0   0   0  24   0]\n",
      " [ 33   0   0   3   1 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80       135\n",
      "           1       1.00      0.96      0.98        47\n",
      "           2       0.88      0.75      0.81        28\n",
      "           3       0.78      0.78      0.78        27\n",
      "           4       0.92      1.00      0.96        24\n",
      "           5       0.89      0.73      0.81       139\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       400\n",
      "   macro avg       0.87      0.85      0.86       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y,adaboost_test))  \n",
    "print(classification_report(test_y,adaboost_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12875007, 0.00452847, 0.00171272, 0.02193731, 0.0041636 ,\n",
       "       0.03223092, 0.17300299, 0.14202616, 0.09167584, 0.0567563 ,\n",
       "       0.07749626, 0.26571935])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizer loading\n",
      "Model partly loaded\n",
      "Tokenizrer loaded\n",
      "Config is done\n"
     ]
    }
   ],
   "source": [
    "from bert_models import base_bert_model_interventions\n",
    "base_bert_model_interventions = reload(base_bert_model_interventions)\n",
    "inteventions_labels_model = base_bert_model_interventions.BaseBertModelInterventions(\"interventions_model_2\", list(range(6)), gpu_device_num_hub=1, gpu_device_num =2, \n",
    "                                                         batch_size = 64, max_seq_length = 64, label_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "interventions_df = shuffle(interventions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryia_pavlovets/.conda/envs/maryia_pavlovets_env/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:00:59.565586\n",
      "[[652   2   1   2   1  19]\n",
      " [  6 202   0   1   1  27]\n",
      " [ 15   1 114   0   1  11]\n",
      " [  2   0   0 122   0   2]\n",
      " [  2   2   0   0 120   0]\n",
      " [  7   6   3   0   2 676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       677\n",
      "           1       0.95      0.85      0.90       237\n",
      "           2       0.97      0.80      0.88       142\n",
      "           3       0.98      0.97      0.97       126\n",
      "           4       0.96      0.97      0.96       124\n",
      "           5       0.92      0.97      0.95       694\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2000\n",
      "   macro avg       0.95      0.92      0.94      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n",
      "F1 score:  0.9358171709079709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([0.05229361, 0.01952783, 0.00848623, 0.00901349, 0.00448894,\n",
       "         0.9061899 ], dtype=float32),\n",
       "  array([0.9075118 , 0.00489847, 0.01592019, 0.00443122, 0.00252644,\n",
       "         0.06471194], dtype=float32),\n",
       "  array([0.02205618, 0.5290204 , 0.18156017, 0.01430384, 0.05696338,\n",
       "         0.19609602], dtype=float32),\n",
       "  array([0.12718034, 0.07060011, 0.6467324 , 0.00922467, 0.0215151 ,\n",
       "         0.12474736], dtype=float32),\n",
       "  array([0.02730835, 0.05585728, 0.01050799, 0.00549356, 0.00369883,\n",
       "         0.89713395], dtype=float32),\n",
       "  array([0.0096434 , 0.5305489 , 0.3456425 , 0.01618847, 0.04350143,\n",
       "         0.05447536], dtype=float32),\n",
       "  array([0.02397994, 0.01092679, 0.01001079, 0.894642  , 0.03740696,\n",
       "         0.02303355], dtype=float32),\n",
       "  array([0.8612951 , 0.0106662 , 0.02007181, 0.03230768, 0.00744174,\n",
       "         0.06821734], dtype=float32),\n",
       "  array([0.7959355 , 0.01039973, 0.09092808, 0.00785386, 0.00714185,\n",
       "         0.08774102], dtype=float32),\n",
       "  array([0.03420011, 0.03710824, 0.0105368 , 0.00668563, 0.00483304,\n",
       "         0.90663624], dtype=float32),\n",
       "  array([0.2364479 , 0.0153994 , 0.01222537, 0.00822026, 0.00391683,\n",
       "         0.7237902 ], dtype=float32),\n",
       "  array([0.90185386, 0.00729829, 0.02423121, 0.0134695 , 0.00552675,\n",
       "         0.04762041], dtype=float32),\n",
       "  array([0.05343496, 0.05440564, 0.0127788 , 0.00474101, 0.00340241,\n",
       "         0.8712372 ], dtype=float32),\n",
       "  array([0.03508999, 0.10684481, 0.02133067, 0.00689704, 0.00550351,\n",
       "         0.82433397], dtype=float32),\n",
       "  array([0.04233225, 0.13405076, 0.37237048, 0.01487419, 0.0417779 ,\n",
       "         0.39459443], dtype=float32),\n",
       "  array([0.29403988, 0.01608539, 0.01444785, 0.00522363, 0.00401166,\n",
       "         0.66619164], dtype=float32),\n",
       "  array([0.03785598, 0.02593666, 0.00969323, 0.03650305, 0.00649641,\n",
       "         0.8835147 ], dtype=float32),\n",
       "  array([0.9095831 , 0.00915133, 0.04210728, 0.00660097, 0.00459916,\n",
       "         0.02795821], dtype=float32),\n",
       "  array([0.91411626, 0.00844123, 0.04196506, 0.00579588, 0.00395485,\n",
       "         0.02572677], dtype=float32),\n",
       "  array([0.01103677, 0.02336678, 0.03525989, 0.06351555, 0.8497895 ,\n",
       "         0.01703152], dtype=float32),\n",
       "  array([0.09164304, 0.03010502, 0.01085596, 0.00827835, 0.00631043,\n",
       "         0.8528073 ], dtype=float32),\n",
       "  array([0.32855752, 0.01274368, 0.01679109, 0.0082598 , 0.00466447,\n",
       "         0.62898344], dtype=float32),\n",
       "  array([0.9075454 , 0.00615824, 0.02774146, 0.00329561, 0.00276325,\n",
       "         0.05249612], dtype=float32),\n",
       "  array([0.93017083, 0.00712119, 0.02216795, 0.01001181, 0.00415365,\n",
       "         0.02637466], dtype=float32),\n",
       "  array([0.02367787, 0.09677231, 0.01969629, 0.00915564, 0.00701906,\n",
       "         0.8436788 ], dtype=float32),\n",
       "  array([0.91608673, 0.00813549, 0.04248684, 0.00542965, 0.00422923,\n",
       "         0.02363204], dtype=float32),\n",
       "  array([0.00784358, 0.03327823, 0.03041884, 0.06185595, 0.8422463 ,\n",
       "         0.02435707], dtype=float32),\n",
       "  array([0.0203675 , 0.05214135, 0.09625974, 0.06192442, 0.63638246,\n",
       "         0.13292448], dtype=float32),\n",
       "  array([0.04612676, 0.02644067, 0.0109143 , 0.00693893, 0.00423161,\n",
       "         0.9053477 ], dtype=float32),\n",
       "  array([0.87936765, 0.01261203, 0.04008381, 0.0275201 , 0.01026467,\n",
       "         0.03015178], dtype=float32),\n",
       "  array([0.9412311 , 0.00534184, 0.01514675, 0.00488093, 0.00273793,\n",
       "         0.03066148], dtype=float32),\n",
       "  array([0.92584616, 0.01003996, 0.02912985, 0.00847845, 0.00456088,\n",
       "         0.02194467], dtype=float32),\n",
       "  array([0.00919936, 0.02517682, 0.02962385, 0.05320923, 0.8614852 ,\n",
       "         0.02130553], dtype=float32),\n",
       "  array([0.04075246, 0.02042504, 0.00779009, 0.00962679, 0.00404413,\n",
       "         0.91736144], dtype=float32),\n",
       "  array([0.864688  , 0.00668228, 0.01944607, 0.00372112, 0.00242564,\n",
       "         0.10303689], dtype=float32),\n",
       "  array([0.85495436, 0.00908739, 0.05922421, 0.01348501, 0.02763117,\n",
       "         0.03561785], dtype=float32),\n",
       "  array([0.90903896, 0.00776457, 0.04451982, 0.00538826, 0.00382088,\n",
       "         0.02946748], dtype=float32),\n",
       "  array([0.9371062 , 0.00720284, 0.02269899, 0.00719739, 0.00426266,\n",
       "         0.02153189], dtype=float32),\n",
       "  array([0.0453894 , 0.08423337, 0.75938636, 0.01560155, 0.05041421,\n",
       "         0.04497512], dtype=float32),\n",
       "  array([0.06088457, 0.02306147, 0.02288673, 0.03443721, 0.02885913,\n",
       "         0.8298709 ], dtype=float32),\n",
       "  array([0.06296368, 0.08835272, 0.12147391, 0.0126251 , 0.0227411 ,\n",
       "         0.6918435 ], dtype=float32),\n",
       "  array([0.04927719, 0.02025178, 0.0078997 , 0.00688027, 0.00323123,\n",
       "         0.9124598 ], dtype=float32),\n",
       "  array([0.05024796, 0.02601295, 0.00841373, 0.00659231, 0.00515605,\n",
       "         0.90357697], dtype=float32),\n",
       "  array([0.07558346, 0.02833172, 0.01343781, 0.01343574, 0.00882553,\n",
       "         0.8603858 ], dtype=float32),\n",
       "  array([0.03196147, 0.13211882, 0.02191681, 0.00835467, 0.00674733,\n",
       "         0.7989009 ], dtype=float32),\n",
       "  array([0.9015745 , 0.00892664, 0.02827752, 0.01285491, 0.00595157,\n",
       "         0.04241485], dtype=float32),\n",
       "  array([0.8901669 , 0.00913521, 0.02553846, 0.00806766, 0.00325762,\n",
       "         0.06383411], dtype=float32),\n",
       "  array([0.02584467, 0.0372887 , 0.01012989, 0.03431913, 0.01290513,\n",
       "         0.8795125 ], dtype=float32),\n",
       "  array([0.09180977, 0.02254795, 0.0109735 , 0.00530733, 0.00507001,\n",
       "         0.8642914 ], dtype=float32),\n",
       "  array([0.01867104, 0.5763376 , 0.12763466, 0.01030476, 0.01597895,\n",
       "         0.251073  ], dtype=float32),\n",
       "  array([0.01041384, 0.5472636 , 0.14473215, 0.04768275, 0.21398123,\n",
       "         0.03592648], dtype=float32),\n",
       "  array([0.07154656, 0.01710523, 0.01045829, 0.00945506, 0.00532174,\n",
       "         0.88611317], dtype=float32),\n",
       "  array([0.86023015, 0.01377468, 0.03974136, 0.02622934, 0.00820669,\n",
       "         0.0518178 ], dtype=float32),\n",
       "  array([0.93041575, 0.00493829, 0.01534457, 0.00665014, 0.00316648,\n",
       "         0.03948484], dtype=float32),\n",
       "  array([0.02251153, 0.1251605 , 0.7413487 , 0.01889255, 0.0546836 ,\n",
       "         0.03740316], dtype=float32),\n",
       "  array([0.03744506, 0.05621961, 0.01166456, 0.00868804, 0.00549723,\n",
       "         0.8804855 ], dtype=float32),\n",
       "  array([0.00833074, 0.8308874 , 0.07292048, 0.01063152, 0.0212769 ,\n",
       "         0.05595309], dtype=float32),\n",
       "  array([0.9297922 , 0.00570249, 0.01623468, 0.00467934, 0.00261815,\n",
       "         0.04097312], dtype=float32),\n",
       "  array([0.02513639, 0.48193777, 0.0849976 , 0.00840754, 0.01067575,\n",
       "         0.38884494], dtype=float32),\n",
       "  array([0.07170519, 0.46711993, 0.35281456, 0.0134258 , 0.02155015,\n",
       "         0.07338433], dtype=float32),\n",
       "  array([0.04313515, 0.01782787, 0.00931058, 0.0165373 , 0.00896167,\n",
       "         0.9042274 ], dtype=float32),\n",
       "  array([0.90636915, 0.01023273, 0.0404354 , 0.01091349, 0.00728708,\n",
       "         0.02476216], dtype=float32),\n",
       "  array([0.03588809, 0.04966132, 0.01767882, 0.05523381, 0.02065015,\n",
       "         0.8208878 ], dtype=float32),\n",
       "  array([0.94110614, 0.00653732, 0.02008935, 0.00531777, 0.00295523,\n",
       "         0.02399415], dtype=float32),\n",
       "  array([0.07981059, 0.03678516, 0.01657348, 0.01596237, 0.01582286,\n",
       "         0.8350456 ], dtype=float32),\n",
       "  array([0.01122832, 0.79312253, 0.04794167, 0.00924115, 0.01394099,\n",
       "         0.12452537], dtype=float32),\n",
       "  array([0.90485907, 0.007262  , 0.0276966 , 0.00544398, 0.003048  ,\n",
       "         0.05169037], dtype=float32),\n",
       "  array([0.03444521, 0.09746397, 0.01425057, 0.05229211, 0.01010583,\n",
       "         0.79144233], dtype=float32),\n",
       "  array([0.05243073, 0.03232035, 0.01729937, 0.00598819, 0.0047948 ,\n",
       "         0.88716656], dtype=float32),\n",
       "  array([0.02428364, 0.50296384, 0.0650572 , 0.00872614, 0.01068769,\n",
       "         0.3882815 ], dtype=float32),\n",
       "  array([0.02676854, 0.04682596, 0.01044599, 0.00616221, 0.00428698,\n",
       "         0.90551037], dtype=float32),\n",
       "  array([0.9221219 , 0.00525688, 0.01459304, 0.00575549, 0.00269845,\n",
       "         0.04957433], dtype=float32),\n",
       "  array([0.06583085, 0.03816278, 0.01127211, 0.00434533, 0.00310706,\n",
       "         0.8772819 ], dtype=float32),\n",
       "  array([0.10032051, 0.09730735, 0.03164056, 0.00911968, 0.00822542,\n",
       "         0.7533865 ], dtype=float32),\n",
       "  array([0.01809038, 0.25587115, 0.03027924, 0.00752196, 0.00676858,\n",
       "         0.68146867], dtype=float32),\n",
       "  array([0.07820272, 0.02592172, 0.01112841, 0.00534232, 0.00526719,\n",
       "         0.8741377 ], dtype=float32),\n",
       "  array([0.02535296, 0.03208654, 0.00770292, 0.00570371, 0.00396921,\n",
       "         0.92518467], dtype=float32),\n",
       "  array([0.03474606, 0.02779987, 0.00730269, 0.00956252, 0.00486152,\n",
       "         0.9157273 ], dtype=float32),\n",
       "  array([0.28522685, 0.0122164 , 0.02394186, 0.00882242, 0.00445347,\n",
       "         0.665339  ], dtype=float32),\n",
       "  array([0.02388247, 0.05123728, 0.0097443 , 0.0126441 , 0.00604663,\n",
       "         0.8964452 ], dtype=float32),\n",
       "  array([0.01287433, 0.7224823 , 0.06646915, 0.01091242, 0.01864385,\n",
       "         0.16861789], dtype=float32),\n",
       "  array([0.03606302, 0.03622801, 0.01615451, 0.63488764, 0.02542598,\n",
       "         0.25124085], dtype=float32),\n",
       "  array([0.15105854, 0.06191058, 0.68350405, 0.01278713, 0.03368315,\n",
       "         0.05705662], dtype=float32),\n",
       "  array([0.01528066, 0.41853508, 0.0275796 , 0.00977706, 0.0119971 ,\n",
       "         0.51683044], dtype=float32),\n",
       "  array([0.9297782 , 0.00556193, 0.0165191 , 0.00548581, 0.00299974,\n",
       "         0.03965516], dtype=float32),\n",
       "  array([0.08861806, 0.45973969, 0.15283059, 0.00843478, 0.02015306,\n",
       "         0.2702238 ], dtype=float32),\n",
       "  array([0.01959247, 0.01422097, 0.01001981, 0.8974052 , 0.02433483,\n",
       "         0.03442673], dtype=float32),\n",
       "  array([0.46761176, 0.03770069, 0.30366364, 0.06165034, 0.07169362,\n",
       "         0.05768001], dtype=float32),\n",
       "  array([0.94600624, 0.00488123, 0.01627579, 0.00557268, 0.00294026,\n",
       "         0.02432389], dtype=float32),\n",
       "  array([0.93769175, 0.00582697, 0.01600003, 0.00476819, 0.00268569,\n",
       "         0.03302742], dtype=float32),\n",
       "  array([0.05119677, 0.03740276, 0.01177571, 0.00764411, 0.00576434,\n",
       "         0.8862163 ], dtype=float32),\n",
       "  array([0.08035697, 0.02487583, 0.00926424, 0.01613228, 0.00352484,\n",
       "         0.86584586], dtype=float32),\n",
       "  array([0.01894858, 0.02506781, 0.02889965, 0.10041475, 0.8011757 ,\n",
       "         0.02549343], dtype=float32),\n",
       "  array([0.929755  , 0.00903811, 0.02845164, 0.00625165, 0.00370804,\n",
       "         0.02279568], dtype=float32),\n",
       "  array([0.93551326, 0.00788686, 0.02447862, 0.00708454, 0.00391799,\n",
       "         0.02111883], dtype=float32),\n",
       "  array([0.03282591, 0.03774339, 0.008376  , 0.01200944, 0.00844155,\n",
       "         0.90060365], dtype=float32),\n",
       "  array([0.87013626, 0.01021944, 0.05296129, 0.01512307, 0.01654959,\n",
       "         0.0350104 ], dtype=float32),\n",
       "  array([0.8979144 , 0.01048211, 0.0545674 , 0.00582057, 0.00468738,\n",
       "         0.02652818], dtype=float32),\n",
       "  array([0.93884623, 0.0055184 , 0.01786945, 0.00518623, 0.00313854,\n",
       "         0.02944118], dtype=float32),\n",
       "  array([0.02912778, 0.0250154 , 0.00721071, 0.01296542, 0.00536019,\n",
       "         0.9203205 ], dtype=float32),\n",
       "  array([0.92558986, 0.00757522, 0.02842184, 0.00447645, 0.00327872,\n",
       "         0.03065784], dtype=float32),\n",
       "  array([0.00915743, 0.02374757, 0.02881043, 0.05659465, 0.8634857 ,\n",
       "         0.01820422], dtype=float32),\n",
       "  array([0.05592136, 0.0228287 , 0.00836761, 0.01312537, 0.00497923,\n",
       "         0.8947777 ], dtype=float32),\n",
       "  array([0.9310219 , 0.00632425, 0.01749742, 0.00640594, 0.00275079,\n",
       "         0.03599973], dtype=float32),\n",
       "  array([0.06331865, 0.0998291 , 0.26564634, 0.01757817, 0.03830151,\n",
       "         0.5153262 ], dtype=float32),\n",
       "  array([0.06377456, 0.01605825, 0.00807193, 0.009223  , 0.00390812,\n",
       "         0.8989641 ], dtype=float32),\n",
       "  array([0.01796476, 0.02902201, 0.04844235, 0.07009599, 0.8103627 ,\n",
       "         0.02411211], dtype=float32),\n",
       "  array([0.04668669, 0.03184976, 0.01028393, 0.0068289 , 0.00349628,\n",
       "         0.90085447], dtype=float32),\n",
       "  array([0.05075013, 0.02631653, 0.00969579, 0.02690173, 0.00716448,\n",
       "         0.8791713 ], dtype=float32),\n",
       "  array([0.84540707, 0.01090783, 0.09262423, 0.00686716, 0.00804262,\n",
       "         0.03615112], dtype=float32),\n",
       "  array([0.02174407, 0.01402773, 0.01112815, 0.8644783 , 0.04748761,\n",
       "         0.04113412], dtype=float32),\n",
       "  array([0.06182813, 0.0226106 , 0.00930599, 0.0055522 , 0.00461174,\n",
       "         0.8960913 ], dtype=float32),\n",
       "  array([0.9322077 , 0.00570543, 0.01419336, 0.00480158, 0.00236841,\n",
       "         0.04072348], dtype=float32),\n",
       "  array([0.9325642 , 0.00727134, 0.02265231, 0.00855089, 0.00469313,\n",
       "         0.02426817], dtype=float32),\n",
       "  array([0.00877847, 0.0262162 , 0.02759111, 0.0690349 , 0.85098743,\n",
       "         0.01739179], dtype=float32),\n",
       "  array([0.02767549, 0.02959532, 0.0076455 , 0.00721541, 0.0049186 ,\n",
       "         0.9229496 ], dtype=float32),\n",
       "  array([0.04150826, 0.0261597 , 0.00916305, 0.00631841, 0.00367266,\n",
       "         0.91317797], dtype=float32),\n",
       "  array([0.15303312, 0.01366808, 0.0065403 , 0.00969834, 0.00492781,\n",
       "         0.81213236], dtype=float32),\n",
       "  array([0.00812338, 0.03460728, 0.03018641, 0.07166089, 0.8350203 ,\n",
       "         0.02040175], dtype=float32),\n",
       "  array([0.93542093, 0.00710583, 0.02292546, 0.00692787, 0.00378021,\n",
       "         0.0238397 ], dtype=float32),\n",
       "  array([0.9102353 , 0.00516335, 0.01367347, 0.00479097, 0.00259858,\n",
       "         0.0635383 ], dtype=float32),\n",
       "  array([0.9020384 , 0.00548654, 0.01274313, 0.0049101 , 0.00239675,\n",
       "         0.07242509], dtype=float32),\n",
       "  array([0.0803147 , 0.02588979, 0.01239897, 0.01298822, 0.00763502,\n",
       "         0.8607733 ], dtype=float32),\n",
       "  array([0.02341546, 0.05647639, 0.00885598, 0.00627045, 0.00520239,\n",
       "         0.89977926], dtype=float32),\n",
       "  array([0.00978575, 0.0228539 , 0.02400403, 0.06577152, 0.8545283 ,\n",
       "         0.02305645], dtype=float32),\n",
       "  array([0.01268409, 0.6381431 , 0.03244808, 0.00963648, 0.01056879,\n",
       "         0.29651937], dtype=float32),\n",
       "  array([0.842368  , 0.00816302, 0.02116355, 0.0164419 , 0.0056066 ,\n",
       "         0.10625699], dtype=float32),\n",
       "  array([0.02914188, 0.01946789, 0.01063512, 0.8535549 , 0.02579594,\n",
       "         0.06140414], dtype=float32),\n",
       "  array([0.04449504, 0.03736179, 0.01447302, 0.0076731 , 0.00423478,\n",
       "         0.89176226], dtype=float32),\n",
       "  array([0.05157508, 0.02751191, 0.01231555, 0.00779175, 0.00497803,\n",
       "         0.8958277 ], dtype=float32),\n",
       "  array([0.01375043, 0.632634  , 0.04757205, 0.01025559, 0.01317169,\n",
       "         0.2826163 ], dtype=float32),\n",
       "  array([0.8712113 , 0.01266421, 0.06312922, 0.00483858, 0.01124496,\n",
       "         0.03691164], dtype=float32),\n",
       "  array([0.03996683, 0.02272437, 0.0073361 , 0.0062213 , 0.00352147,\n",
       "         0.9202299 ], dtype=float32),\n",
       "  array([0.07204609, 0.0177479 , 0.00948667, 0.0121683 , 0.00669008,\n",
       "         0.881861  ], dtype=float32),\n",
       "  array([0.03814005, 0.04739011, 0.01095897, 0.02099726, 0.00788645,\n",
       "         0.8746272 ], dtype=float32),\n",
       "  array([0.01712852, 0.20084752, 0.01579044, 0.00869214, 0.00786603,\n",
       "         0.7496754 ], dtype=float32),\n",
       "  array([0.9261508 , 0.00516936, 0.01420178, 0.00519816, 0.00294772,\n",
       "         0.04633221], dtype=float32),\n",
       "  array([0.04574068, 0.02389683, 0.00855288, 0.01002602, 0.00470817,\n",
       "         0.9070754 ], dtype=float32),\n",
       "  array([0.86517245, 0.00985101, 0.07362176, 0.00901321, 0.01343595,\n",
       "         0.0289057 ], dtype=float32),\n",
       "  array([0.0344311 , 0.02779257, 0.00763393, 0.00637143, 0.0037214 ,\n",
       "         0.92004955], dtype=float32),\n",
       "  array([0.08982944, 0.04624128, 0.04050029, 0.00677485, 0.00860394,\n",
       "         0.80805016], dtype=float32),\n",
       "  array([0.9385504 , 0.00546358, 0.01490222, 0.00449317, 0.00256591,\n",
       "         0.03402459], dtype=float32),\n",
       "  array([0.9215031 , 0.00726435, 0.02908471, 0.0080177 , 0.00377103,\n",
       "         0.03035903], dtype=float32),\n",
       "  array([0.8316339 , 0.01013649, 0.10642937, 0.0068176 , 0.00723747,\n",
       "         0.03774516], dtype=float32),\n",
       "  array([0.91665053, 0.00561978, 0.01415774, 0.00693476, 0.00357264,\n",
       "         0.05306444], dtype=float32),\n",
       "  array([0.08860651, 0.08171351, 0.7307267 , 0.01758824, 0.04987867,\n",
       "         0.03148639], dtype=float32),\n",
       "  array([0.9404419 , 0.00606816, 0.0199206 , 0.00596321, 0.00310965,\n",
       "         0.02449644], dtype=float32),\n",
       "  array([0.2996291 , 0.05158788, 0.5221744 , 0.00957995, 0.0178316 ,\n",
       "         0.09919705], dtype=float32),\n",
       "  array([0.92463267, 0.00617883, 0.01991134, 0.00491707, 0.0028959 ,\n",
       "         0.04146409], dtype=float32),\n",
       "  array([0.17493662, 0.01263861, 0.00985334, 0.01730096, 0.00660232,\n",
       "         0.7786681 ], dtype=float32),\n",
       "  array([0.0305717 , 0.05166426, 0.01120929, 0.00690797, 0.00626785,\n",
       "         0.8933789 ], dtype=float32),\n",
       "  array([0.9318236 , 0.00469232, 0.01476352, 0.00561488, 0.00262292,\n",
       "         0.0404829 ], dtype=float32),\n",
       "  array([0.90249527, 0.00472823, 0.01253003, 0.00397322, 0.00241791,\n",
       "         0.07385541], dtype=float32),\n",
       "  array([0.07169566, 0.04399098, 0.01275796, 0.00563309, 0.0045603 ,\n",
       "         0.861362  ], dtype=float32),\n",
       "  array([0.06022821, 0.02119518, 0.01006856, 0.00696245, 0.00494303,\n",
       "         0.8966026 ], dtype=float32),\n",
       "  array([0.94267285, 0.00456937, 0.01436605, 0.00530162, 0.00306836,\n",
       "         0.0300217 ], dtype=float32),\n",
       "  array([0.9201337 , 0.00680277, 0.02062037, 0.00379612, 0.00261114,\n",
       "         0.0460359 ], dtype=float32),\n",
       "  array([0.04061468, 0.05138795, 0.0108978 , 0.00478343, 0.00585108,\n",
       "         0.886465  ], dtype=float32),\n",
       "  array([0.7567739 , 0.0208122 , 0.15704279, 0.00860512, 0.00760816,\n",
       "         0.04915783], dtype=float32),\n",
       "  array([0.02893182, 0.06924951, 0.01119681, 0.01992883, 0.00596194,\n",
       "         0.86473113], dtype=float32),\n",
       "  array([0.03276935, 0.0842467 , 0.01471724, 0.00611548, 0.00442609,\n",
       "         0.8577251 ], dtype=float32),\n",
       "  array([0.9314016 , 0.00716163, 0.0216328 , 0.00670679, 0.00351698,\n",
       "         0.02958035], dtype=float32),\n",
       "  array([0.02025815, 0.01161346, 0.01048856, 0.8962835 , 0.03621311,\n",
       "         0.02514316], dtype=float32),\n",
       "  array([0.9343098 , 0.00759461, 0.02672698, 0.00556233, 0.00391892,\n",
       "         0.02188735], dtype=float32),\n",
       "  array([0.02524537, 0.0160437 , 0.01108681, 0.86539227, 0.0274178 ,\n",
       "         0.05481407], dtype=float32),\n",
       "  array([0.11725505, 0.0164198 , 0.00904808, 0.00818858, 0.00394611,\n",
       "         0.8451424 ], dtype=float32),\n",
       "  array([0.09878507, 0.02261475, 0.00924313, 0.00574829, 0.00576983,\n",
       "         0.8578389 ], dtype=float32),\n",
       "  array([0.01948151, 0.01271204, 0.01091314, 0.9000688 , 0.02881886,\n",
       "         0.02800554], dtype=float32),\n",
       "  array([0.9181062 , 0.00766711, 0.03631892, 0.00623373, 0.00409566,\n",
       "         0.02757835], dtype=float32),\n",
       "  array([0.02418576, 0.01409711, 0.01287029, 0.80712503, 0.10006514,\n",
       "         0.04165654], dtype=float32),\n",
       "  array([0.01398494, 0.01742157, 0.01170278, 0.84503514, 0.08309611,\n",
       "         0.02875947], dtype=float32),\n",
       "  array([0.9306747 , 0.00665516, 0.0219941 , 0.00530545, 0.00272374,\n",
       "         0.0326469 ], dtype=float32),\n",
       "  array([0.01712852, 0.20084752, 0.01579044, 0.00869214, 0.00786603,\n",
       "         0.7496754 ], dtype=float32),\n",
       "  array([0.84387076, 0.01055282, 0.07004549, 0.00492665, 0.00473528,\n",
       "         0.06586899], dtype=float32),\n",
       "  array([0.12981255, 0.02133303, 0.01259892, 0.00648789, 0.00529764,\n",
       "         0.8244699 ], dtype=float32),\n",
       "  array([0.18716465, 0.0786794 , 0.6350728 , 0.01063497, 0.02099353,\n",
       "         0.06745463], dtype=float32),\n",
       "  array([0.35587114, 0.02291592, 0.0386271 , 0.0085139 , 0.00832926,\n",
       "         0.56574273], dtype=float32),\n",
       "  array([0.0408874 , 0.03658244, 0.00982636, 0.00560366, 0.00395373,\n",
       "         0.9031464 ], dtype=float32),\n",
       "  array([0.9134692 , 0.00595325, 0.01780502, 0.0051725 , 0.00272868,\n",
       "         0.05487142], dtype=float32),\n",
       "  array([0.01196175, 0.01852742, 0.02535766, 0.07379522, 0.8457603 ,\n",
       "         0.02459763], dtype=float32),\n",
       "  array([0.00909904, 0.02638487, 0.03181918, 0.06849948, 0.8413543 ,\n",
       "         0.02284313], dtype=float32),\n",
       "  array([0.01454814, 0.6968234 , 0.0782217 , 0.01827125, 0.02901177,\n",
       "         0.16312358], dtype=float32),\n",
       "  array([0.06578649, 0.0170574 , 0.0100005 , 0.01463934, 0.00608338,\n",
       "         0.8864329 ], dtype=float32),\n",
       "  array([0.92586935, 0.00657079, 0.02419989, 0.00665752, 0.00346039,\n",
       "         0.03324198], dtype=float32),\n",
       "  array([0.15980688, 0.0237338 , 0.0195795 , 0.0064587 , 0.00415803,\n",
       "         0.7862631 ], dtype=float32),\n",
       "  array([0.9158662 , 0.00640834, 0.02365401, 0.00391355, 0.00334235,\n",
       "         0.04681564], dtype=float32),\n",
       "  array([0.9391848 , 0.00469607, 0.01586786, 0.00508319, 0.00448472,\n",
       "         0.03068337], dtype=float32),\n",
       "  array([0.939786  , 0.00628804, 0.02109604, 0.00559047, 0.00300129,\n",
       "         0.02423807], dtype=float32),\n",
       "  array([0.05101297, 0.02090678, 0.00761051, 0.0083097 , 0.00491629,\n",
       "         0.9072437 ], dtype=float32),\n",
       "  array([0.92798454, 0.007096  , 0.02129207, 0.0105829 , 0.00461943,\n",
       "         0.02842507], dtype=float32),\n",
       "  array([0.01302081, 0.02156362, 0.03847835, 0.06430249, 0.8471464 ,\n",
       "         0.01548833], dtype=float32),\n",
       "  array([0.32678658, 0.01798065, 0.01044078, 0.03710775, 0.00694222,\n",
       "         0.60074204], dtype=float32),\n",
       "  array([0.02296987, 0.03335825, 0.0086965 , 0.00804567, 0.00653354,\n",
       "         0.9203961 ], dtype=float32),\n",
       "  array([0.04912657, 0.05459983, 0.01594763, 0.00897383, 0.00783585,\n",
       "         0.8635163 ], dtype=float32),\n",
       "  array([0.03837703, 0.02363197, 0.0079901 , 0.00716295, 0.003768  ,\n",
       "         0.91906995], dtype=float32),\n",
       "  array([0.0302044 , 0.02194579, 0.00756609, 0.00551342, 0.00348597,\n",
       "         0.93128437], dtype=float32),\n",
       "  array([0.03022657, 0.02923672, 0.06390624, 0.08983492, 0.7670655 ,\n",
       "         0.01973004], dtype=float32),\n",
       "  array([0.9349019 , 0.00534973, 0.01821306, 0.00661537, 0.00351715,\n",
       "         0.03140279], dtype=float32),\n",
       "  array([0.03667112, 0.03279879, 0.00824694, 0.00568031, 0.00399307,\n",
       "         0.9126098 ], dtype=float32),\n",
       "  array([0.01774847, 0.01549392, 0.01096209, 0.88630486, 0.02624549,\n",
       "         0.04324511], dtype=float32),\n",
       "  array([0.24091396, 0.01448254, 0.0123636 , 0.00735529, 0.00372273,\n",
       "         0.7211619 ], dtype=float32),\n",
       "  array([0.05738795, 0.03126602, 0.01007912, 0.0063847 , 0.00426945,\n",
       "         0.8906128 ], dtype=float32),\n",
       "  array([0.838145  , 0.01298596, 0.08150297, 0.01056584, 0.00764408,\n",
       "         0.04915611], dtype=float32),\n",
       "  array([0.5922211 , 0.01478783, 0.0360412 , 0.01038469, 0.0057655 ,\n",
       "         0.3407997 ], dtype=float32),\n",
       "  array([0.88785154, 0.00728533, 0.01733761, 0.00641412, 0.00482478,\n",
       "         0.07628661], dtype=float32),\n",
       "  array([0.02609575, 0.66702724, 0.05534229, 0.01050914, 0.02275482,\n",
       "         0.21827078], dtype=float32),\n",
       "  array([0.01196688, 0.7212328 , 0.05264381, 0.01108127, 0.01380235,\n",
       "         0.18927294], dtype=float32),\n",
       "  array([0.85360384, 0.00740034, 0.01771583, 0.0180508 , 0.0100668 ,\n",
       "         0.0931626 ], dtype=float32),\n",
       "  array([0.9404757 , 0.00525747, 0.01728404, 0.00643417, 0.00406241,\n",
       "         0.02648614], dtype=float32),\n",
       "  array([0.03161413, 0.02687354, 0.00786226, 0.0058048 , 0.00364109,\n",
       "         0.92420423], dtype=float32),\n",
       "  array([0.02222291, 0.01559507, 0.01400675, 0.82058287, 0.10571434,\n",
       "         0.02187801], dtype=float32),\n",
       "  array([0.0263632 , 0.01239046, 0.01010134, 0.87564546, 0.03200656,\n",
       "         0.04349302], dtype=float32),\n",
       "  array([0.00870378, 0.02930999, 0.02917288, 0.06454637, 0.8492925 ,\n",
       "         0.01897443], dtype=float32),\n",
       "  array([0.03035517, 0.02769583, 0.01182585, 0.00748215, 0.00588506,\n",
       "         0.9167559 ], dtype=float32),\n",
       "  array([0.8972906 , 0.005645  , 0.01393687, 0.00571535, 0.00241394,\n",
       "         0.07499821], dtype=float32),\n",
       "  array([0.00886746, 0.024576  , 0.02875908, 0.05701162, 0.864261  ,\n",
       "         0.01652484], dtype=float32),\n",
       "  array([0.06832054, 0.0152758 , 0.01008009, 0.00746272, 0.00496546,\n",
       "         0.89389545], dtype=float32),\n",
       "  array([0.9330451 , 0.00519159, 0.01873909, 0.00484654, 0.00308639,\n",
       "         0.0350914 ], dtype=float32),\n",
       "  array([0.06742819, 0.02091823, 0.01327118, 0.0631511 , 0.02187545,\n",
       "         0.8133559 ], dtype=float32),\n",
       "  array([0.03812217, 0.02825373, 0.01150286, 0.01175063, 0.00892718,\n",
       "         0.9014434 ], dtype=float32),\n",
       "  array([0.04271365, 0.02697664, 0.01095533, 0.00795058, 0.00535971,\n",
       "         0.90604407], dtype=float32),\n",
       "  array([0.9441249 , 0.00556159, 0.01759913, 0.00594768, 0.0031456 ,\n",
       "         0.02362117], dtype=float32),\n",
       "  array([0.9148256 , 0.00704084, 0.02012112, 0.00788773, 0.00381671,\n",
       "         0.04630788], dtype=float32),\n",
       "  array([0.0371898 , 0.01809665, 0.01674398, 0.8076408 , 0.07622036,\n",
       "         0.04410845], dtype=float32),\n",
       "  array([0.05983944, 0.02093418, 0.00789103, 0.00642952, 0.00412515,\n",
       "         0.9007806 ], dtype=float32),\n",
       "  array([0.01562554, 0.5994855 , 0.06115354, 0.02760994, 0.06631404,\n",
       "         0.22981152], dtype=float32),\n",
       "  array([0.04091853, 0.03383801, 0.0099293 , 0.00663531, 0.0045948 ,\n",
       "         0.904084  ], dtype=float32),\n",
       "  array([0.00758415, 0.8305029 , 0.04670067, 0.0096125 , 0.01669481,\n",
       "         0.08890495], dtype=float32),\n",
       "  array([0.04815859, 0.08194332, 0.14725713, 0.01350523, 0.032051  ,\n",
       "         0.67708474], dtype=float32),\n",
       "  array([0.9240572 , 0.00727848, 0.03298254, 0.0064642 , 0.00510962,\n",
       "         0.02410801], dtype=float32),\n",
       "  array([0.00961521, 0.79514027, 0.07707699, 0.01060408, 0.01662317,\n",
       "         0.09094033], dtype=float32),\n",
       "  array([0.02582313, 0.46075258, 0.06624054, 0.01675748, 0.02953105,\n",
       "         0.40089524], dtype=float32),\n",
       "  array([0.01114729, 0.7234973 , 0.03523788, 0.01493706, 0.01932784,\n",
       "         0.19585258], dtype=float32),\n",
       "  array([0.62095267, 0.01937799, 0.03862562, 0.01354246, 0.01494381,\n",
       "         0.29255742], dtype=float32),\n",
       "  array([0.64711696, 0.01670308, 0.04634112, 0.20080945, 0.02735846,\n",
       "         0.06167094], dtype=float32),\n",
       "  array([0.8855111 , 0.00762564, 0.03132247, 0.00765545, 0.00354651,\n",
       "         0.06433888], dtype=float32),\n",
       "  array([0.05067015, 0.02610551, 0.00874397, 0.00848873, 0.00444388,\n",
       "         0.90154773], dtype=float32),\n",
       "  array([0.05477187, 0.04118822, 0.01078035, 0.00596616, 0.00504038,\n",
       "         0.882253  ], dtype=float32),\n",
       "  array([0.04986301, 0.21904813, 0.18099748, 0.00767886, 0.01143024,\n",
       "         0.5309823 ], dtype=float32),\n",
       "  array([0.9346676 , 0.00498217, 0.01493792, 0.00417219, 0.00235891,\n",
       "         0.03888127], dtype=float32),\n",
       "  array([0.02566288, 0.11013021, 0.01721953, 0.01777466, 0.00943404,\n",
       "         0.8197786 ], dtype=float32),\n",
       "  array([0.930159  , 0.00489548, 0.01540295, 0.00501245, 0.00245824,\n",
       "         0.04207175], dtype=float32),\n",
       "  array([0.8798074 , 0.0091888 , 0.02589788, 0.01626633, 0.00505861,\n",
       "         0.06378102], dtype=float32),\n",
       "  array([0.9394103 , 0.00557626, 0.01822092, 0.00695165, 0.00394092,\n",
       "         0.02589988], dtype=float32),\n",
       "  array([0.01810705, 0.10819554, 0.0120474 , 0.00757833, 0.00686197,\n",
       "         0.8472097 ], dtype=float32),\n",
       "  array([0.21546164, 0.06131265, 0.04999729, 0.01065652, 0.0133094 ,\n",
       "         0.6492625 ], dtype=float32),\n",
       "  array([0.03483107, 0.02463901, 0.00992635, 0.06560726, 0.00818564,\n",
       "         0.8568106 ], dtype=float32),\n",
       "  array([0.02444228, 0.01537547, 0.01126995, 0.8917038 , 0.02860566,\n",
       "         0.02860282], dtype=float32),\n",
       "  array([0.11810714, 0.01644622, 0.00997246, 0.00575024, 0.00423205,\n",
       "         0.8454919 ], dtype=float32),\n",
       "  array([0.9298012 , 0.00776934, 0.02729428, 0.00829448, 0.00451337,\n",
       "         0.02232732], dtype=float32),\n",
       "  array([0.9355263 , 0.00745823, 0.02544783, 0.00672783, 0.00426762,\n",
       "         0.02057201], dtype=float32),\n",
       "  array([0.11642745, 0.10184695, 0.03197765, 0.0134439 , 0.01404741,\n",
       "         0.72225666], dtype=float32),\n",
       "  array([0.04758952, 0.03471038, 0.0122655 , 0.0073339 , 0.00510787,\n",
       "         0.8929928 ], dtype=float32),\n",
       "  array([0.92440975, 0.00693994, 0.02359286, 0.00454512, 0.00262438,\n",
       "         0.03788795], dtype=float32),\n",
       "  array([0.03746255, 0.14549083, 0.71243757, 0.01803541, 0.04085107,\n",
       "         0.04572252], dtype=float32),\n",
       "  array([0.93086004, 0.00769769, 0.02727783, 0.00478779, 0.00316147,\n",
       "         0.02621517], dtype=float32),\n",
       "  array([0.12742212, 0.01106148, 0.00830508, 0.01330132, 0.0040616 ,\n",
       "         0.8358484 ], dtype=float32),\n",
       "  array([0.02274078, 0.69204056, 0.0898836 , 0.01384254, 0.02095185,\n",
       "         0.16054063], dtype=float32),\n",
       "  array([0.01993637, 0.01572923, 0.01013916, 0.8554984 , 0.0393062 ,\n",
       "         0.05939063], dtype=float32),\n",
       "  array([0.02445389, 0.04066834, 0.00854519, 0.01119126, 0.00592954,\n",
       "         0.9092118 ], dtype=float32),\n",
       "  array([0.912438  , 0.00921749, 0.04075757, 0.00604066, 0.00409648,\n",
       "         0.02744973], dtype=float32),\n",
       "  array([0.04261282, 0.06862348, 0.7146255 , 0.0181078 , 0.05726984,\n",
       "         0.09876062], dtype=float32),\n",
       "  array([0.02865935, 0.03795769, 0.009201  , 0.0062093 , 0.00376957,\n",
       "         0.9142031 ], dtype=float32),\n",
       "  array([0.00786374, 0.7966872 , 0.08664761, 0.01135692, 0.02326751,\n",
       "         0.07417703], dtype=float32),\n",
       "  array([0.08986846, 0.06465907, 0.5082723 , 0.02634576, 0.18945806,\n",
       "         0.12139635], dtype=float32),\n",
       "  array([0.93881714, 0.00699107, 0.02102538, 0.00687189, 0.00401132,\n",
       "         0.02228329], dtype=float32),\n",
       "  array([0.0644237 , 0.05574977, 0.7744409 , 0.01208991, 0.0394995 ,\n",
       "         0.05379616], dtype=float32),\n",
       "  array([0.9211338 , 0.0082672 , 0.03081464, 0.0045516 , 0.00378363,\n",
       "         0.03144904], dtype=float32),\n",
       "  array([0.02504664, 0.43946162, 0.03204909, 0.01287542, 0.01506128,\n",
       "         0.47550595], dtype=float32),\n",
       "  array([0.05005319, 0.03278901, 0.01027608, 0.00727794, 0.00512341,\n",
       "         0.8944804 ], dtype=float32),\n",
       "  array([0.02278515, 0.5439674 , 0.14240089, 0.00855666, 0.01594233,\n",
       "         0.26634756], dtype=float32),\n",
       "  array([0.8953614 , 0.00659323, 0.01501202, 0.00618403, 0.00265035,\n",
       "         0.07419894], dtype=float32),\n",
       "  array([0.05417933, 0.01581321, 0.00694493, 0.02015891, 0.00560848,\n",
       "         0.8972952 ], dtype=float32),\n",
       "  array([0.04581148, 0.02715392, 0.01332746, 0.00982602, 0.00744339,\n",
       "         0.89643776], dtype=float32),\n",
       "  array([0.11950226, 0.02261369, 0.01552996, 0.00592677, 0.00346972,\n",
       "         0.83295757], dtype=float32),\n",
       "  array([0.00943215, 0.02445096, 0.03010724, 0.05949989, 0.8607693 ,\n",
       "         0.01574055], dtype=float32),\n",
       "  array([0.11872005, 0.09379886, 0.63287836, 0.0162609 , 0.06706844,\n",
       "         0.07127343], dtype=float32),\n",
       "  array([0.02333139, 0.03090419, 0.0088107 , 0.00753846, 0.00559447,\n",
       "         0.9238208 ], dtype=float32),\n",
       "  array([0.929713  , 0.00667631, 0.02063976, 0.00702386, 0.00311873,\n",
       "         0.03282826], dtype=float32),\n",
       "  array([0.04827611, 0.04725813, 0.01127197, 0.12052806, 0.01174088,\n",
       "         0.7609248 ], dtype=float32),\n",
       "  array([0.9385352 , 0.00430485, 0.01459227, 0.00539749, 0.00268489,\n",
       "         0.03448519], dtype=float32),\n",
       "  array([0.31391555, 0.0107251 , 0.01447375, 0.48931557, 0.03372573,\n",
       "         0.13784428], dtype=float32),\n",
       "  array([0.08447321, 0.03807245, 0.02059037, 0.00797454, 0.00540443,\n",
       "         0.84348494], dtype=float32),\n",
       "  array([0.02299131, 0.15948637, 0.01615967, 0.00730884, 0.00602165,\n",
       "         0.7880322 ], dtype=float32),\n",
       "  array([0.01199508, 0.02334318, 0.03588108, 0.05383395, 0.85876465,\n",
       "         0.01618209], dtype=float32),\n",
       "  array([0.00791092, 0.03114003, 0.03043611, 0.06023663, 0.84913725,\n",
       "         0.02113904], dtype=float32),\n",
       "  array([0.12046281, 0.03801148, 0.06567139, 0.02007492, 0.01294994,\n",
       "         0.7428295 ], dtype=float32),\n",
       "  array([0.9323416 , 0.0069999 , 0.02236819, 0.00515611, 0.00265003,\n",
       "         0.03048423], dtype=float32),\n",
       "  array([0.03063653, 0.11453119, 0.01771976, 0.03415927, 0.01120688,\n",
       "         0.7917464 ], dtype=float32),\n",
       "  array([0.02738469, 0.0116993 , 0.00958091, 0.85585594, 0.05222756,\n",
       "         0.04325165], dtype=float32),\n",
       "  array([0.00903189, 0.02548314, 0.03053544, 0.05482925, 0.86322135,\n",
       "         0.01689903], dtype=float32),\n",
       "  array([0.02051389, 0.01272697, 0.01114377, 0.9025982 , 0.0307466 ,\n",
       "         0.02227051], dtype=float32),\n",
       "  array([0.9270431 , 0.00778157, 0.02239826, 0.00614914, 0.00415999,\n",
       "         0.03246792], dtype=float32),\n",
       "  array([0.9256965 , 0.00934295, 0.03060402, 0.00690169, 0.00418617,\n",
       "         0.02326868], dtype=float32),\n",
       "  array([0.01150696, 0.02465787, 0.03169011, 0.06513012, 0.85177517,\n",
       "         0.01523976], dtype=float32),\n",
       "  array([0.04420755, 0.12749201, 0.02152355, 0.0073238 , 0.00845699,\n",
       "         0.79099613], dtype=float32),\n",
       "  array([0.91014874, 0.00631211, 0.01894106, 0.0092165 , 0.00371189,\n",
       "         0.05166965], dtype=float32),\n",
       "  array([0.01334348, 0.5620197 , 0.03248838, 0.00786808, 0.01200241,\n",
       "         0.37227798], dtype=float32),\n",
       "  array([0.00857616, 0.02749803, 0.0302568 , 0.06470758, 0.8393221 ,\n",
       "         0.02963934], dtype=float32),\n",
       "  array([0.03358649, 0.02686445, 0.00903429, 0.00597766, 0.0041225 ,\n",
       "         0.92041457], dtype=float32),\n",
       "  array([0.03649212, 0.15994361, 0.01855972, 0.0127017 , 0.00963738,\n",
       "         0.7626654 ], dtype=float32),\n",
       "  array([0.9172533 , 0.00990651, 0.02550324, 0.01710078, 0.00633506,\n",
       "         0.02390107], dtype=float32),\n",
       "  array([0.92680883, 0.00567523, 0.01973451, 0.00433275, 0.00257055,\n",
       "         0.04087813], dtype=float32),\n",
       "  array([0.85214037, 0.00908533, 0.02577077, 0.01024202, 0.00475782,\n",
       "         0.09800364], dtype=float32),\n",
       "  array([0.8753201 , 0.00551158, 0.0117079 , 0.0045009 , 0.00272126,\n",
       "         0.10023838], dtype=float32),\n",
       "  array([0.15487728, 0.03107516, 0.01394348, 0.48496056, 0.01968987,\n",
       "         0.29545367], dtype=float32),\n",
       "  array([0.01854092, 0.2590863 , 0.5898421 , 0.01973117, 0.05309246,\n",
       "         0.05970699], dtype=float32),\n",
       "  array([0.93485343, 0.00615732, 0.02342655, 0.00585468, 0.00326608,\n",
       "         0.02644192], dtype=float32),\n",
       "  array([0.01214436, 0.74399894, 0.03548114, 0.01365963, 0.02034026,\n",
       "         0.17437561], dtype=float32),\n",
       "  array([0.03330957, 0.48881158, 0.28281498, 0.00831501, 0.01568978,\n",
       "         0.1710591 ], dtype=float32),\n",
       "  array([0.02446744, 0.03953525, 0.00955741, 0.0114129 , 0.00578404,\n",
       "         0.9092429 ], dtype=float32),\n",
       "  array([0.04739239, 0.02417221, 0.01204168, 0.01355097, 0.00747236,\n",
       "         0.8953704 ], dtype=float32),\n",
       "  array([0.93782413, 0.00542325, 0.01619428, 0.00816057, 0.00375897,\n",
       "         0.02863877], dtype=float32),\n",
       "  array([0.07855191, 0.06941723, 0.1047889 , 0.01328725, 0.03333056,\n",
       "         0.70062417], dtype=float32),\n",
       "  array([0.11351016, 0.03890348, 0.01465541, 0.00561115, 0.00602883,\n",
       "         0.821291  ], dtype=float32),\n",
       "  array([0.84955716, 0.01101069, 0.03181896, 0.05005561, 0.01445347,\n",
       "         0.04310408], dtype=float32),\n",
       "  array([0.752496  , 0.0261444 , 0.04391877, 0.09725205, 0.01622316,\n",
       "         0.06396563], dtype=float32),\n",
       "  array([0.04692489, 0.19302787, 0.03728561, 0.00651041, 0.00830048,\n",
       "         0.7079508 ], dtype=float32),\n",
       "  array([0.9228428 , 0.00808541, 0.03214855, 0.00914732, 0.00675522,\n",
       "         0.02102062], dtype=float32),\n",
       "  array([0.04496797, 0.03819705, 0.01113175, 0.0447013 , 0.00811406,\n",
       "         0.8528879 ], dtype=float32),\n",
       "  array([0.91387296, 0.01017149, 0.03809484, 0.00696936, 0.00576272,\n",
       "         0.02512864], dtype=float32),\n",
       "  array([0.02270486, 0.09398736, 0.01508682, 0.00829978, 0.00806742,\n",
       "         0.8518538 ], dtype=float32),\n",
       "  array([0.9348757 , 0.00470138, 0.01576668, 0.00488001, 0.0025724 ,\n",
       "         0.03720392], dtype=float32),\n",
       "  array([0.04067416, 0.0839749 , 0.0280872 , 0.00396301, 0.00478512,\n",
       "         0.8385156 ], dtype=float32),\n",
       "  array([0.9328172 , 0.00703757, 0.02371592, 0.00649748, 0.00440609,\n",
       "         0.0255257 ], dtype=float32),\n",
       "  array([0.0140219 , 0.78856885, 0.06151223, 0.00991558, 0.01742268,\n",
       "         0.10855878], dtype=float32),\n",
       "  array([0.9159681 , 0.00575698, 0.02023041, 0.00416774, 0.00246453,\n",
       "         0.05141208], dtype=float32),\n",
       "  array([0.15359522, 0.0704672 , 0.66742903, 0.01159092, 0.02963967,\n",
       "         0.06727799], dtype=float32),\n",
       "  array([0.02543575, 0.07132262, 0.011853  , 0.01181953, 0.00589178,\n",
       "         0.87367725], dtype=float32),\n",
       "  array([0.04104009, 0.02754357, 0.00831613, 0.00838635, 0.00469697,\n",
       "         0.91001695], dtype=float32),\n",
       "  array([0.92410487, 0.00563902, 0.01814262, 0.00531246, 0.00252257,\n",
       "         0.04427831], dtype=float32),\n",
       "  array([0.0419393 , 0.03473432, 0.01369406, 0.16231133, 0.01215055,\n",
       "         0.7351704 ], dtype=float32),\n",
       "  array([0.0287248 , 0.26634002, 0.02213314, 0.00659666, 0.00774388,\n",
       "         0.6684615 ], dtype=float32),\n",
       "  array([0.0262449 , 0.03817787, 0.00981002, 0.00439572, 0.00360439,\n",
       "         0.9177671 ], dtype=float32),\n",
       "  array([0.04125519, 0.03013056, 0.01102665, 0.0109939 , 0.00676586,\n",
       "         0.89982784], dtype=float32),\n",
       "  array([0.09818093, 0.03897949, 0.01457629, 0.00696977, 0.00503796,\n",
       "         0.83625555], dtype=float32),\n",
       "  array([0.9356677 , 0.00638505, 0.02119043, 0.00828715, 0.00426778,\n",
       "         0.02420198], dtype=float32),\n",
       "  array([0.9211095 , 0.0070934 , 0.02367862, 0.00820469, 0.00366487,\n",
       "         0.03624889], dtype=float32),\n",
       "  array([0.12614134, 0.01991046, 0.01126156, 0.00863105, 0.00436637,\n",
       "         0.82968915], dtype=float32),\n",
       "  array([0.01913087, 0.01295084, 0.01057999, 0.8980086 , 0.03275281,\n",
       "         0.02657688], dtype=float32),\n",
       "  array([0.12972972, 0.02115477, 0.01595562, 0.00762529, 0.00652209,\n",
       "         0.8190125 ], dtype=float32),\n",
       "  array([0.0254775 , 0.01555595, 0.01114622, 0.8644058 , 0.0207641 ,\n",
       "         0.06265038], dtype=float32),\n",
       "  array([0.04028359, 0.02212328, 0.00842777, 0.00584199, 0.00354755,\n",
       "         0.9197759 ], dtype=float32),\n",
       "  array([0.03171026, 0.02125395, 0.01177949, 0.832031  , 0.04162627,\n",
       "         0.06159892], dtype=float32),\n",
       "  array([0.01072259, 0.02489875, 0.029143  , 0.05871886, 0.855792  ,\n",
       "         0.0207248 ], dtype=float32),\n",
       "  array([0.92078155, 0.00449091, 0.01209594, 0.00406622, 0.00268581,\n",
       "         0.0558794 ], dtype=float32),\n",
       "  array([0.9362766 , 0.00707249, 0.02549857, 0.00590776, 0.00338551,\n",
       "         0.02185903], dtype=float32),\n",
       "  array([0.03321031, 0.02977112, 0.01068635, 0.0975617 , 0.00941568,\n",
       "         0.81935483], dtype=float32),\n",
       "  array([0.05317694, 0.07803249, 0.76114184, 0.01495352, 0.03654315,\n",
       "         0.05615212], dtype=float32),\n",
       "  array([0.03860223, 0.03137793, 0.01003108, 0.03125561, 0.01059448,\n",
       "         0.8781387 ], dtype=float32),\n",
       "  array([0.03906167, 0.01896263, 0.0059921 , 0.01036552, 0.00447454,\n",
       "         0.92114353], dtype=float32),\n",
       "  array([0.01253662, 0.02518081, 0.03299706, 0.06214724, 0.8461111 ,\n",
       "         0.0210272 ], dtype=float32),\n",
       "  array([0.9175188 , 0.00816254, 0.03331789, 0.0078074 , 0.00378989,\n",
       "         0.02940346], dtype=float32),\n",
       "  array([0.88625467, 0.00789342, 0.02936933, 0.00549316, 0.00283455,\n",
       "         0.06815482], dtype=float32),\n",
       "  array([0.03311648, 0.06029268, 0.01143996, 0.00485236, 0.00460121,\n",
       "         0.88569725], dtype=float32),\n",
       "  array([0.08291553, 0.03401573, 0.01529458, 0.51153445, 0.02038621,\n",
       "         0.33585346], dtype=float32),\n",
       "  array([0.10189157, 0.0756109 , 0.5775175 , 0.01445978, 0.02880239,\n",
       "         0.20171793], dtype=float32),\n",
       "  array([0.8744101 , 0.01036108, 0.06590629, 0.00535628, 0.00481743,\n",
       "         0.03914869], dtype=float32),\n",
       "  array([0.04124018, 0.10704892, 0.76517093, 0.01581798, 0.03263548,\n",
       "         0.03808657], dtype=float32),\n",
       "  array([0.9303388 , 0.00915812, 0.02734264, 0.00640104, 0.00419402,\n",
       "         0.0225655 ], dtype=float32),\n",
       "  array([0.8986101 , 0.00667401, 0.02372732, 0.00641662, 0.00436638,\n",
       "         0.06020549], dtype=float32),\n",
       "  array([0.68400115, 0.00905365, 0.01475779, 0.01024169, 0.00505512,\n",
       "         0.27689067], dtype=float32),\n",
       "  array([0.00835959, 0.02936304, 0.03080766, 0.06084675, 0.85347444,\n",
       "         0.01714852], dtype=float32),\n",
       "  array([0.03032467, 0.02386116, 0.00895322, 0.03203569, 0.00621422,\n",
       "         0.89861107], dtype=float32),\n",
       "  array([0.11654006, 0.22459637, 0.0976057 , 0.00685251, 0.01181594,\n",
       "         0.5425895 ], dtype=float32),\n",
       "  array([0.8911226 , 0.00946663, 0.0484108 , 0.01329292, 0.00616242,\n",
       "         0.03154479], dtype=float32),\n",
       "  array([0.90671694, 0.00825872, 0.03301013, 0.00870619, 0.00399582,\n",
       "         0.03931224], dtype=float32),\n",
       "  array([0.12061855, 0.09355876, 0.31244108, 0.01211952, 0.02848462,\n",
       "         0.43277752], dtype=float32),\n",
       "  array([0.93267065, 0.0058604 , 0.01604388, 0.00436296, 0.00265923,\n",
       "         0.03840295], dtype=float32),\n",
       "  array([0.9382392 , 0.00563193, 0.02091036, 0.00613687, 0.0037157 ,\n",
       "         0.0253661 ], dtype=float32),\n",
       "  array([0.01013921, 0.02660288, 0.03720712, 0.05753462, 0.85136074,\n",
       "         0.01715543], dtype=float32),\n",
       "  array([0.18219806, 0.08045497, 0.64110494, 0.01463045, 0.02886202,\n",
       "         0.05274961], dtype=float32),\n",
       "  array([0.05647058, 0.03652157, 0.01361827, 0.01035015, 0.00754666,\n",
       "         0.8754928 ], dtype=float32),\n",
       "  array([0.00891558, 0.6716957 , 0.03470446, 0.01047676, 0.01533326,\n",
       "         0.2588742 ], dtype=float32),\n",
       "  array([0.0080453 , 0.78945017, 0.05657552, 0.00818941, 0.01377294,\n",
       "         0.1239667 ], dtype=float32),\n",
       "  array([0.9062675 , 0.00679115, 0.0404193 , 0.00454091, 0.00327621,\n",
       "         0.03870492], dtype=float32),\n",
       "  array([0.00789441, 0.03063365, 0.02909867, 0.06641883, 0.84543514,\n",
       "         0.02051922], dtype=float32),\n",
       "  array([0.17814851, 0.04367169, 0.02511878, 0.01283076, 0.00604204,\n",
       "         0.73418826], dtype=float32),\n",
       "  array([0.17583628, 0.02793536, 0.0443366 , 0.01823593, 0.03425043,\n",
       "         0.6994054 ], dtype=float32),\n",
       "  array([0.9387312 , 0.00512858, 0.01543833, 0.0043006 , 0.00236268,\n",
       "         0.03403857], dtype=float32),\n",
       "  array([0.01604487, 0.16521178, 0.01385209, 0.00837282, 0.00783534,\n",
       "         0.78868306], dtype=float32),\n",
       "  array([0.01750518, 0.32012984, 0.1241449 , 0.05854988, 0.30785167,\n",
       "         0.17181861], dtype=float32),\n",
       "  array([0.94143915, 0.00623444, 0.01961434, 0.00565488, 0.00307223,\n",
       "         0.02398499], dtype=float32),\n",
       "  array([0.0401895 , 0.0313908 , 0.00873535, 0.00739078, 0.00392276,\n",
       "         0.9083708 ], dtype=float32),\n",
       "  array([0.07210493, 0.04976951, 0.73954403, 0.01924143, 0.07353672,\n",
       "         0.04580343], dtype=float32),\n",
       "  array([0.03331959, 0.05733953, 0.01220687, 0.00603335, 0.00463994,\n",
       "         0.8864607 ], dtype=float32),\n",
       "  array([0.0594035 , 0.02529189, 0.01323222, 0.02652043, 0.0086631 ,\n",
       "         0.8668889 ], dtype=float32),\n",
       "  array([0.8384539 , 0.01009023, 0.02737783, 0.0034737 , 0.00251498,\n",
       "         0.11808936], dtype=float32),\n",
       "  array([0.38150257, 0.0217245 , 0.2603376 , 0.06064219, 0.24886413,\n",
       "         0.02692898], dtype=float32),\n",
       "  array([0.91284853, 0.00717268, 0.02841652, 0.00407646, 0.00301925,\n",
       "         0.04446655], dtype=float32),\n",
       "  array([0.03465365, 0.03297833, 0.00836374, 0.00530445, 0.00331985,\n",
       "         0.91538   ], dtype=float32),\n",
       "  array([0.37138125, 0.05472987, 0.04533204, 0.00499714, 0.0046951 ,\n",
       "         0.5188646 ], dtype=float32),\n",
       "  array([0.50814056, 0.08071515, 0.13193987, 0.00535804, 0.0071286 ,\n",
       "         0.26671782], dtype=float32),\n",
       "  array([0.9008558 , 0.01252778, 0.04396576, 0.00581593, 0.00510712,\n",
       "         0.0317276 ], dtype=float32),\n",
       "  array([0.08390874, 0.03223574, 0.01451574, 0.01896124, 0.00844858,\n",
       "         0.84193   ], dtype=float32),\n",
       "  array([0.10925242, 0.02759699, 0.01213494, 0.01292432, 0.00654822,\n",
       "         0.831543  ], dtype=float32),\n",
       "  array([0.9413374 , 0.00660582, 0.01903163, 0.00687168, 0.00348883,\n",
       "         0.02266465], dtype=float32),\n",
       "  array([0.04712445, 0.12446254, 0.66683567, 0.01097492, 0.02947195,\n",
       "         0.12113051], dtype=float32),\n",
       "  array([0.9283662 , 0.00720011, 0.0178243 , 0.0046724 , 0.002673  ,\n",
       "         0.03926409], dtype=float32),\n",
       "  array([0.6425257 , 0.02724682, 0.24602535, 0.00730345, 0.00855804,\n",
       "         0.0683407 ], dtype=float32),\n",
       "  array([0.93773824, 0.00562414, 0.01849491, 0.00727808, 0.00353755,\n",
       "         0.02732698], dtype=float32),\n",
       "  array([0.03615238, 0.02384687, 0.00784117, 0.00612836, 0.00326936,\n",
       "         0.9227618 ], dtype=float32),\n",
       "  array([0.8748713 , 0.01423928, 0.04928876, 0.01569143, 0.00661885,\n",
       "         0.03929033], dtype=float32),\n",
       "  array([0.8829386 , 0.01470868, 0.04174265, 0.02034922, 0.00740629,\n",
       "         0.0328544 ], dtype=float32),\n",
       "  array([0.02381918, 0.03936988, 0.00774034, 0.00784825, 0.00534976,\n",
       "         0.9158726 ], dtype=float32),\n",
       "  array([0.09865898, 0.02679114, 0.02676814, 0.00930766, 0.01506299,\n",
       "         0.8234111 ], dtype=float32),\n",
       "  array([0.14702135, 0.05870475, 0.07678374, 0.00479969, 0.00539516,\n",
       "         0.7072953 ], dtype=float32),\n",
       "  array([0.9401083 , 0.0055741 , 0.0161815 , 0.00495085, 0.0027258 ,\n",
       "         0.0304594 ], dtype=float32),\n",
       "  array([0.00843901, 0.8000387 , 0.05556783, 0.01530859, 0.02008612,\n",
       "         0.10055977], dtype=float32),\n",
       "  array([0.01205467, 0.7735849 , 0.06011039, 0.01041476, 0.01970358,\n",
       "         0.12413161], dtype=float32),\n",
       "  array([0.00841949, 0.7628347 , 0.04086759, 0.00795611, 0.01185819,\n",
       "         0.16806392], dtype=float32),\n",
       "  array([0.935675  , 0.00836548, 0.02309912, 0.0063199 , 0.00354228,\n",
       "         0.02299809], dtype=float32),\n",
       "  array([0.904837  , 0.00785934, 0.03193457, 0.00528576, 0.00351932,\n",
       "         0.04656399], dtype=float32),\n",
       "  array([0.08691327, 0.02803152, 0.01880609, 0.00501901, 0.00454413,\n",
       "         0.85668606], dtype=float32),\n",
       "  array([0.05750486, 0.07324328, 0.7499594 , 0.01343181, 0.03659438,\n",
       "         0.06926637], dtype=float32),\n",
       "  array([0.06643406, 0.02193843, 0.00917646, 0.00865434, 0.00530612,\n",
       "         0.88849056], dtype=float32),\n",
       "  array([0.02246022, 0.60375875, 0.19159952, 0.01224624, 0.02686059,\n",
       "         0.14307468], dtype=float32),\n",
       "  array([0.02228592, 0.13311449, 0.01999861, 0.00758049, 0.00661144,\n",
       "         0.81040907], dtype=float32),\n",
       "  array([0.87905085, 0.00489136, 0.01457639, 0.00517191, 0.00292417,\n",
       "         0.09338541], dtype=float32),\n",
       "  array([0.01935334, 0.01460833, 0.01107974, 0.8988799 , 0.03033464,\n",
       "         0.02574391], dtype=float32),\n",
       "  array([0.0335491 , 0.03263828, 0.01050686, 0.00890302, 0.00751768,\n",
       "         0.9068851 ], dtype=float32),\n",
       "  array([0.04942464, 0.09282546, 0.03518516, 0.0096328 , 0.0179276 ,\n",
       "         0.79500437], dtype=float32),\n",
       "  array([0.9432116 , 0.00508368, 0.0172965 , 0.00545297, 0.00284867,\n",
       "         0.0261066 ], dtype=float32),\n",
       "  array([0.13979879, 0.04897179, 0.17689633, 0.01502602, 0.03746415,\n",
       "         0.5818429 ], dtype=float32),\n",
       "  array([0.05789537, 0.02235802, 0.00845678, 0.00635683, 0.0035067 ,\n",
       "         0.90142626], dtype=float32),\n",
       "  array([0.0304734 , 0.02240854, 0.00849927, 0.02681293, 0.00573171,\n",
       "         0.9060741 ], dtype=float32),\n",
       "  array([0.02358847, 0.04675534, 0.0093588 , 0.0046602 , 0.00472609,\n",
       "         0.91091114], dtype=float32),\n",
       "  array([0.9306889 , 0.00601983, 0.01976821, 0.00792716, 0.00397626,\n",
       "         0.0316197 ], dtype=float32),\n",
       "  array([0.7859777 , 0.01416203, 0.07048415, 0.00506003, 0.00402543,\n",
       "         0.12029061], dtype=float32),\n",
       "  array([0.04699335, 0.02070104, 0.00953642, 0.01922653, 0.00791231,\n",
       "         0.8956303 ], dtype=float32),\n",
       "  array([0.8565901 , 0.01241802, 0.0386054 , 0.03505321, 0.01363455,\n",
       "         0.04369866], dtype=float32),\n",
       "  array([0.01407029, 0.6038554 , 0.03797463, 0.00883709, 0.01567229,\n",
       "         0.3195903 ], dtype=float32),\n",
       "  array([0.90140736, 0.00754765, 0.03395886, 0.00459897, 0.00305396,\n",
       "         0.04943313], dtype=float32),\n",
       "  array([0.9243106 , 0.00699225, 0.02063091, 0.00725572, 0.00325065,\n",
       "         0.0375599 ], dtype=float32),\n",
       "  array([0.8500816 , 0.0134771 , 0.08765013, 0.00589215, 0.004775  ,\n",
       "         0.03812397], dtype=float32),\n",
       "  array([0.15594521, 0.02343971, 0.01604137, 0.01020098, 0.00474798,\n",
       "         0.78962475], dtype=float32),\n",
       "  array([0.01578964, 0.639216  , 0.10384509, 0.00706688, 0.01502636,\n",
       "         0.21905595], dtype=float32),\n",
       "  array([0.09794386, 0.03835968, 0.03649106, 0.00668313, 0.00707479,\n",
       "         0.8134475 ], dtype=float32),\n",
       "  array([0.03363292, 0.02627444, 0.00841172, 0.01252572, 0.00699641,\n",
       "         0.9121588 ], dtype=float32),\n",
       "  array([0.02803926, 0.15259975, 0.71249527, 0.01639718, 0.03957075,\n",
       "         0.05089777], dtype=float32),\n",
       "  array([0.932405  , 0.00643391, 0.02014275, 0.00658307, 0.00290434,\n",
       "         0.031531  ], dtype=float32),\n",
       "  array([0.01314155, 0.79389477, 0.07217556, 0.00883345, 0.01654909,\n",
       "         0.09540554], dtype=float32),\n",
       "  array([0.00921485, 0.78311354, 0.06037481, 0.01002716, 0.01767865,\n",
       "         0.11959104], dtype=float32),\n",
       "  array([0.06095996, 0.03335636, 0.01010532, 0.00508605, 0.00429563,\n",
       "         0.8861966 ], dtype=float32),\n",
       "  array([0.00947657, 0.0295254 , 0.0297226 , 0.05782373, 0.8538423 ,\n",
       "         0.01960933], dtype=float32),\n",
       "  array([0.8676106 , 0.01267657, 0.07768026, 0.00641984, 0.00649323,\n",
       "         0.02911948], dtype=float32),\n",
       "  array([0.94091743, 0.00551563, 0.01706368, 0.00637587, 0.00330545,\n",
       "         0.02682192], dtype=float32),\n",
       "  array([0.01707206, 0.2604158 , 0.02005165, 0.00746201, 0.00770506,\n",
       "         0.6872934 ], dtype=float32),\n",
       "  array([0.92125255, 0.00889309, 0.03104305, 0.00998023, 0.00483989,\n",
       "         0.02399122], dtype=float32),\n",
       "  array([0.02588562, 0.6961008 , 0.10009956, 0.01388807, 0.03291844,\n",
       "         0.13110754], dtype=float32),\n",
       "  array([0.92899966, 0.00861137, 0.02965679, 0.00631285, 0.00361964,\n",
       "         0.02279973], dtype=float32),\n",
       "  array([0.02967348, 0.04286322, 0.00752854, 0.00661675, 0.00393526,\n",
       "         0.9093828 ], dtype=float32),\n",
       "  array([0.08146389, 0.03659573, 0.03404819, 0.00940105, 0.0095435 ,\n",
       "         0.8289476 ], dtype=float32),\n",
       "  array([0.81522894, 0.01626226, 0.12173365, 0.01241384, 0.01222719,\n",
       "         0.02213412], dtype=float32),\n",
       "  array([0.7597015 , 0.01909186, 0.16705923, 0.01051307, 0.01528675,\n",
       "         0.0283476 ], dtype=float32),\n",
       "  array([0.8935262 , 0.00689006, 0.02314289, 0.0036498 , 0.00231636,\n",
       "         0.0704748 ], dtype=float32),\n",
       "  array([0.0095875 , 0.02951838, 0.0298734 , 0.05891083, 0.85226524,\n",
       "         0.01984457], dtype=float32),\n",
       "  array([0.03043003, 0.0267934 , 0.00760609, 0.01317288, 0.00399317,\n",
       "         0.91800445], dtype=float32),\n",
       "  array([0.89342743, 0.00990485, 0.0531918 , 0.00649885, 0.00402147,\n",
       "         0.03295562], dtype=float32),\n",
       "  array([0.938883  , 0.00692318, 0.01967022, 0.00744887, 0.00361632,\n",
       "         0.02345839], dtype=float32),\n",
       "  array([0.01199633, 0.74242127, 0.05477075, 0.0149897 , 0.0187853 ,\n",
       "         0.15703674], dtype=float32),\n",
       "  array([0.04269137, 0.03085848, 0.00849378, 0.01493455, 0.00560277,\n",
       "         0.897419  ], dtype=float32),\n",
       "  array([0.9259957 , 0.00840554, 0.02792421, 0.01074717, 0.00582257,\n",
       "         0.0211047 ], dtype=float32),\n",
       "  array([0.02440585, 0.01546306, 0.01381185, 0.7431055 , 0.14264043,\n",
       "         0.06057333], dtype=float32),\n",
       "  array([0.02046587, 0.01137023, 0.00997639, 0.88807243, 0.04634256,\n",
       "         0.02377255], dtype=float32),\n",
       "  array([0.78655905, 0.01713925, 0.14286882, 0.00698218, 0.00812367,\n",
       "         0.038327  ], dtype=float32),\n",
       "  array([0.02644195, 0.04839246, 0.02735631, 0.00901361, 0.01453731,\n",
       "         0.8742584 ], dtype=float32),\n",
       "  array([0.05173404, 0.02448568, 0.01168569, 0.10109934, 0.00908438,\n",
       "         0.8019108 ], dtype=float32),\n",
       "  array([0.08796912, 0.01650659, 0.01195446, 0.01523159, 0.00665954,\n",
       "         0.86167866], dtype=float32),\n",
       "  array([0.92117244, 0.00465108, 0.01437895, 0.00418053, 0.00256275,\n",
       "         0.05305415], dtype=float32),\n",
       "  array([0.9201146 , 0.00461037, 0.01302729, 0.00370207, 0.00219878,\n",
       "         0.05634697], dtype=float32),\n",
       "  array([0.9353557 , 0.00657873, 0.02209695, 0.00678511, 0.0034659 ,\n",
       "         0.02571778], dtype=float32),\n",
       "  array([0.04657033, 0.0354333 , 0.01861081, 0.01082917, 0.01115285,\n",
       "         0.87740356], dtype=float32),\n",
       "  array([0.04276008, 0.03990418, 0.01083796, 0.00378244, 0.00362651,\n",
       "         0.8990888 ], dtype=float32),\n",
       "  array([0.01741379, 0.02122772, 0.010652  , 0.8738525 , 0.03531798,\n",
       "         0.04153606], dtype=float32),\n",
       "  array([0.9000148 , 0.01065779, 0.05127528, 0.0058671 , 0.00459927,\n",
       "         0.02758577], dtype=float32),\n",
       "  array([0.09166282, 0.01900672, 0.0108357 , 0.00847682, 0.0063807 ,\n",
       "         0.86363727], dtype=float32),\n",
       "  array([0.07160079, 0.12478389, 0.19012763, 0.01873096, 0.06752006,\n",
       "         0.5272367 ], dtype=float32),\n",
       "  array([0.9124511 , 0.00847248, 0.04327782, 0.00658203, 0.00475604,\n",
       "         0.02446042], dtype=float32),\n",
       "  array([0.01119566, 0.7607579 , 0.07762854, 0.00975519, 0.01138909,\n",
       "         0.12927362], dtype=float32),\n",
       "  array([0.7331374 , 0.01910584, 0.18453936, 0.01032843, 0.00855463,\n",
       "         0.04433427], dtype=float32),\n",
       "  array([0.02207761, 0.01405469, 0.01515499, 0.8467756 , 0.06211109,\n",
       "         0.03982608], dtype=float32),\n",
       "  array([0.07124528, 0.01964719, 0.00784663, 0.00624778, 0.0049758 ,\n",
       "         0.8900373 ], dtype=float32),\n",
       "  array([0.00632711, 0.8186081 , 0.06363761, 0.01064103, 0.01913043,\n",
       "         0.08165585], dtype=float32),\n",
       "  array([0.03310171, 0.05749138, 0.7834361 , 0.01382635, 0.05651749,\n",
       "         0.05562703], dtype=float32),\n",
       "  array([0.04138424, 0.36312443, 0.10576333, 0.00619664, 0.00903388,\n",
       "         0.47449756], dtype=float32),\n",
       "  array([0.0139936 , 0.0204061 , 0.03431654, 0.05963528, 0.8455683 ,\n",
       "         0.02608022], dtype=float32),\n",
       "  array([0.87112534, 0.01354169, 0.03570682, 0.02018561, 0.0060687 ,\n",
       "         0.0533719 ], dtype=float32),\n",
       "  array([0.74810725, 0.01456194, 0.03279215, 0.00493606, 0.00407713,\n",
       "         0.19552541], dtype=float32),\n",
       "  array([0.90355283, 0.00717184, 0.03847821, 0.0041147 , 0.00382941,\n",
       "         0.04285298], dtype=float32),\n",
       "  array([0.03516535, 0.04626985, 0.00976474, 0.0072392 , 0.00440427,\n",
       "         0.8971566 ], dtype=float32),\n",
       "  array([0.02354855, 0.5033042 , 0.29649812, 0.00799552, 0.01455144,\n",
       "         0.15410224], dtype=float32),\n",
       "  array([0.01962722, 0.0141544 , 0.01191236, 0.8976106 , 0.0307368 ,\n",
       "         0.02595869], dtype=float32),\n",
       "  array([0.06033675, 0.05112494, 0.01538021, 0.00578756, 0.00569944,\n",
       "         0.86167115], dtype=float32),\n",
       "  array([0.03985694, 0.12416542, 0.6933288 , 0.01606525, 0.03296315,\n",
       "         0.09362048], dtype=float32),\n",
       "  array([0.65837526, 0.0107435 , 0.04312988, 0.02240962, 0.01235942,\n",
       "         0.2529824 ], dtype=float32),\n",
       "  array([0.08735503, 0.02000644, 0.01508844, 0.7853903 , 0.03482861,\n",
       "         0.05733108], dtype=float32),\n",
       "  array([0.01326768, 0.01970144, 0.01049939, 0.88206846, 0.03018   ,\n",
       "         0.04428313], dtype=float32),\n",
       "  array([0.00708758, 0.04841155, 0.04044427, 0.061368  , 0.7995096 ,\n",
       "         0.04317909], dtype=float32),\n",
       "  array([0.00677346, 0.8048429 , 0.0980024 , 0.01420148, 0.02761745,\n",
       "         0.04856241], dtype=float32),\n",
       "  array([0.01975482, 0.01295422, 0.01206581, 0.86667097, 0.07044928,\n",
       "         0.01810489], dtype=float32),\n",
       "  array([0.04346241, 0.03054732, 0.01967793, 0.02753799, 0.03233529,\n",
       "         0.84643906], dtype=float32),\n",
       "  array([0.02444487, 0.05353167, 0.0091201 , 0.00502879, 0.00372041,\n",
       "         0.9041542 ], dtype=float32),\n",
       "  array([0.01470205, 0.43888918, 0.04135861, 0.00774043, 0.01105363,\n",
       "         0.4862562 ], dtype=float32),\n",
       "  array([0.04821273, 0.04619069, 0.01510348, 0.11352605, 0.01402394,\n",
       "         0.7629431 ], dtype=float32),\n",
       "  array([0.9201102 , 0.00635461, 0.01385153, 0.00467916, 0.00247501,\n",
       "         0.05252932], dtype=float32),\n",
       "  array([0.01248943, 0.71169007, 0.14013587, 0.00878108, 0.01462193,\n",
       "         0.11228167], dtype=float32),\n",
       "  array([0.00906516, 0.7879112 , 0.06339262, 0.01745773, 0.02579662,\n",
       "         0.09637674], dtype=float32),\n",
       "  array([0.02494265, 0.34220245, 0.05188092, 0.00770692, 0.00820189,\n",
       "         0.56506515], dtype=float32),\n",
       "  array([0.00788255, 0.75848955, 0.07582491, 0.01307418, 0.03395715,\n",
       "         0.11077172], dtype=float32),\n",
       "  array([0.04987447, 0.02777493, 0.00994642, 0.07231615, 0.00958618,\n",
       "         0.83050185], dtype=float32),\n",
       "  array([0.03664634, 0.02208568, 0.00844479, 0.02525672, 0.00646097,\n",
       "         0.90110546], dtype=float32),\n",
       "  array([0.02605368, 0.0436734 , 0.00853122, 0.0082405 , 0.00450079,\n",
       "         0.90900034], dtype=float32),\n",
       "  array([0.86327106, 0.01390833, 0.0590819 , 0.00699442, 0.00489794,\n",
       "         0.0518463 ], dtype=float32),\n",
       "  array([0.8546469 , 0.01765276, 0.04631127, 0.03324104, 0.00969781,\n",
       "         0.03845025], dtype=float32),\n",
       "  array([0.00858964, 0.03054916, 0.02949377, 0.0614137 , 0.8470903 ,\n",
       "         0.02286341], dtype=float32),\n",
       "  array([0.0436104 , 0.02251804, 0.00821899, 0.01062441, 0.00549022,\n",
       "         0.9095379 ], dtype=float32),\n",
       "  array([0.05682532, 0.11226184, 0.72922516, 0.01707633, 0.04447641,\n",
       "         0.04013499], dtype=float32),\n",
       "  array([0.9368268 , 0.00523562, 0.0167108 , 0.00538633, 0.00318047,\n",
       "         0.03265993], dtype=float32),\n",
       "  array([0.04371943, 0.01804262, 0.00707469, 0.00709619, 0.0036136 ,\n",
       "         0.9204535 ], dtype=float32),\n",
       "  array([0.03662824, 0.04116444, 0.00934316, 0.00550671, 0.00411192,\n",
       "         0.9032455 ], dtype=float32),\n",
       "  array([0.0293962 , 0.02327994, 0.01312816, 0.7957493 , 0.02966315,\n",
       "         0.10878323], dtype=float32),\n",
       "  array([0.00910733, 0.7635519 , 0.04585335, 0.01306679, 0.01819814,\n",
       "         0.15022247], dtype=float32),\n",
       "  array([0.01073935, 0.7526718 , 0.04084576, 0.01117647, 0.016011  ,\n",
       "         0.16855577], dtype=float32),\n",
       "  array([0.04011137, 0.0417249 , 0.01589652, 0.00410767, 0.00554826,\n",
       "         0.89261127], dtype=float32),\n",
       "  array([0.18928042, 0.02674701, 0.0211801 , 0.00530888, 0.00447873,\n",
       "         0.75300485], dtype=float32),\n",
       "  array([0.02590821, 0.03757873, 0.00825642, 0.01555527, 0.00638714,\n",
       "         0.90631425], dtype=float32),\n",
       "  array([0.0419153 , 0.03961036, 0.01183639, 0.00889105, 0.00425424,\n",
       "         0.8934927 ], dtype=float32),\n",
       "  array([0.92768866, 0.00438783, 0.01295292, 0.00506977, 0.00265809,\n",
       "         0.04724265], dtype=float32),\n",
       "  array([0.06077015, 0.03012421, 0.0292883 , 0.00663416, 0.0062906 ,\n",
       "         0.8668926 ], dtype=float32),\n",
       "  array([0.06119213, 0.02352081, 0.01046787, 0.00889305, 0.00520837,\n",
       "         0.89071774], dtype=float32),\n",
       "  array([0.02630141, 0.02490464, 0.00718108, 0.00691067, 0.00433158,\n",
       "         0.9303707 ], dtype=float32),\n",
       "  array([0.02174407, 0.01402773, 0.01112815, 0.8644783 , 0.04748761,\n",
       "         0.04113412], dtype=float32),\n",
       "  array([0.0633702 , 0.01622623, 0.00844911, 0.00696863, 0.00477015,\n",
       "         0.90021574], dtype=float32),\n",
       "  array([0.93367296, 0.00474181, 0.01451676, 0.00630385, 0.00309424,\n",
       "         0.03767039], dtype=float32),\n",
       "  array([0.00781739, 0.77959085, 0.05821915, 0.01482802, 0.02156415,\n",
       "         0.11798054], dtype=float32),\n",
       "  array([0.02589248, 0.03822652, 0.00999239, 0.00814805, 0.00609694,\n",
       "         0.9116436 ], dtype=float32),\n",
       "  array([0.00692558, 0.7978235 , 0.03703752, 0.01635326, 0.02768378,\n",
       "         0.1141765 ], dtype=float32),\n",
       "  array([0.00825704, 0.79068226, 0.04940144, 0.01090813, 0.02062909,\n",
       "         0.12012198], dtype=float32),\n",
       "  array([0.9206155 , 0.00736785, 0.03783827, 0.00559415, 0.00410135,\n",
       "         0.02448275], dtype=float32),\n",
       "  array([0.63874865, 0.02958315, 0.26629055, 0.014622  , 0.02224315,\n",
       "         0.02851251], dtype=float32),\n",
       "  array([0.02127622, 0.01663095, 0.01049208, 0.8679783 , 0.03936082,\n",
       "         0.04426175], dtype=float32),\n",
       "  array([0.00829202, 0.7326531 , 0.05346545, 0.0095141 , 0.01306838,\n",
       "         0.18300696], dtype=float32),\n",
       "  array([0.91959316, 0.00516599, 0.0147914 , 0.00802842, 0.0039685 ,\n",
       "         0.0484525 ], dtype=float32),\n",
       "  array([0.17720811, 0.01809025, 0.01207231, 0.46860537, 0.02529084,\n",
       "         0.2987331 ], dtype=float32),\n",
       "  array([0.07523368, 0.14581855, 0.47839725, 0.01648528, 0.07080352,\n",
       "         0.21326177], dtype=float32),\n",
       "  array([0.09191146, 0.05474917, 0.71053356, 0.01274751, 0.04320502,\n",
       "         0.08685326], dtype=float32),\n",
       "  array([0.07346446, 0.06503707, 0.01881544, 0.02832549, 0.00985694,\n",
       "         0.8045006 ], dtype=float32),\n",
       "  array([0.9436152 , 0.00524393, 0.0164293 , 0.00641496, 0.00376259,\n",
       "         0.02453397], dtype=float32),\n",
       "  array([0.06304638, 0.01870536, 0.01022529, 0.01015115, 0.00625614,\n",
       "         0.89161575], dtype=float32),\n",
       "  array([0.11517761, 0.01839051, 0.01088592, 0.0637653 , 0.01440066,\n",
       "         0.77738   ], dtype=float32),\n",
       "  array([0.910214  , 0.00948935, 0.03334286, 0.0121618 , 0.00918789,\n",
       "         0.02560404], dtype=float32),\n",
       "  array([0.03668372, 0.0366371 , 0.01083291, 0.06023623, 0.00765874,\n",
       "         0.84795123], dtype=float32),\n",
       "  array([0.06031982, 0.03232924, 0.01070342, 0.00598607, 0.0044308 ,\n",
       "         0.88623065], dtype=float32),\n",
       "  array([0.03823853, 0.02556653, 0.00958889, 0.00984404, 0.00523231,\n",
       "         0.91152966], dtype=float32),\n",
       "  array([0.03012222, 0.10591029, 0.01789513, 0.00709205, 0.00641919,\n",
       "         0.83256114], dtype=float32),\n",
       "  array([0.05597389, 0.02453853, 0.0090078 , 0.00522318, 0.00581415,\n",
       "         0.8994425 ], dtype=float32),\n",
       "  array([0.02831515, 0.0343659 , 0.01324106, 0.05088875, 0.02102824,\n",
       "         0.85216093], dtype=float32),\n",
       "  array([0.06689539, 0.02063724, 0.01366294, 0.00979578, 0.00578257,\n",
       "         0.88322616], dtype=float32),\n",
       "  array([0.06852602, 0.0135184 , 0.01220769, 0.79867494, 0.0275039 ,\n",
       "         0.07956905], dtype=float32),\n",
       "  array([0.06577397, 0.04465535, 0.01685133, 0.4320521 , 0.02151076,\n",
       "         0.41915652], dtype=float32),\n",
       "  array([0.8482642 , 0.01105754, 0.08438639, 0.00538913, 0.00494434,\n",
       "         0.04595838], dtype=float32),\n",
       "  array([0.04501561, 0.0281916 , 0.00864008, 0.01043733, 0.00758866,\n",
       "         0.90012676], dtype=float32),\n",
       "  array([0.12342405, 0.01545141, 0.01158242, 0.00664736, 0.00550597,\n",
       "         0.8373888 ], dtype=float32),\n",
       "  array([0.0165612 , 0.5710959 , 0.03494106, 0.01116848, 0.01524841,\n",
       "         0.3509849 ], dtype=float32),\n",
       "  array([0.8715233 , 0.01291057, 0.03660497, 0.02572402, 0.00719891,\n",
       "         0.04603831], dtype=float32),\n",
       "  array([0.18194191, 0.02163833, 0.0186391 , 0.00601879, 0.00611229,\n",
       "         0.7656496 ], dtype=float32),\n",
       "  array([0.7739018 , 0.01091665, 0.0254339 , 0.00512924, 0.00332272,\n",
       "         0.1812956 ], dtype=float32),\n",
       "  array([0.05528016, 0.27523744, 0.45758137, 0.0271878 , 0.04896548,\n",
       "         0.13574779], dtype=float32),\n",
       "  array([0.03839478, 0.01964542, 0.01631251, 0.80813247, 0.04862128,\n",
       "         0.06889353], dtype=float32),\n",
       "  array([0.17330657, 0.02361682, 0.01809615, 0.00704824, 0.00615574,\n",
       "         0.77177644], dtype=float32),\n",
       "  array([0.09923042, 0.01301732, 0.01444879, 0.79553914, 0.03337907,\n",
       "         0.0443853 ], dtype=float32),\n",
       "  array([0.05663728, 0.02363552, 0.00810739, 0.00644815, 0.00468941,\n",
       "         0.90048224], dtype=float32),\n",
       "  array([0.9345567 , 0.00712625, 0.02125832, 0.00545776, 0.00292847,\n",
       "         0.0286726 ], dtype=float32),\n",
       "  array([0.17777054, 0.07683694, 0.02110914, 0.00626008, 0.00770696,\n",
       "         0.7103163 ], dtype=float32),\n",
       "  array([0.7477073 , 0.00931652, 0.02474617, 0.00666695, 0.00327059,\n",
       "         0.20829248], dtype=float32),\n",
       "  array([0.9347505 , 0.0073184 , 0.02650583, 0.00579577, 0.00366883,\n",
       "         0.02196057], dtype=float32),\n",
       "  array([0.01062758, 0.7826648 , 0.07075603, 0.01594654, 0.02619828,\n",
       "         0.09380675], dtype=float32),\n",
       "  array([0.03440583, 0.05104897, 0.00904955, 0.00737264, 0.00458804,\n",
       "         0.89353496], dtype=float32),\n",
       "  array([0.88161033, 0.00712262, 0.03600181, 0.00458381, 0.00328502,\n",
       "         0.06739652], dtype=float32),\n",
       "  array([0.9348455 , 0.00703245, 0.01999357, 0.00464637, 0.00319052,\n",
       "         0.03029167], dtype=float32),\n",
       "  array([0.9279962 , 0.0058788 , 0.01668776, 0.00560116, 0.00299599,\n",
       "         0.04084007], dtype=float32),\n",
       "  array([0.9353205 , 0.00526997, 0.0165576 , 0.00403065, 0.0024143 ,\n",
       "         0.03640696], dtype=float32),\n",
       "  array([0.0895509 , 0.02139863, 0.0085851 , 0.00892064, 0.00454318,\n",
       "         0.8670016 ], dtype=float32),\n",
       "  array([0.9142584 , 0.00462325, 0.01836376, 0.00444068, 0.0027911 ,\n",
       "         0.05552278], dtype=float32),\n",
       "  array([0.02796816, 0.16278103, 0.01899549, 0.01224328, 0.01029253,\n",
       "         0.76771945], dtype=float32),\n",
       "  array([0.8414934 , 0.00825315, 0.01738018, 0.00565955, 0.00238835,\n",
       "         0.12482546], dtype=float32),\n",
       "  array([0.93733466, 0.00572895, 0.01679525, 0.00679912, 0.0032698 ,\n",
       "         0.03007224], dtype=float32),\n",
       "  array([0.19964184, 0.02012518, 0.01342496, 0.0080071 , 0.00677992,\n",
       "         0.752021  ], dtype=float32),\n",
       "  array([0.01068416, 0.75373507, 0.04623789, 0.00883898, 0.01452684,\n",
       "         0.1659771 ], dtype=float32),\n",
       "  array([0.07101896, 0.04539352, 0.01173303, 0.00676565, 0.00413149,\n",
       "         0.8609574 ], dtype=float32),\n",
       "  array([0.02475695, 0.01900322, 0.01029033, 0.8074326 , 0.0352506 ,\n",
       "         0.10326629], dtype=float32),\n",
       "  array([0.92431134, 0.00569255, 0.02267891, 0.00620214, 0.00338889,\n",
       "         0.03772605], dtype=float32),\n",
       "  array([0.70727485, 0.03715493, 0.08635378, 0.01071926, 0.01103868,\n",
       "         0.14745846], dtype=float32),\n",
       "  array([0.92428446, 0.00664379, 0.02981459, 0.00538727, 0.00336292,\n",
       "         0.03050691], dtype=float32),\n",
       "  array([0.93391806, 0.00749154, 0.02364833, 0.00769815, 0.00380776,\n",
       "         0.02343626], dtype=float32),\n",
       "  array([0.03842147, 0.13030256, 0.6534066 , 0.0142277 , 0.1077757 ,\n",
       "         0.055866  ], dtype=float32),\n",
       "  array([0.07370886, 0.06108307, 0.11061209, 0.01353682, 0.02970517,\n",
       "         0.711354  ], dtype=float32),\n",
       "  array([0.03580332, 0.14639732, 0.6265123 , 0.01042423, 0.02712529,\n",
       "         0.1537375 ], dtype=float32),\n",
       "  array([0.9188433 , 0.00572209, 0.01545993, 0.00367106, 0.00226504,\n",
       "         0.05403853], dtype=float32),\n",
       "  array([0.9400925 , 0.00595804, 0.01738215, 0.00474121, 0.00304371,\n",
       "         0.0287822 ], dtype=float32),\n",
       "  array([0.02035379, 0.5093631 , 0.28895316, 0.01053084, 0.02298335,\n",
       "         0.14781575], dtype=float32),\n",
       "  array([0.93474495, 0.00596482, 0.01707627, 0.00430919, 0.0027051 ,\n",
       "         0.03519956], dtype=float32),\n",
       "  array([0.01763354, 0.01319403, 0.0115812 , 0.89687115, 0.04091249,\n",
       "         0.01980769], dtype=float32),\n",
       "  array([0.02466658, 0.08042844, 0.01258913, 0.00746893, 0.00594612,\n",
       "         0.8689008 ], dtype=float32),\n",
       "  array([0.02645107, 0.49070236, 0.03962195, 0.00961094, 0.01346822,\n",
       "         0.4201455 ], dtype=float32),\n",
       "  array([0.02106047, 0.33650512, 0.0286811 , 0.00686629, 0.00862979,\n",
       "         0.5982572 ], dtype=float32),\n",
       "  array([0.9353237 , 0.00633487, 0.02243655, 0.00479735, 0.00312944,\n",
       "         0.0279781 ], dtype=float32),\n",
       "  array([0.053713  , 0.01797082, 0.01145327, 0.80894583, 0.02349753,\n",
       "         0.08441954], dtype=float32),\n",
       "  array([0.03274086, 0.02508925, 0.00763193, 0.00524709, 0.00444756,\n",
       "         0.9248433 ], dtype=float32),\n",
       "  array([0.02285962, 0.02688507, 0.0348916 , 0.08534174, 0.8022213 ,\n",
       "         0.02780071], dtype=float32),\n",
       "  array([0.0317963 , 0.02827947, 0.00646814, 0.01469701, 0.0051183 ,\n",
       "         0.91364074], dtype=float32),\n",
       "  array([0.54563034, 0.0122312 , 0.01773802, 0.0089063 , 0.00386103,\n",
       "         0.4116332 ], dtype=float32),\n",
       "  array([0.9258766 , 0.008363  , 0.03468449, 0.00595826, 0.00449632,\n",
       "         0.02062133], dtype=float32),\n",
       "  array([0.05954845, 0.03683983, 0.03052351, 0.00980817, 0.00673938,\n",
       "         0.8565407 ], dtype=float32),\n",
       "  array([0.9207218 , 0.00810152, 0.03421341, 0.00707164, 0.00546574,\n",
       "         0.02442589], dtype=float32),\n",
       "  array([0.93113786, 0.00514164, 0.01606187, 0.00433211, 0.00280643,\n",
       "         0.0405201 ], dtype=float32),\n",
       "  array([0.03227989, 0.01241901, 0.01383519, 0.8580669 , 0.04382372,\n",
       "         0.03957533], dtype=float32),\n",
       "  array([0.846684  , 0.00946293, 0.05591648, 0.00596293, 0.00373506,\n",
       "         0.0782387 ], dtype=float32),\n",
       "  array([0.92854404, 0.00545113, 0.02249063, 0.00344109, 0.00248834,\n",
       "         0.03758478], dtype=float32),\n",
       "  array([0.06055285, 0.01588101, 0.00777849, 0.00672901, 0.00385154,\n",
       "         0.90520716], dtype=float32),\n",
       "  array([0.08278722, 0.02457647, 0.01682351, 0.00789095, 0.00813283,\n",
       "         0.859789  ], dtype=float32),\n",
       "  array([0.93988174, 0.00577154, 0.02016679, 0.00516465, 0.00269207,\n",
       "         0.02632327], dtype=float32),\n",
       "  array([0.01878342, 0.6627784 , 0.20338129, 0.01173644, 0.02549314,\n",
       "         0.07782724], dtype=float32),\n",
       "  array([0.8289614 , 0.01403922, 0.10260894, 0.00665424, 0.00764062,\n",
       "         0.04009562], dtype=float32),\n",
       "  array([0.02280221, 0.16512743, 0.01965791, 0.00560204, 0.00900655,\n",
       "         0.7778039 ], dtype=float32),\n",
       "  array([0.04869985, 0.02692376, 0.01361867, 0.00736581, 0.00409913,\n",
       "         0.8992927 ], dtype=float32),\n",
       "  array([0.923844  , 0.00584413, 0.02590749, 0.00512014, 0.00294956,\n",
       "         0.03633483], dtype=float32),\n",
       "  array([0.0448208 , 0.4071554 , 0.09626248, 0.01615021, 0.01451751,\n",
       "         0.42109364], dtype=float32),\n",
       "  array([0.5516649 , 0.01251459, 0.0233795 , 0.10436915, 0.02652135,\n",
       "         0.28155053], dtype=float32),\n",
       "  array([0.7652916 , 0.01384131, 0.03580944, 0.01158221, 0.00403074,\n",
       "         0.16944475], dtype=float32),\n",
       "  array([0.6434758 , 0.01988433, 0.03519348, 0.09480163, 0.01283384,\n",
       "         0.19381098], dtype=float32),\n",
       "  array([0.01475586, 0.31436867, 0.09626479, 0.07546037, 0.34419757,\n",
       "         0.15495266], dtype=float32),\n",
       "  array([0.8578399 , 0.00856259, 0.04307881, 0.00639661, 0.00513478,\n",
       "         0.0789873 ], dtype=float32),\n",
       "  array([0.05147593, 0.02193498, 0.01006059, 0.00681165, 0.00399951,\n",
       "         0.9057173 ], dtype=float32),\n",
       "  array([0.00863987, 0.0311162 , 0.03026561, 0.06651186, 0.8448756 ,\n",
       "         0.01859088], dtype=float32),\n",
       "  array([0.89027774, 0.009965  , 0.03349416, 0.01410918, 0.00465764,\n",
       "         0.04749645], dtype=float32),\n",
       "  array([0.01074016, 0.701863  , 0.04237441, 0.00880695, 0.01036147,\n",
       "         0.22585413], dtype=float32),\n",
       "  array([0.02271141, 0.15960456, 0.01477761, 0.00729299, 0.00669115,\n",
       "         0.7889223 ], dtype=float32),\n",
       "  array([0.00972011, 0.7592664 , 0.07991319, 0.01094627, 0.02246437,\n",
       "         0.11768974], dtype=float32),\n",
       "  array([0.26804188, 0.01485344, 0.01259011, 0.02880603, 0.00735164,\n",
       "         0.66835696], dtype=float32),\n",
       "  array([0.00845899, 0.78648347, 0.06020491, 0.01216706, 0.02611816,\n",
       "         0.10656744], dtype=float32),\n",
       "  array([0.89946854, 0.01342918, 0.04509374, 0.00582304, 0.00588354,\n",
       "         0.030302  ], dtype=float32),\n",
       "  array([0.01190186, 0.6076116 , 0.0309195 , 0.01130467, 0.01434958,\n",
       "         0.3239127 ], dtype=float32),\n",
       "  array([0.9013233 , 0.00685356, 0.02370821, 0.00434005, 0.00337591,\n",
       "         0.06039894], dtype=float32),\n",
       "  array([0.04819892, 0.04019307, 0.00959997, 0.00581361, 0.00366746,\n",
       "         0.89252704], dtype=float32),\n",
       "  array([0.93805486, 0.0074012 , 0.02199693, 0.00619133, 0.00335996,\n",
       "         0.0229957 ], dtype=float32),\n",
       "  array([0.013554  , 0.61737365, 0.03150922, 0.01164682, 0.0213401 ,\n",
       "         0.30457625], dtype=float32),\n",
       "  array([0.04862675, 0.03836222, 0.01218592, 0.00688309, 0.00456566,\n",
       "         0.8893763 ], dtype=float32),\n",
       "  array([0.8892886 , 0.0111127 , 0.05205506, 0.01457452, 0.0096824 ,\n",
       "         0.02328663], dtype=float32),\n",
       "  array([0.6050259 , 0.0335377 , 0.06221004, 0.00645146, 0.00604253,\n",
       "         0.28673244], dtype=float32),\n",
       "  array([0.83124536, 0.00532213, 0.0125234 , 0.0063974 , 0.00373555,\n",
       "         0.14077622], dtype=float32),\n",
       "  array([0.87194   , 0.00546603, 0.01939538, 0.00500926, 0.00526472,\n",
       "         0.09292448], dtype=float32),\n",
       "  array([0.93236375, 0.00827869, 0.02706002, 0.00544179, 0.003708  ,\n",
       "         0.02314771], dtype=float32),\n",
       "  array([0.9310983 , 0.00688951, 0.02279436, 0.00531532, 0.00256532,\n",
       "         0.03133715], dtype=float32),\n",
       "  array([0.9285615 , 0.00608356, 0.01595213, 0.00628476, 0.00333282,\n",
       "         0.03978518], dtype=float32),\n",
       "  array([0.92525   , 0.00673264, 0.02237294, 0.00946462, 0.00358088,\n",
       "         0.032599  ], dtype=float32),\n",
       "  array([0.07119528, 0.02365626, 0.01120946, 0.00792948, 0.00563771,\n",
       "         0.8803718 ], dtype=float32),\n",
       "  array([0.03987301, 0.01825545, 0.01202317, 0.80806184, 0.02023525,\n",
       "         0.10155128], dtype=float32),\n",
       "  array([0.07011745, 0.03276399, 0.01212226, 0.00562499, 0.00474161,\n",
       "         0.87462974], dtype=float32),\n",
       "  array([0.01996027, 0.1799325 , 0.70918554, 0.01360327, 0.04275833,\n",
       "         0.03456011], dtype=float32),\n",
       "  array([0.02757684, 0.03517347, 0.00778017, 0.01138133, 0.00471599,\n",
       "         0.91337216], dtype=float32),\n",
       "  array([0.9389093 , 0.00499576, 0.01546771, 0.00472547, 0.00242883,\n",
       "         0.03347297], dtype=float32),\n",
       "  array([0.91456115, 0.005419  , 0.01486991, 0.00555577, 0.00234996,\n",
       "         0.05724419], dtype=float32),\n",
       "  array([0.07330929, 0.10456781, 0.02102805, 0.0079927 , 0.00720607,\n",
       "         0.78589606], dtype=float32),\n",
       "  array([0.02893429, 0.03058335, 0.00813601, 0.00757434, 0.00458412,\n",
       "         0.92018795], dtype=float32),\n",
       "  array([0.9059073 , 0.00756483, 0.02730954, 0.00522005, 0.00276004,\n",
       "         0.05123819], dtype=float32),\n",
       "  array([0.03052677, 0.459067  , 0.05667459, 0.008782  , 0.01336589,\n",
       "         0.43158373], dtype=float32),\n",
       "  array([0.03789121, 0.06956027, 0.7920954 , 0.01329958, 0.04794592,\n",
       "         0.03920756], dtype=float32),\n",
       "  array([0.05433853, 0.08167788, 0.01464101, 0.00477607, 0.0048587 ,\n",
       "         0.8397078 ], dtype=float32),\n",
       "  array([0.92391664, 0.00576201, 0.01937081, 0.00550376, 0.00394559,\n",
       "         0.04150105], dtype=float32),\n",
       "  array([0.009137  , 0.02736957, 0.02692584, 0.07459328, 0.845154  ,\n",
       "         0.0168204 ], dtype=float32),\n",
       "  array([0.92343587, 0.00534418, 0.01591681, 0.00495092, 0.00242341,\n",
       "         0.0479288 ], dtype=float32),\n",
       "  array([0.05872658, 0.02741901, 0.01291794, 0.7342979 , 0.02128134,\n",
       "         0.14535728], dtype=float32),\n",
       "  array([0.02662489, 0.085354  , 0.79814154, 0.015925  , 0.04244521,\n",
       "         0.03150922], dtype=float32),\n",
       "  array([0.02213002, 0.03988812, 0.00815979, 0.00619382, 0.00375593,\n",
       "         0.9198723 ], dtype=float32),\n",
       "  array([0.02582653, 0.02405769, 0.00785404, 0.020465  , 0.0050284 ,\n",
       "         0.9167683 ], dtype=float32),\n",
       "  array([0.9092649 , 0.00705647, 0.04075288, 0.00545337, 0.00388658,\n",
       "         0.03358582], dtype=float32),\n",
       "  array([0.01881424, 0.0131775 , 0.01097968, 0.9034888 , 0.03094562,\n",
       "         0.02259415], dtype=float32),\n",
       "  array([0.04196773, 0.01911932, 0.0091253 , 0.01708988, 0.00725684,\n",
       "         0.9054409 ], dtype=float32),\n",
       "  array([0.9178557 , 0.00954793, 0.02923884, 0.01182678, 0.00527914,\n",
       "         0.02625162], dtype=float32),\n",
       "  array([0.01279289, 0.69034994, 0.0436736 , 0.01060147, 0.01188332,\n",
       "         0.2306988 ], dtype=float32),\n",
       "  array([0.08989988, 0.02763857, 0.01312754, 0.01189638, 0.0062388 ,\n",
       "         0.85119885], dtype=float32),\n",
       "  array([0.0316783 , 0.0299621 , 0.01001413, 0.06082441, 0.00903681,\n",
       "         0.8584842 ], dtype=float32),\n",
       "  array([0.93512416, 0.0069731 , 0.02247257, 0.00651319, 0.00340502,\n",
       "         0.025512  ], dtype=float32),\n",
       "  array([0.08543169, 0.05120631, 0.47194   , 0.03506729, 0.28024024,\n",
       "         0.07611445], dtype=float32),\n",
       "  array([0.03680755, 0.03713058, 0.0173322 , 0.5282859 , 0.06112828,\n",
       "         0.3193155 ], dtype=float32),\n",
       "  array([0.05024627, 0.06782296, 0.01491002, 0.00659703, 0.00572803,\n",
       "         0.8546957 ], dtype=float32),\n",
       "  array([0.9117901 , 0.00577705, 0.01879695, 0.00654524, 0.00370559,\n",
       "         0.05338509], dtype=float32),\n",
       "  array([0.00789642, 0.02936238, 0.03085078, 0.05305254, 0.85351235,\n",
       "         0.02532551], dtype=float32),\n",
       "  array([0.8644773 , 0.01083164, 0.02528679, 0.01959116, 0.0049882 ,\n",
       "         0.0748249 ], dtype=float32),\n",
       "  array([0.91724455, 0.00701532, 0.02053875, 0.00906587, 0.00358602,\n",
       "         0.04254953], dtype=float32),\n",
       "  array([0.09730252, 0.01472989, 0.01631694, 0.79231477, 0.03903849,\n",
       "         0.04029738], dtype=float32),\n",
       "  array([0.02724832, 0.03110797, 0.00859274, 0.00593359, 0.0039505 ,\n",
       "         0.9231669 ], dtype=float32),\n",
       "  array([0.9140252 , 0.00619185, 0.02402647, 0.00393594, 0.00289846,\n",
       "         0.04892196], dtype=float32),\n",
       "  array([0.9053313 , 0.00728518, 0.02450663, 0.01235766, 0.00513055,\n",
       "         0.04538862], dtype=float32),\n",
       "  array([0.13196895, 0.03159158, 0.02899121, 0.00564362, 0.00617291,\n",
       "         0.79563177], dtype=float32),\n",
       "  array([0.03453853, 0.03323568, 0.0109661 , 0.00614381, 0.0037179 ,\n",
       "         0.91139793], dtype=float32),\n",
       "  array([0.9450599 , 0.00572549, 0.01798762, 0.00542211, 0.00309237,\n",
       "         0.02271244], dtype=float32),\n",
       "  array([0.02206618, 0.03140439, 0.00800255, 0.00589811, 0.00403624,\n",
       "         0.92859256], dtype=float32),\n",
       "  array([0.08580002, 0.02565647, 0.03064583, 0.00680184, 0.00457026,\n",
       "         0.8465256 ], dtype=float32),\n",
       "  array([0.22227576, 0.02240085, 0.02204706, 0.00801565, 0.00313501,\n",
       "         0.7221257 ], dtype=float32),\n",
       "  array([0.6367439 , 0.03311894, 0.23785046, 0.01417712, 0.02615166,\n",
       "         0.0519579 ], dtype=float32),\n",
       "  array([0.9101999 , 0.00756626, 0.03577604, 0.01269406, 0.00667631,\n",
       "         0.02708754], dtype=float32),\n",
       "  array([0.0712364 , 0.03150619, 0.02179804, 0.01566893, 0.01854882,\n",
       "         0.8412416 ], dtype=float32),\n",
       "  array([0.00788007, 0.02547546, 0.02837132, 0.06554363, 0.85763335,\n",
       "         0.01509612], dtype=float32),\n",
       "  array([0.86182076, 0.00661307, 0.01523867, 0.00628283, 0.00238249,\n",
       "         0.10766222], dtype=float32),\n",
       "  array([0.01315893, 0.06683687, 0.07264014, 0.06938799, 0.75106883,\n",
       "         0.02690724], dtype=float32),\n",
       "  array([0.06774893, 0.02473865, 0.01632691, 0.07601251, 0.07024429,\n",
       "         0.7449287 ], dtype=float32),\n",
       "  array([0.03181551, 0.04329285, 0.01128787, 0.00878339, 0.0057854 ,\n",
       "         0.89903504], dtype=float32),\n",
       "  array([0.9014099 , 0.00982892, 0.04284971, 0.00452725, 0.00360078,\n",
       "         0.03778344], dtype=float32),\n",
       "  array([0.2938733 , 0.07260619, 0.4956058 , 0.01067529, 0.02377507,\n",
       "         0.10346432], dtype=float32),\n",
       "  array([0.0250908 , 0.03025655, 0.00708076, 0.01352865, 0.00500054,\n",
       "         0.9190427 ], dtype=float32),\n",
       "  array([0.93742096, 0.00550675, 0.02182477, 0.00455366, 0.00263905,\n",
       "         0.02805481], dtype=float32),\n",
       "  array([0.89056426, 0.01276061, 0.05199905, 0.00651598, 0.00625518,\n",
       "         0.03190485], dtype=float32),\n",
       "  array([0.91661155, 0.00835977, 0.03883354, 0.00550837, 0.00343553,\n",
       "         0.02725127], dtype=float32),\n",
       "  array([0.09563784, 0.02972852, 0.01140822, 0.00558534, 0.00392709,\n",
       "         0.85371304], dtype=float32),\n",
       "  array([0.01047754, 0.02542847, 0.03019764, 0.06227973, 0.85025334,\n",
       "         0.02136326], dtype=float32),\n",
       "  array([0.04906097, 0.03232644, 0.01162098, 0.01123591, 0.00743475,\n",
       "         0.8883209 ], dtype=float32),\n",
       "  array([0.03201697, 0.01262452, 0.0121103 , 0.8829476 , 0.03359411,\n",
       "         0.02670645], dtype=float32),\n",
       "  array([0.9406036 , 0.00561429, 0.017849  , 0.00721139, 0.00354095,\n",
       "         0.02518086], dtype=float32),\n",
       "  array([0.04735992, 0.13250858, 0.0856551 , 0.02230136, 0.07339387,\n",
       "         0.63878125], dtype=float32),\n",
       "  array([0.0343815 , 0.03902469, 0.00921076, 0.0056402 , 0.00372794,\n",
       "         0.90801495], dtype=float32),\n",
       "  array([0.06446776, 0.08482229, 0.4303932 , 0.01222106, 0.02710935,\n",
       "         0.3809864 ], dtype=float32),\n",
       "  array([0.00942009, 0.02649335, 0.03764594, 0.05947439, 0.84834194,\n",
       "         0.01862426], dtype=float32),\n",
       "  array([0.04810053, 0.02772689, 0.00931122, 0.00793936, 0.00453032,\n",
       "         0.90239173], dtype=float32),\n",
       "  array([0.01276237, 0.0270597 , 0.04062299, 0.05812616, 0.8073941 ,\n",
       "         0.05403474], dtype=float32),\n",
       "  array([0.8529387 , 0.0102484 , 0.04329253, 0.00391525, 0.00277756,\n",
       "         0.08682761], dtype=float32),\n",
       "  array([0.8647527 , 0.0063234 , 0.01103077, 0.00572419, 0.00283606,\n",
       "         0.10933284], dtype=float32),\n",
       "  array([0.01983689, 0.25580183, 0.02314679, 0.00962822, 0.00946049,\n",
       "         0.68212575], dtype=float32),\n",
       "  array([0.8767212 , 0.01198706, 0.06739537, 0.00769067, 0.00576236,\n",
       "         0.03044328], dtype=float32),\n",
       "  array([0.02756162, 0.03497558, 0.0088265 , 0.00669888, 0.00420947,\n",
       "         0.91772795], dtype=float32),\n",
       "  array([0.01989694, 0.02475305, 0.048126  , 0.14631087, 0.729053  ,\n",
       "         0.03186015], dtype=float32),\n",
       "  array([0.01499847, 0.722641  , 0.0502859 , 0.01155113, 0.01886982,\n",
       "         0.18165368], dtype=float32),\n",
       "  array([0.2604017 , 0.01549806, 0.01125939, 0.08844503, 0.00861475,\n",
       "         0.6157811 ], dtype=float32),\n",
       "  array([0.9309201 , 0.00418194, 0.01340777, 0.00638912, 0.00355677,\n",
       "         0.04154424], dtype=float32),\n",
       "  array([0.85656357, 0.00847524, 0.01907769, 0.0075633 , 0.00305652,\n",
       "         0.10526366], dtype=float32),\n",
       "  array([0.92861396, 0.00629174, 0.01763686, 0.0040749 , 0.00249742,\n",
       "         0.0408852 ], dtype=float32),\n",
       "  array([0.01512278, 0.61606413, 0.09129556, 0.0182738 , 0.07440532,\n",
       "         0.18483846], dtype=float32),\n",
       "  array([0.05567828, 0.13224508, 0.07027888, 0.00759731, 0.01425317,\n",
       "         0.71994734], dtype=float32),\n",
       "  array([0.929729  , 0.00430749, 0.01327317, 0.00662332, 0.0032625 ,\n",
       "         0.0428046 ], dtype=float32),\n",
       "  array([0.9362062 , 0.00504918, 0.01454565, 0.00557665, 0.00272972,\n",
       "         0.03589256], dtype=float32),\n",
       "  array([0.03792879, 0.05071903, 0.01718113, 0.00844733, 0.00818256,\n",
       "         0.8775411 ], dtype=float32),\n",
       "  array([0.77218926, 0.01393767, 0.05340703, 0.07506879, 0.03202999,\n",
       "         0.05336723], dtype=float32),\n",
       "  array([0.50900525, 0.02016602, 0.02641575, 0.00953629, 0.00409519,\n",
       "         0.43078154], dtype=float32),\n",
       "  array([0.03999565, 0.07442954, 0.01647072, 0.00488635, 0.0051185 ,\n",
       "         0.85909927], dtype=float32),\n",
       "  array([0.01298478, 0.04258319, 0.05418536, 0.06955168, 0.7103405 ,\n",
       "         0.11035449], dtype=float32),\n",
       "  array([0.86577785, 0.01029611, 0.03755793, 0.00763469, 0.00374807,\n",
       "         0.07498539], dtype=float32),\n",
       "  array([0.79372585, 0.02235739, 0.04187814, 0.0365776 , 0.01251898,\n",
       "         0.09294208], dtype=float32),\n",
       "  array([0.04997531, 0.08411595, 0.7262134 , 0.01610169, 0.05344989,\n",
       "         0.0701438 ], dtype=float32),\n",
       "  array([0.00651926, 0.8307852 , 0.05129232, 0.01384716, 0.02327152,\n",
       "         0.07428452], dtype=float32),\n",
       "  array([0.00982468, 0.0200657 , 0.03249832, 0.06380526, 0.8467674 ,\n",
       "         0.02703866], dtype=float32),\n",
       "  array([0.01087274, 0.6994961 , 0.05938429, 0.00930037, 0.02068013,\n",
       "         0.20026633], dtype=float32),\n",
       "  array([0.05010398, 0.07540574, 0.01955919, 0.00444145, 0.00666812,\n",
       "         0.8438215 ], dtype=float32),\n",
       "  array([0.90851504, 0.00745217, 0.02387979, 0.01616467, 0.00496804,\n",
       "         0.03902021], dtype=float32),\n",
       "  array([0.00681442, 0.84028804, 0.04720452, 0.01340907, 0.02240296,\n",
       "         0.0698811 ], dtype=float32),\n",
       "  array([0.05783749, 0.01817744, 0.00985706, 0.01085006, 0.00445382,\n",
       "         0.89882416], dtype=float32),\n",
       "  array([0.8854693 , 0.00823924, 0.02276091, 0.00894904, 0.00307054,\n",
       "         0.07151103], dtype=float32),\n",
       "  array([0.0323818 , 0.01396019, 0.01081639, 0.8588081 , 0.03966135,\n",
       "         0.04437218], dtype=float32),\n",
       "  array([0.01546393, 0.35553104, 0.4847563 , 0.01815763, 0.07221042,\n",
       "         0.05388068], dtype=float32),\n",
       "  array([0.05498207, 0.01289647, 0.00763865, 0.01481343, 0.0055176 ,\n",
       "         0.9041518 ], dtype=float32),\n",
       "  array([0.01362221, 0.02131336, 0.042688  , 0.0566901 , 0.84701234,\n",
       "         0.01867398], dtype=float32),\n",
       "  array([0.01438819, 0.46938902, 0.39949974, 0.02068962, 0.06853314,\n",
       "         0.02750022], dtype=float32),\n",
       "  array([0.08113907, 0.07890184, 0.7220884 , 0.01176833, 0.02780961,\n",
       "         0.07829283], dtype=float32),\n",
       "  array([0.02099073, 0.5510096 , 0.0585553 , 0.01623828, 0.03103455,\n",
       "         0.32217154], dtype=float32),\n",
       "  array([0.73395425, 0.01689987, 0.02254504, 0.00510899, 0.00295929,\n",
       "         0.21853255], dtype=float32),\n",
       "  array([0.05317712, 0.08856519, 0.76581717, 0.01530116, 0.04273232,\n",
       "         0.03440707], dtype=float32),\n",
       "  array([0.01802434, 0.02070819, 0.04779028, 0.06178868, 0.8319001 ,\n",
       "         0.01978842], dtype=float32),\n",
       "  array([0.35587114, 0.02291592, 0.0386271 , 0.0085139 , 0.00832926,\n",
       "         0.56574273], dtype=float32),\n",
       "  array([0.02340063, 0.01883539, 0.01044672, 0.85718215, 0.02477879,\n",
       "         0.06535633], dtype=float32),\n",
       "  array([0.15196507, 0.01795616, 0.01477645, 0.0074896 , 0.00462921,\n",
       "         0.80318356], dtype=float32),\n",
       "  array([0.03638549, 0.01730047, 0.0316754 , 0.7364898 , 0.15585363,\n",
       "         0.02229521], dtype=float32),\n",
       "  array([0.08207069, 0.02317063, 0.00951436, 0.02344247, 0.00838521,\n",
       "         0.8534167 ], dtype=float32),\n",
       "  array([0.01569313, 0.40916097, 0.0260333 , 0.01081832, 0.01072321,\n",
       "         0.5275711 ], dtype=float32),\n",
       "  array([0.09570764, 0.01697633, 0.00774071, 0.01039821, 0.00582133,\n",
       "         0.86335576], dtype=float32),\n",
       "  array([0.01292445, 0.66208357, 0.04961393, 0.00884831, 0.01161547,\n",
       "         0.25491434], dtype=float32),\n",
       "  array([0.03097216, 0.1697274 , 0.69978875, 0.00944534, 0.02954538,\n",
       "         0.06052093], dtype=float32),\n",
       "  array([0.05322769, 0.05482757, 0.01891593, 0.00702039, 0.00562231,\n",
       "         0.86038613], dtype=float32),\n",
       "  array([0.02166221, 0.21748586, 0.6275416 , 0.01379773, 0.06033627,\n",
       "         0.05917629], dtype=float32),\n",
       "  array([0.27720276, 0.0573168 , 0.05339383, 0.00622273, 0.00863214,\n",
       "         0.59723175], dtype=float32),\n",
       "  array([0.0807486 , 0.06510662, 0.61335987, 0.03028484, 0.11380645,\n",
       "         0.09669366], dtype=float32),\n",
       "  array([0.9283252 , 0.00833174, 0.02697619, 0.00478927, 0.00351128,\n",
       "         0.02806644], dtype=float32),\n",
       "  array([0.9336404 , 0.00732959, 0.02132474, 0.00854405, 0.00398737,\n",
       "         0.0251738 ], dtype=float32),\n",
       "  array([0.01211019, 0.0240976 , 0.02926714, 0.07035921, 0.823784  ,\n",
       "         0.04038187], dtype=float32),\n",
       "  array([0.67390203, 0.01938557, 0.24395865, 0.01286933, 0.02077588,\n",
       "         0.0291086 ], dtype=float32),\n",
       "  array([0.01618783, 0.02002687, 0.04638325, 0.06567179, 0.83058774,\n",
       "         0.02114256], dtype=float32),\n",
       "  array([0.02808375, 0.02470025, 0.0070736 , 0.00604018, 0.00356445,\n",
       "         0.93053776], dtype=float32),\n",
       "  array([0.93468124, 0.00740428, 0.02022111, 0.00699306, 0.00320862,\n",
       "         0.02749162], dtype=float32),\n",
       "  array([0.04430132, 0.03427165, 0.01419305, 0.00855863, 0.00592293,\n",
       "         0.8927524 ], dtype=float32),\n",
       "  array([0.01069315, 0.7560416 , 0.03875574, 0.00913451, 0.01396059,\n",
       "         0.17141443], dtype=float32),\n",
       "  array([0.910247  , 0.00544552, 0.01792613, 0.00389102, 0.00285134,\n",
       "         0.05963887], dtype=float32),\n",
       "  array([0.00765156, 0.7950952 , 0.03668522, 0.01183462, 0.01447861,\n",
       "         0.13425487], dtype=float32),\n",
       "  array([0.04711647, 0.02608191, 0.00881399, 0.00588849, 0.00306857,\n",
       "         0.9090306 ], dtype=float32),\n",
       "  array([0.93980527, 0.00701376, 0.0223463 , 0.00609385, 0.00346898,\n",
       "         0.0212718 ], dtype=float32),\n",
       "  array([0.91168034, 0.00951748, 0.04120305, 0.00595068, 0.00363956,\n",
       "         0.02800875], dtype=float32),\n",
       "  array([0.07855281, 0.02017162, 0.01131219, 0.0059513 , 0.00406612,\n",
       "         0.87994593], dtype=float32),\n",
       "  array([0.91889066, 0.00546189, 0.01672027, 0.00397077, 0.00253395,\n",
       "         0.05242243], dtype=float32),\n",
       "  array([0.89269304, 0.01136324, 0.04988021, 0.01374561, 0.0078539 ,\n",
       "         0.02446392], dtype=float32),\n",
       "  array([0.04876598, 0.02421186, 0.01016867, 0.00521748, 0.00411173,\n",
       "         0.9075243 ], dtype=float32),\n",
       "  array([0.9336424 , 0.00837704, 0.02309993, 0.00524711, 0.00345665,\n",
       "         0.02617694], dtype=float32),\n",
       "  array([0.05414502, 0.02756421, 0.00986333, 0.00597666, 0.00416204,\n",
       "         0.8982887 ], dtype=float32),\n",
       "  array([0.85344905, 0.01102709, 0.08706575, 0.00561241, 0.00480366,\n",
       "         0.03804194], dtype=float32),\n",
       "  array([0.88663536, 0.00799379, 0.05070334, 0.00506758, 0.00475642,\n",
       "         0.04484346], dtype=float32),\n",
       "  array([0.9435029 , 0.00572723, 0.01905574, 0.00493946, 0.00286993,\n",
       "         0.02390482], dtype=float32),\n",
       "  array([0.05514186, 0.05577546, 0.01672378, 0.16758163, 0.01539494,\n",
       "         0.6893823 ], dtype=float32),\n",
       "  array([0.8991793 , 0.00757848, 0.02959034, 0.00460944, 0.00245303,\n",
       "         0.0565894 ], dtype=float32),\n",
       "  array([0.8918475 , 0.00684198, 0.01295839, 0.00829672, 0.00363494,\n",
       "         0.07642043], dtype=float32),\n",
       "  array([0.06844588, 0.06454714, 0.6732855 , 0.0137936 , 0.03660438,\n",
       "         0.14332359], dtype=float32),\n",
       "  array([0.04629917, 0.02486541, 0.00921851, 0.03125826, 0.00645221,\n",
       "         0.88190645], dtype=float32),\n",
       "  array([0.03014605, 0.07713644, 0.01136608, 0.0092727 , 0.00508792,\n",
       "         0.86699075], dtype=float32),\n",
       "  array([0.8679751 , 0.00955383, 0.0413937 , 0.00626557, 0.00357101,\n",
       "         0.07124077], dtype=float32),\n",
       "  array([0.02383788, 0.08416649, 0.01282173, 0.00528393, 0.00426058,\n",
       "         0.8696293 ], dtype=float32),\n",
       "  array([0.8846227 , 0.01120296, 0.06560193, 0.00817168, 0.00604648,\n",
       "         0.02435423], dtype=float32),\n",
       "  array([0.07594119, 0.01675839, 0.01023105, 0.00778395, 0.00528583,\n",
       "         0.8839996 ], dtype=float32),\n",
       "  array([0.04051238, 0.0182246 , 0.00767387, 0.00670849, 0.00405042,\n",
       "         0.9228302 ], dtype=float32),\n",
       "  array([0.9265102 , 0.00694495, 0.02454896, 0.00670412, 0.0040432 ,\n",
       "         0.03124855], dtype=float32),\n",
       "  array([0.7548192 , 0.02773143, 0.161359  , 0.01089126, 0.0120975 ,\n",
       "         0.03310167], dtype=float32),\n",
       "  array([0.8813649 , 0.00523107, 0.01643581, 0.00613484, 0.00470962,\n",
       "         0.08612371], dtype=float32),\n",
       "  array([0.8372202 , 0.00986256, 0.03334156, 0.00468901, 0.00385393,\n",
       "         0.11103277], dtype=float32),\n",
       "  array([0.04982524, 0.02725026, 0.0132537 , 0.7236119 , 0.02456736,\n",
       "         0.16149156], dtype=float32),\n",
       "  array([0.05826451, 0.08548065, 0.02396658, 0.00872051, 0.00795189,\n",
       "         0.81561583], dtype=float32),\n",
       "  array([0.00570684, 0.83515286, 0.0371944 , 0.01101527, 0.01807539,\n",
       "         0.09285521], dtype=float32),\n",
       "  array([0.06641199, 0.01842631, 0.00806184, 0.0060402 , 0.0041944 ,\n",
       "         0.8968653 ], dtype=float32),\n",
       "  array([0.03926019, 0.09183414, 0.03273049, 0.00787664, 0.00683672,\n",
       "         0.82146186], dtype=float32),\n",
       "  array([0.03039815, 0.03587673, 0.00990222, 0.07742509, 0.01080389,\n",
       "         0.83559394], dtype=float32),\n",
       "  array([0.06314935, 0.06641862, 0.74605495, 0.0238215 , 0.07719056,\n",
       "         0.02336508], dtype=float32),\n",
       "  array([0.05121542, 0.05574019, 0.0134225 , 0.00738787, 0.00618546,\n",
       "         0.8660486 ], dtype=float32),\n",
       "  array([0.02279263, 0.02905344, 0.00785045, 0.00961849, 0.00422315,\n",
       "         0.9264618 ], dtype=float32),\n",
       "  array([0.03444064, 0.03161009, 0.01114197, 0.00899641, 0.00586329,\n",
       "         0.9079476 ], dtype=float32),\n",
       "  array([0.09351278, 0.08494429, 0.08290925, 0.01234948, 0.00894677,\n",
       "         0.71733737], dtype=float32),\n",
       "  array([0.01822057, 0.6081096 , 0.26583058, 0.01091393, 0.04231758,\n",
       "         0.05460771], dtype=float32),\n",
       "  array([0.93596345, 0.00630974, 0.02234478, 0.00459186, 0.0027576 ,\n",
       "         0.02803252], dtype=float32),\n",
       "  array([0.655036  , 0.01363714, 0.02736167, 0.00783303, 0.00323613,\n",
       "         0.2928961 ], dtype=float32),\n",
       "  array([0.8610455 , 0.01583739, 0.08116046, 0.00813016, 0.0055175 ,\n",
       "         0.02830912], dtype=float32),\n",
       "  array([0.00653761, 0.85421777, 0.0478876 , 0.01318679, 0.0203299 ,\n",
       "         0.05784033], dtype=float32),\n",
       "  array([0.0115823 , 0.7001635 , 0.11834631, 0.01078169, 0.02131263,\n",
       "         0.13781355], dtype=float32),\n",
       "  array([0.00848146, 0.03132652, 0.02752922, 0.06991365, 0.8412785 ,\n",
       "         0.02147074], dtype=float32),\n",
       "  array([0.01035365, 0.02445191, 0.02876396, 0.06090757, 0.8548147 ,\n",
       "         0.02070819], dtype=float32),\n",
       "  array([0.04168615, 0.08418433, 0.7433154 , 0.0262692 , 0.07347777,\n",
       "         0.03106712], dtype=float32),\n",
       "  array([0.06842449, 0.02680509, 0.01015996, 0.00559729, 0.00357425,\n",
       "         0.885439  ], dtype=float32),\n",
       "  array([0.93223155, 0.00605137, 0.02613418, 0.00542082, 0.00315018,\n",
       "         0.02701185], dtype=float32),\n",
       "  array([0.06206609, 0.02160163, 0.00788251, 0.0083951 , 0.0045944 ,\n",
       "         0.89546025], dtype=float32),\n",
       "  array([0.04903938, 0.02224525, 0.00746586, 0.02269013, 0.00636353,\n",
       "         0.8921958 ], dtype=float32),\n",
       "  array([0.04943397, 0.05950041, 0.01634302, 0.34776422, 0.02284862,\n",
       "         0.50410974], dtype=float32),\n",
       "  array([0.855075  , 0.01458049, 0.03002849, 0.00518749, 0.00381579,\n",
       "         0.09131276], dtype=float32),\n",
       "  array([0.02786976, 0.01670514, 0.01271557, 0.8719101 , 0.02272281,\n",
       "         0.04807662], dtype=float32),\n",
       "  array([0.02274355, 0.13517404, 0.01474874, 0.00725038, 0.00788711,\n",
       "         0.81219614], dtype=float32),\n",
       "  array([0.00931483, 0.7767018 , 0.06215798, 0.00997721, 0.01496277,\n",
       "         0.1268853 ], dtype=float32),\n",
       "  array([0.04781137, 0.01671362, 0.00791612, 0.01102237, 0.00571074,\n",
       "         0.9108258 ], dtype=float32),\n",
       "  array([0.9173999 , 0.0104445 , 0.02978584, 0.01138562, 0.00516864,\n",
       "         0.02581545], dtype=float32),\n",
       "  array([0.9307132 , 0.00540863, 0.01811346, 0.00520893, 0.00278007,\n",
       "         0.03777565], dtype=float32),\n",
       "  array([0.9384074 , 0.00567979, 0.0159465 , 0.00678366, 0.00460371,\n",
       "         0.02857895], dtype=float32),\n",
       "  array([0.02306141, 0.24018066, 0.0293433 , 0.0079098 , 0.00785862,\n",
       "         0.6916462 ], dtype=float32),\n",
       "  array([0.9418378 , 0.00584035, 0.02036048, 0.00643812, 0.0034224 ,\n",
       "         0.02210093], dtype=float32),\n",
       "  array([0.02233179, 0.17068939, 0.6211868 , 0.01848321, 0.10792862,\n",
       "         0.05938021], dtype=float32),\n",
       "  array([0.02851137, 0.0351197 , 0.00801375, 0.01118896, 0.00646473,\n",
       "         0.9107015 ], dtype=float32),\n",
       "  array([0.05663393, 0.02225457, 0.0101402 , 0.01098859, 0.00597646,\n",
       "         0.89400625], dtype=float32),\n",
       "  array([0.07042382, 0.02300129, 0.00937243, 0.00994145, 0.00545228,\n",
       "         0.88180876], dtype=float32),\n",
       "  array([0.92861414, 0.0076659 , 0.0295925 , 0.00870436, 0.0059049 ,\n",
       "         0.01951806], dtype=float32),\n",
       "  array([0.09569521, 0.07807133, 0.48611405, 0.03115235, 0.13921878,\n",
       "         0.16974834], dtype=float32),\n",
       "  array([0.9258437 , 0.00618587, 0.01932344, 0.00351393, 0.0027638 ,\n",
       "         0.04236932], dtype=float32),\n",
       "  array([0.01293708, 0.02109387, 0.0285758 , 0.05595442, 0.8613655 ,\n",
       "         0.02007322], dtype=float32),\n",
       "  array([0.02549872, 0.03325247, 0.0368842 , 0.08370996, 0.78465337,\n",
       "         0.03600127], dtype=float32),\n",
       "  array([0.9270644 , 0.00579418, 0.02038652, 0.00377468, 0.00253417,\n",
       "         0.04044608], dtype=float32),\n",
       "  array([0.01586605, 0.51090926, 0.04874843, 0.00710149, 0.01143127,\n",
       "         0.40594357], dtype=float32),\n",
       "  array([0.01632675, 0.23181269, 0.6353862 , 0.01222969, 0.04926468,\n",
       "         0.05497998], dtype=float32),\n",
       "  array([0.01411468, 0.59010714, 0.0744685 , 0.01036576, 0.01985855,\n",
       "         0.29108542], dtype=float32),\n",
       "  array([0.908475  , 0.00811888, 0.03931701, 0.00468448, 0.00383418,\n",
       "         0.03557055], dtype=float32),\n",
       "  array([0.91096693, 0.01214661, 0.03239046, 0.00602419, 0.00514082,\n",
       "         0.03333097], dtype=float32),\n",
       "  array([0.8968144 , 0.00923906, 0.05501891, 0.00508558, 0.00510717,\n",
       "         0.02873498], dtype=float32),\n",
       "  array([0.02286884, 0.17999475, 0.01860002, 0.00731951, 0.00642322,\n",
       "         0.7647937 ], dtype=float32),\n",
       "  array([0.94059443, 0.00572145, 0.01982821, 0.00517732, 0.00286187,\n",
       "         0.02581686], dtype=float32),\n",
       "  array([0.5719249 , 0.02505913, 0.27650353, 0.00749468, 0.01078288,\n",
       "         0.10823487], dtype=float32),\n",
       "  array([0.93754804, 0.00683164, 0.02469256, 0.00491935, 0.00407111,\n",
       "         0.0219373 ], dtype=float32),\n",
       "  array([0.17328353, 0.0210021 , 0.01069593, 0.18323682, 0.01020453,\n",
       "         0.6015771 ], dtype=float32),\n",
       "  array([0.91680026, 0.00863561, 0.02203019, 0.00483594, 0.00271928,\n",
       "         0.04497879], dtype=float32),\n",
       "  array([0.02516625, 0.01928052, 0.02227878, 0.8153011 , 0.07470276,\n",
       "         0.04327061], dtype=float32),\n",
       "  array([0.05895312, 0.01941655, 0.0104079 , 0.01072515, 0.00494224,\n",
       "         0.8955551 ], dtype=float32),\n",
       "  array([0.9371359 , 0.00514319, 0.01772141, 0.00552505, 0.00412366,\n",
       "         0.03035077], dtype=float32),\n",
       "  array([0.9283077 , 0.00499596, 0.01821791, 0.0037775 , 0.0024675 ,\n",
       "         0.04223344], dtype=float32),\n",
       "  array([0.03041546, 0.5159882 , 0.32211718, 0.0117137 , 0.02604063,\n",
       "         0.09372485], dtype=float32),\n",
       "  array([0.06387825, 0.05103299, 0.016594  , 0.00624761, 0.00759788,\n",
       "         0.85464925], dtype=float32),\n",
       "  array([0.8272377 , 0.00910595, 0.02464848, 0.00385228, 0.0025981 ,\n",
       "         0.13255748], dtype=float32),\n",
       "  array([0.8458635 , 0.01373922, 0.094793  , 0.00695018, 0.00558625,\n",
       "         0.03306787], dtype=float32),\n",
       "  array([0.05239344, 0.06696656, 0.02413878, 0.00645878, 0.00854687,\n",
       "         0.84149563], dtype=float32),\n",
       "  array([0.93575007, 0.00715181, 0.02298496, 0.00830378, 0.00386655,\n",
       "         0.02194284], dtype=float32),\n",
       "  array([0.90818805, 0.00998055, 0.04358004, 0.00877283, 0.00480575,\n",
       "         0.02467281], dtype=float32),\n",
       "  array([0.05021325, 0.09039988, 0.17686363, 0.0156838 , 0.04049016,\n",
       "         0.6263493 ], dtype=float32),\n",
       "  array([0.9211459 , 0.00641608, 0.02199757, 0.00375177, 0.00307112,\n",
       "         0.0436176 ], dtype=float32),\n",
       "  array([0.0101847 , 0.76960695, 0.10136633, 0.0100323 , 0.03116367,\n",
       "         0.07764594], dtype=float32),\n",
       "  array([0.03045991, 0.04484951, 0.0092678 , 0.01170616, 0.0070042 ,\n",
       "         0.89671236], dtype=float32),\n",
       "  array([0.11915515, 0.13019548, 0.6697884 , 0.01321739, 0.03544246,\n",
       "         0.03220112], dtype=float32),\n",
       "  array([0.04147912, 0.04548793, 0.01306832, 0.01148448, 0.00700023,\n",
       "         0.8814799 ], dtype=float32),\n",
       "  array([0.90363973, 0.00780947, 0.02419477, 0.00694165, 0.00341157,\n",
       "         0.05400291], dtype=float32),\n",
       "  array([0.24361315, 0.04583428, 0.5927303 , 0.02228115, 0.07131547,\n",
       "         0.02422562], dtype=float32),\n",
       "  array([0.05283332, 0.03561205, 0.01218623, 0.00649642, 0.00498709,\n",
       "         0.8878849 ], dtype=float32),\n",
       "  array([0.9301664 , 0.00741206, 0.02752452, 0.00547282, 0.00293737,\n",
       "         0.02648691], dtype=float32),\n",
       "  array([0.04411866, 0.03344504, 0.00914168, 0.00530895, 0.00414336,\n",
       "         0.9038423 ], dtype=float32),\n",
       "  array([0.00794886, 0.0355971 , 0.02622714, 0.15557109, 0.7436303 ,\n",
       "         0.03102541], dtype=float32),\n",
       "  array([0.00758653, 0.7689626 , 0.03527625, 0.01056697, 0.01915594,\n",
       "         0.15845177], dtype=float32),\n",
       "  array([0.92594653, 0.00749503, 0.02640651, 0.00678129, 0.00359581,\n",
       "         0.02977484], dtype=float32),\n",
       "  array([0.02850588, 0.0438971 , 0.01146046, 0.02285056, 0.01256253,\n",
       "         0.8807234 ], dtype=float32),\n",
       "  array([0.02456246, 0.02958626, 0.00787723, 0.00826172, 0.0051319 ,\n",
       "         0.9245804 ], dtype=float32),\n",
       "  array([0.00981191, 0.7861149 , 0.06918908, 0.00924236, 0.01567722,\n",
       "         0.10996451], dtype=float32),\n",
       "  array([0.5980748 , 0.01947694, 0.03557178, 0.00623048, 0.00568305,\n",
       "         0.33496293], dtype=float32),\n",
       "  array([0.11307614, 0.0275191 , 0.0401148 , 0.01820358, 0.03351044,\n",
       "         0.7675759 ], dtype=float32),\n",
       "  array([0.83714104, 0.01298916, 0.04627831, 0.00650528, 0.00350874,\n",
       "         0.09357747], dtype=float32),\n",
       "  array([0.8788617 , 0.00843286, 0.03236476, 0.01251126, 0.00591989,\n",
       "         0.06190962], dtype=float32),\n",
       "  array([0.89411974, 0.00718856, 0.02310948, 0.00575495, 0.00257903,\n",
       "         0.06724816], dtype=float32),\n",
       "  array([0.03927704, 0.14153329, 0.02439045, 0.00911847, 0.00851434,\n",
       "         0.77716637], dtype=float32),\n",
       "  array([0.8595041 , 0.01547707, 0.05230492, 0.00784852, 0.00520816,\n",
       "         0.0596572 ], dtype=float32),\n",
       "  array([0.04276397, 0.01718233, 0.01268881, 0.81561744, 0.02002052,\n",
       "         0.09172686], dtype=float32),\n",
       "  array([0.93421435, 0.00577879, 0.01765134, 0.00818648, 0.00405334,\n",
       "         0.03011562], dtype=float32),\n",
       "  array([0.04971951, 0.2634295 , 0.51716894, 0.01139219, 0.02040982,\n",
       "         0.13788013], dtype=float32),\n",
       "  array([0.9228959 , 0.00756644, 0.03341615, 0.00425133, 0.00314258,\n",
       "         0.02872759], dtype=float32),\n",
       "  array([0.9151053 , 0.00554724, 0.01632044, 0.00390639, 0.00268801,\n",
       "         0.0564326 ], dtype=float32),\n",
       "  array([0.00714533, 0.03623097, 0.03104875, 0.06995662, 0.8289933 ,\n",
       "         0.02662506], dtype=float32),\n",
       "  array([0.93277556, 0.00642399, 0.02149315, 0.00579364, 0.00299365,\n",
       "         0.03052006], dtype=float32),\n",
       "  array([0.8798027 , 0.00563372, 0.018789  , 0.00487594, 0.00258399,\n",
       "         0.0883148 ], dtype=float32),\n",
       "  array([0.07194757, 0.2538499 , 0.06431779, 0.00795117, 0.00882689,\n",
       "         0.5931067 ], dtype=float32),\n",
       "  array([0.0913291 , 0.03218178, 0.01541079, 0.00400023, 0.0040736 ,\n",
       "         0.85300446], dtype=float32),\n",
       "  array([0.05379101, 0.08373804, 0.16978915, 0.01161167, 0.03254524,\n",
       "         0.6485249 ], dtype=float32),\n",
       "  array([0.8938491 , 0.01286847, 0.05455071, 0.0094203 , 0.00698796,\n",
       "         0.02232346], dtype=float32),\n",
       "  array([0.9179923 , 0.00726895, 0.03965251, 0.00766688, 0.00678277,\n",
       "         0.02063663], dtype=float32),\n",
       "  array([0.05275502, 0.05260891, 0.01325956, 0.01013969, 0.00674054,\n",
       "         0.86449623], dtype=float32),\n",
       "  array([0.9335968 , 0.00585426, 0.0166317 , 0.00652002, 0.00306097,\n",
       "         0.03433628], dtype=float32),\n",
       "  array([0.70075434, 0.01454167, 0.10418558, 0.00670679, 0.00932238,\n",
       "         0.16448916], dtype=float32),\n",
       "  array([0.00883266, 0.03216559, 0.03153035, 0.06470542, 0.84362525,\n",
       "         0.01914068], dtype=float32),\n",
       "  array([0.00942552, 0.7584287 , 0.04371263, 0.01009587, 0.01500194,\n",
       "         0.16333535], dtype=float32),\n",
       "  array([0.02931936, 0.03891032, 0.00870104, 0.00587179, 0.00385035,\n",
       "         0.9133472 ], dtype=float32),\n",
       "  array([0.9353468 , 0.00483125, 0.01299873, 0.00555604, 0.00263435,\n",
       "         0.03863287], dtype=float32),\n",
       "  array([0.03754504, 0.01766846, 0.01140239, 0.80264467, 0.02899812,\n",
       "         0.10174135], dtype=float32),\n",
       "  array([0.14909011, 0.02603217, 0.01600469, 0.03786662, 0.00594109,\n",
       "         0.7650654 ], dtype=float32),\n",
       "  array([0.8970922 , 0.00981123, 0.0288358 , 0.01678789, 0.00569355,\n",
       "         0.04177928], dtype=float32),\n",
       "  array([0.92736703, 0.00799268, 0.02742982, 0.0061927 , 0.00301489,\n",
       "         0.02800275], dtype=float32),\n",
       "  array([0.03280859, 0.1185407 , 0.6012069 , 0.02071836, 0.10140071,\n",
       "         0.12532468], dtype=float32),\n",
       "  array([0.0286369 , 0.02901076, 0.00855282, 0.00617242, 0.00413289,\n",
       "         0.9234942 ], dtype=float32),\n",
       "  array([0.20005564, 0.01229536, 0.01607891, 0.65469337, 0.02353459,\n",
       "         0.09334224], dtype=float32),\n",
       "  array([0.04281717, 0.02328397, 0.00852365, 0.00568167, 0.00393482,\n",
       "         0.9157587 ], dtype=float32),\n",
       "  array([0.0160902 , 0.48342043, 0.02718116, 0.01029765, 0.012942  ,\n",
       "         0.4500686 ], dtype=float32),\n",
       "  array([0.8814107 , 0.00798577, 0.02014817, 0.00973708, 0.00622674,\n",
       "         0.07449158], dtype=float32),\n",
       "  array([0.0526942 , 0.02079048, 0.00897574, 0.00704491, 0.00407948,\n",
       "         0.9064152 ], dtype=float32),\n",
       "  array([0.89365363, 0.01131969, 0.0361247 , 0.01654851, 0.00574664,\n",
       "         0.03660681], dtype=float32),\n",
       "  array([0.92175376, 0.00784596, 0.03309563, 0.0044978 , 0.00470859,\n",
       "         0.02809822], dtype=float32),\n",
       "  array([0.03096424, 0.04123069, 0.00902557, 0.00612227, 0.00419373,\n",
       "         0.9084635 ], dtype=float32),\n",
       "  array([0.01748976, 0.01110319, 0.00999604, 0.8948054 , 0.04335408,\n",
       "         0.02325164], dtype=float32),\n",
       "  array([0.00740829, 0.8154668 , 0.04674741, 0.00968997, 0.01420634,\n",
       "         0.10648105], dtype=float32),\n",
       "  array([0.01056664, 0.7766633 , 0.10781263, 0.00852124, 0.01715939,\n",
       "         0.07927679], dtype=float32),\n",
       "  array([0.01317794, 0.6680521 , 0.06962939, 0.00933949, 0.01498084,\n",
       "         0.22482032], dtype=float32),\n",
       "  array([0.92004704, 0.00758825, 0.0250388 , 0.01123648, 0.00465727,\n",
       "         0.03143211], dtype=float32),\n",
       "  array([0.00721322, 0.7862037 , 0.03801264, 0.01371453, 0.02678338,\n",
       "         0.12807252], dtype=float32),\n",
       "  array([0.05051268, 0.09753284, 0.15458216, 0.15000379, 0.5135363 ,\n",
       "         0.03383226], dtype=float32),\n",
       "  array([0.03014849, 0.034356  , 0.0080529 , 0.00585226, 0.00492   ,\n",
       "         0.9166703 ], dtype=float32),\n",
       "  array([0.18663642, 0.0159953 , 0.02759557, 0.6624974 , 0.07015682,\n",
       "         0.03711846], dtype=float32),\n",
       "  array([0.0255764 , 0.14994198, 0.01703684, 0.00600094, 0.00586694,\n",
       "         0.7955769 ], dtype=float32),\n",
       "  array([0.01008231, 0.02372617, 0.02464802, 0.08164978, 0.83999914,\n",
       "         0.01989452], dtype=float32),\n",
       "  array([0.05572668, 0.02896788, 0.00916362, 0.01086332, 0.00702085,\n",
       "         0.8882576 ], dtype=float32),\n",
       "  array([0.01965997, 0.14706402, 0.02570757, 0.006572  , 0.00768875,\n",
       "         0.7933077 ], dtype=float32),\n",
       "  array([0.05064291, 0.03128447, 0.01090526, 0.01209981, 0.00408608,\n",
       "         0.89098144], dtype=float32),\n",
       "  array([0.02655176, 0.30674365, 0.03293609, 0.00955216, 0.01400458,\n",
       "         0.6102118 ], dtype=float32),\n",
       "  array([0.9249363 , 0.00828342, 0.02810629, 0.00710484, 0.00518986,\n",
       "         0.02637915], dtype=float32),\n",
       "  array([0.01149198, 0.02491118, 0.02409247, 0.08005451, 0.82884544,\n",
       "         0.03060436], dtype=float32),\n",
       "  array([0.07553319, 0.09094125, 0.02186858, 0.00843637, 0.00575465,\n",
       "         0.79746604], dtype=float32),\n",
       "  array([0.01436873, 0.48246694, 0.0419309 , 0.00863008, 0.01069063,\n",
       "         0.4419128 ], dtype=float32),\n",
       "  array([0.03877153, 0.03030028, 0.0088713 , 0.01784336, 0.00489214,\n",
       "         0.8993214 ], dtype=float32),\n",
       "  array([0.05957045, 0.24332094, 0.16333133, 0.01304752, 0.02855226,\n",
       "         0.4921775 ], dtype=float32),\n",
       "  array([0.01756722, 0.01698933, 0.01014059, 0.8774962 , 0.04362008,\n",
       "         0.03418658], dtype=float32),\n",
       "  array([0.03952657, 0.02328578, 0.00883015, 0.05339059, 0.00701218,\n",
       "         0.86795473], dtype=float32),\n",
       "  array([0.06720061, 0.02079252, 0.01382826, 0.71015346, 0.02216302,\n",
       "         0.16586211], dtype=float32),\n",
       "  array([0.11855297, 0.14013903, 0.10985481, 0.01168162, 0.04063045,\n",
       "         0.57914114], dtype=float32),\n",
       "  array([0.04165391, 0.03968715, 0.01091721, 0.01671371, 0.00734547,\n",
       "         0.8836826 ], dtype=float32),\n",
       "  array([0.01066289, 0.64131093, 0.03114788, 0.01581948, 0.02364741,\n",
       "         0.27741137], dtype=float32),\n",
       "  array([0.01766578, 0.21960956, 0.01852365, 0.00937177, 0.00902741,\n",
       "         0.72580177], dtype=float32),\n",
       "  array([0.93925506, 0.00692983, 0.02154629, 0.00550459, 0.00335268,\n",
       "         0.02341162], dtype=float32),\n",
       "  array([0.04346269, 0.06599127, 0.75628835, 0.01219564, 0.04147512,\n",
       "         0.08058693], dtype=float32),\n",
       "  array([0.10133456, 0.04558854, 0.09083001, 0.00978882, 0.0165549 ,\n",
       "         0.73590314], dtype=float32),\n",
       "  array([0.87270963, 0.00748116, 0.02860506, 0.00862777, 0.00370385,\n",
       "         0.07887252], dtype=float32),\n",
       "  array([0.9006027 , 0.00843596, 0.02633206, 0.0115745 , 0.00461753,\n",
       "         0.0484373 ], dtype=float32),\n",
       "  array([0.00788457, 0.03468538, 0.03649152, 0.0619428 , 0.816694  ,\n",
       "         0.04230175], dtype=float32),\n",
       "  array([0.870095  , 0.0089082 , 0.0730692 , 0.00590252, 0.00845309,\n",
       "         0.03357203], dtype=float32),\n",
       "  array([0.04628513, 0.02460543, 0.00899293, 0.00677749, 0.00379811,\n",
       "         0.90954095], dtype=float32),\n",
       "  array([0.05677211, 0.18541132, 0.15846285, 0.06212911, 0.4580497 ,\n",
       "         0.07917489], dtype=float32),\n",
       "  array([0.5475274 , 0.03801409, 0.35205573, 0.01111657, 0.01468406,\n",
       "         0.03660217], dtype=float32),\n",
       "  array([0.00760994, 0.0304105 , 0.02865117, 0.0703954 , 0.8428392 ,\n",
       "         0.0200939 ], dtype=float32),\n",
       "  array([0.90276366, 0.0064552 , 0.03748067, 0.00686344, 0.00426763,\n",
       "         0.04216938], dtype=float32),\n",
       "  array([0.93122715, 0.00440073, 0.01200817, 0.00382578, 0.00246025,\n",
       "         0.04607801], dtype=float32),\n",
       "  array([0.04098721, 0.07813502, 0.74944943, 0.02351717, 0.0883823 ,\n",
       "         0.01952898], dtype=float32),\n",
       "  array([0.04659066, 0.14511672, 0.03799896, 0.01014664, 0.01059681,\n",
       "         0.7495502 ], dtype=float32),\n",
       "  array([0.9392229 , 0.00517539, 0.01496654, 0.00522237, 0.00274577,\n",
       "         0.03266694], dtype=float32),\n",
       "  array([0.00987436, 0.01878853, 0.02570416, 0.09645627, 0.8351619 ,\n",
       "         0.01401476], dtype=float32),\n",
       "  array([0.6531553 , 0.01532746, 0.04145599, 0.0273688 , 0.01048927,\n",
       "         0.25220308], dtype=float32),\n",
       "  array([0.22026825, 0.08028687, 0.48904544, 0.00740574, 0.01243323,\n",
       "         0.19056043], dtype=float32),\n",
       "  array([0.04774151, 0.04051415, 0.01020916, 0.01668015, 0.00548776,\n",
       "         0.8793673 ], dtype=float32),\n",
       "  array([0.02662489, 0.085354  , 0.79814154, 0.015925  , 0.04244521,\n",
       "         0.03150922], dtype=float32),\n",
       "  array([0.89266616, 0.00973965, 0.04202085, 0.00550784, 0.00352583,\n",
       "         0.04653971], dtype=float32),\n",
       "  array([0.02289031, 0.08902119, 0.01337667, 0.00664567, 0.00560016,\n",
       "         0.862466  ], dtype=float32),\n",
       "  array([0.93501   , 0.00638954, 0.02336412, 0.0074429 , 0.00437497,\n",
       "         0.02341853], dtype=float32),\n",
       "  array([0.9292471 , 0.00572498, 0.01748746, 0.00427021, 0.00225153,\n",
       "         0.04101874], dtype=float32),\n",
       "  array([0.2823045 , 0.02718637, 0.0564311 , 0.00601144, 0.00773751,\n",
       "         0.6203291 ], dtype=float32),\n",
       "  array([0.04144325, 0.0316662 , 0.00845771, 0.00787832, 0.00430198,\n",
       "         0.90625256], dtype=float32),\n",
       "  ...],\n",
       " [5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  ...],\n",
       " [5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  ...])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inteventions_labels_model.train_model(interventions_df, interventions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92  3  9  1  0 30]\n",
      " [ 2 35  1  0  0  9]\n",
      " [ 9  0 18  0  0  1]\n",
      " [ 0  0  0 23  0  4]\n",
      " [ 6  2  0  2 14  0]\n",
      " [32  4  1  4  0 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67       135\n",
      "           1       0.80      0.74      0.77        47\n",
      "           2       0.62      0.64      0.63        28\n",
      "           3       0.77      0.85      0.81        27\n",
      "           4       1.00      0.58      0.74        24\n",
      "           5       0.69      0.71      0.70       139\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       400\n",
      "   macro avg       0.75      0.70      0.72       400\n",
      "weighted avg       0.71      0.70      0.70       400\n",
      "\n",
      "F1 score:  0.7181408215309695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([0.77385885, 0.00731763, 0.01072983, 0.01440036, 0.00460787,\n",
       "         0.18908545], dtype=float32),\n",
       "  array([0.9176632 , 0.00606267, 0.01564185, 0.00913732, 0.00350644,\n",
       "         0.04798862], dtype=float32),\n",
       "  array([0.92355675, 0.0049089 , 0.02236335, 0.00549911, 0.00433918,\n",
       "         0.03933277], dtype=float32),\n",
       "  array([0.9391089 , 0.00599499, 0.01755757, 0.00606791, 0.00335736,\n",
       "         0.02791329], dtype=float32),\n",
       "  array([0.9392664 , 0.00664633, 0.01941336, 0.00644553, 0.00320184,\n",
       "         0.02502644], dtype=float32),\n",
       "  array([0.8048865 , 0.02648338, 0.04387946, 0.00511895, 0.0037892 ,\n",
       "         0.11584254], dtype=float32),\n",
       "  array([0.9178611 , 0.00829609, 0.04083361, 0.00596925, 0.00456639,\n",
       "         0.02247353], dtype=float32),\n",
       "  array([0.1558724 , 0.01601584, 0.01006406, 0.00926264, 0.00620055,\n",
       "         0.80258447], dtype=float32),\n",
       "  array([0.9307043 , 0.00693183, 0.02491433, 0.00767526, 0.00491225,\n",
       "         0.02486198], dtype=float32),\n",
       "  array([0.06672908, 0.02294515, 0.00887096, 0.0082042 , 0.00506785,\n",
       "         0.88818276], dtype=float32),\n",
       "  array([0.9144454 , 0.00742976, 0.02192373, 0.012591  , 0.00700704,\n",
       "         0.03660308], dtype=float32),\n",
       "  array([0.9282393 , 0.00758171, 0.02311932, 0.00578898, 0.00470186,\n",
       "         0.03056882], dtype=float32),\n",
       "  array([0.9332585 , 0.00629263, 0.02401933, 0.00442584, 0.00377108,\n",
       "         0.0282327 ], dtype=float32),\n",
       "  array([0.16756871, 0.01734067, 0.01375738, 0.00904884, 0.00409601,\n",
       "         0.78818834], dtype=float32),\n",
       "  array([0.0620172 , 0.03027327, 0.01182228, 0.00738042, 0.00608693,\n",
       "         0.8824199 ], dtype=float32),\n",
       "  array([0.87572366, 0.00966309, 0.05032806, 0.01535395, 0.01532907,\n",
       "         0.03360224], dtype=float32),\n",
       "  array([0.19421002, 0.01298846, 0.01032565, 0.0258135 , 0.00669924,\n",
       "         0.74996316], dtype=float32),\n",
       "  array([0.932013  , 0.00534745, 0.02358765, 0.00686701, 0.00499399,\n",
       "         0.02719082], dtype=float32),\n",
       "  array([0.913378  , 0.00653771, 0.03141331, 0.00533358, 0.00327033,\n",
       "         0.04006715], dtype=float32),\n",
       "  array([0.90405065, 0.00920816, 0.03113466, 0.01184206, 0.00453267,\n",
       "         0.03923184], dtype=float32),\n",
       "  array([0.7385682 , 0.01104159, 0.0136422 , 0.02506815, 0.0068655 ,\n",
       "         0.2048144 ], dtype=float32),\n",
       "  array([0.90814805, 0.00723939, 0.03026124, 0.00398999, 0.00258184,\n",
       "         0.04777929], dtype=float32),\n",
       "  array([0.9226406 , 0.00507244, 0.01473728, 0.00413538, 0.00311124,\n",
       "         0.05030303], dtype=float32),\n",
       "  array([0.9160741 , 0.00590422, 0.01820019, 0.00749148, 0.00364371,\n",
       "         0.04868627], dtype=float32),\n",
       "  array([0.9396603 , 0.00574202, 0.01812898, 0.00708005, 0.00367144,\n",
       "         0.02571713], dtype=float32),\n",
       "  array([0.90552264, 0.00852014, 0.0191761 , 0.00873234, 0.00511622,\n",
       "         0.05293248], dtype=float32),\n",
       "  array([0.38450468, 0.02852116, 0.1366405 , 0.0832329 , 0.22897062,\n",
       "         0.13813014], dtype=float32),\n",
       "  array([0.8857945 , 0.01215079, 0.02695118, 0.00657753, 0.00427257,\n",
       "         0.06425339], dtype=float32),\n",
       "  array([0.02880368, 0.2519836 , 0.05113319, 0.01103129, 0.01287384,\n",
       "         0.64417434], dtype=float32),\n",
       "  array([0.8436839 , 0.01718374, 0.08455238, 0.00868795, 0.00777207,\n",
       "         0.03812001], dtype=float32),\n",
       "  array([0.33279166, 0.03779061, 0.39356625, 0.04928968, 0.14044972,\n",
       "         0.04611216], dtype=float32),\n",
       "  array([0.93068767, 0.00882337, 0.02768292, 0.00786225, 0.00455172,\n",
       "         0.02039215], dtype=float32),\n",
       "  array([0.91531163, 0.00447132, 0.012326  , 0.00387166, 0.00237274,\n",
       "         0.06164643], dtype=float32),\n",
       "  array([0.77115643, 0.02154472, 0.04103119, 0.00901807, 0.00672538,\n",
       "         0.15052417], dtype=float32),\n",
       "  array([0.92496717, 0.00630309, 0.02191637, 0.00578931, 0.00400081,\n",
       "         0.03702329], dtype=float32),\n",
       "  array([0.6631388 , 0.02712246, 0.23727249, 0.01303267, 0.02375048,\n",
       "         0.03568307], dtype=float32),\n",
       "  array([0.9357609 , 0.00603448, 0.02104599, 0.00530467, 0.00297466,\n",
       "         0.02887933], dtype=float32),\n",
       "  array([0.93814296, 0.00669622, 0.02247718, 0.00735948, 0.00393677,\n",
       "         0.02138736], dtype=float32),\n",
       "  array([0.29712042, 0.020247  , 0.0199555 , 0.01376987, 0.00870858,\n",
       "         0.6401987 ], dtype=float32),\n",
       "  array([0.7192826 , 0.01347459, 0.0354794 , 0.10272188, 0.01675077,\n",
       "         0.11229073], dtype=float32),\n",
       "  array([0.01084301, 0.72839177, 0.04400012, 0.02012767, 0.02167566,\n",
       "         0.17496175], dtype=float32),\n",
       "  array([0.01401143, 0.40199032, 0.02553603, 0.01845654, 0.02002832,\n",
       "         0.5199774 ], dtype=float32),\n",
       "  array([0.00719109, 0.8289752 , 0.05392217, 0.01370111, 0.02750304,\n",
       "         0.0687075 ], dtype=float32),\n",
       "  array([0.02380336, 0.7137836 , 0.15190564, 0.00880557, 0.01579845,\n",
       "         0.08590329], dtype=float32),\n",
       "  array([0.03788015, 0.12678221, 0.01742275, 0.01186831, 0.00797219,\n",
       "         0.7980744 ], dtype=float32),\n",
       "  array([0.01246062, 0.59536237, 0.03559393, 0.01301201, 0.015169  ,\n",
       "         0.32840207], dtype=float32),\n",
       "  array([0.02514392, 0.70257646, 0.08946316, 0.0075131 , 0.01777455,\n",
       "         0.15752879], dtype=float32),\n",
       "  array([0.00734052, 0.8127381 , 0.03666928, 0.01258882, 0.02009629,\n",
       "         0.11056699], dtype=float32),\n",
       "  array([0.01788752, 0.7256725 , 0.06422345, 0.01085227, 0.02394797,\n",
       "         0.15741624], dtype=float32),\n",
       "  array([0.05687994, 0.544592  , 0.11282882, 0.02514569, 0.03721274,\n",
       "         0.22334076], dtype=float32),\n",
       "  array([0.02508744, 0.658341  , 0.05906291, 0.00805946, 0.01427984,\n",
       "         0.23516937], dtype=float32),\n",
       "  array([0.02760675, 0.39969894, 0.4776955 , 0.01702058, 0.04305159,\n",
       "         0.03492659], dtype=float32),\n",
       "  array([0.00671143, 0.8250051 , 0.05146939, 0.01090358, 0.01681847,\n",
       "         0.08909209], dtype=float32),\n",
       "  array([0.00650233, 0.8453131 , 0.064652  , 0.01396766, 0.02384365,\n",
       "         0.04572132], dtype=float32),\n",
       "  array([0.02027445, 0.08426253, 0.01074992, 0.00635066, 0.00512527,\n",
       "         0.8732372 ], dtype=float32),\n",
       "  array([0.01078911, 0.74059427, 0.06729814, 0.00979082, 0.01975465,\n",
       "         0.15177299], dtype=float32),\n",
       "  array([0.00642976, 0.84675527, 0.04886221, 0.01288174, 0.02393122,\n",
       "         0.06113977], dtype=float32),\n",
       "  array([0.00791773, 0.78464735, 0.10594144, 0.01403434, 0.0225959 ,\n",
       "         0.06486335], dtype=float32),\n",
       "  array([0.02006716, 0.49373773, 0.03492487, 0.01035574, 0.00998684,\n",
       "         0.43092772], dtype=float32),\n",
       "  array([0.02017838, 0.16473448, 0.01430064, 0.00811825, 0.00733523,\n",
       "         0.78533304], dtype=float32),\n",
       "  array([0.00593754, 0.81595147, 0.03814942, 0.01075306, 0.02020689,\n",
       "         0.10900167], dtype=float32),\n",
       "  array([0.0136398 , 0.666935  , 0.05618886, 0.00885963, 0.01534032,\n",
       "         0.2390364 ], dtype=float32),\n",
       "  array([0.00985376, 0.7554823 , 0.03640467, 0.01297284, 0.02004668,\n",
       "         0.16523965], dtype=float32),\n",
       "  array([0.01673711, 0.6521296 , 0.21264568, 0.01706633, 0.03858193,\n",
       "         0.06283943], dtype=float32),\n",
       "  array([0.0084325 , 0.78886473, 0.11228482, 0.01489377, 0.02618091,\n",
       "         0.04934326], dtype=float32),\n",
       "  array([0.02367323, 0.3255755 , 0.02458562, 0.0096668 , 0.00972669,\n",
       "         0.6067722 ], dtype=float32),\n",
       "  array([0.03631813, 0.11471453, 0.02551328, 0.00436731, 0.00575274,\n",
       "         0.81333405], dtype=float32),\n",
       "  array([0.00720592, 0.7920423 , 0.05171509, 0.00935795, 0.01651636,\n",
       "         0.12316237], dtype=float32),\n",
       "  array([0.01319867, 0.5616565 , 0.03516964, 0.01431517, 0.02035698,\n",
       "         0.35530314], dtype=float32),\n",
       "  array([0.03689167, 0.46969467, 0.1249593 , 0.01222789, 0.01999672,\n",
       "         0.33622974], dtype=float32),\n",
       "  array([0.7464571 , 0.045909  , 0.03641528, 0.01704219, 0.0101386 ,\n",
       "         0.14403784], dtype=float32),\n",
       "  array([0.02281177, 0.6920919 , 0.05947187, 0.00921072, 0.01785784,\n",
       "         0.19855592], dtype=float32),\n",
       "  array([0.00581844, 0.83028215, 0.05303366, 0.01381757, 0.02352901,\n",
       "         0.07351916], dtype=float32),\n",
       "  array([0.0880594 , 0.0398996 , 0.01099847, 0.00589949, 0.00477197,\n",
       "         0.85037106], dtype=float32),\n",
       "  array([0.01216193, 0.7319424 , 0.0631197 , 0.00838583, 0.01446722,\n",
       "         0.16992295], dtype=float32),\n",
       "  array([0.0079086 , 0.8094738 , 0.06748876, 0.00902225, 0.01831673,\n",
       "         0.08778982], dtype=float32),\n",
       "  array([0.07998024, 0.288623  , 0.08259939, 0.04049707, 0.01804941,\n",
       "         0.49025086], dtype=float32),\n",
       "  array([0.8900812 , 0.01224505, 0.05584902, 0.01029543, 0.00730955,\n",
       "         0.02421978], dtype=float32),\n",
       "  array([0.13299704, 0.07073542, 0.63925225, 0.01095103, 0.02935161,\n",
       "         0.11671271], dtype=float32),\n",
       "  array([0.02504628, 0.1378993 , 0.7340379 , 0.01495194, 0.03076888,\n",
       "         0.05729576], dtype=float32),\n",
       "  array([0.03364767, 0.12490982, 0.74516547, 0.02019842, 0.04783588,\n",
       "         0.02824281], dtype=float32),\n",
       "  array([0.1634446 , 0.12795684, 0.57487917, 0.00864669, 0.01973724,\n",
       "         0.10533547], dtype=float32),\n",
       "  array([0.10056781, 0.0652243 , 0.7046219 , 0.01144408, 0.02831795,\n",
       "         0.089824  ], dtype=float32),\n",
       "  array([0.03475076, 0.15479544, 0.71140516, 0.02010468, 0.05566731,\n",
       "         0.02327669], dtype=float32),\n",
       "  array([0.01953335, 0.26181298, 0.61700284, 0.01421543, 0.03417192,\n",
       "         0.05326354], dtype=float32),\n",
       "  array([0.04684961, 0.068491  , 0.77037084, 0.01117957, 0.04036193,\n",
       "         0.06274707], dtype=float32),\n",
       "  array([0.11518265, 0.0616365 , 0.5056067 , 0.03956177, 0.2176498 ,\n",
       "         0.06036266], dtype=float32),\n",
       "  array([0.39091837, 0.05847872, 0.44016364, 0.01042984, 0.02622995,\n",
       "         0.07377945], dtype=float32),\n",
       "  array([0.07399698, 0.07257647, 0.7573414 , 0.01250742, 0.03824031,\n",
       "         0.04533739], dtype=float32),\n",
       "  array([0.19345059, 0.08529848, 0.6414528 , 0.00975662, 0.02501663,\n",
       "         0.04502492], dtype=float32),\n",
       "  array([0.31643796, 0.05451916, 0.52327734, 0.00885659, 0.01671866,\n",
       "         0.08019029], dtype=float32),\n",
       "  array([0.33211496, 0.02030998, 0.06663615, 0.22660875, 0.3219882 ,\n",
       "         0.03234194], dtype=float32),\n",
       "  array([0.02920435, 0.02505585, 0.06081665, 0.06155552, 0.79783887,\n",
       "         0.02552872], dtype=float32),\n",
       "  array([0.81687003, 0.01478269, 0.08923576, 0.01724247, 0.03694373,\n",
       "         0.0249252 ], dtype=float32),\n",
       "  array([0.0290375 , 0.02810225, 0.04027875, 0.1117963 , 0.7616843 ,\n",
       "         0.02910086], dtype=float32),\n",
       "  array([0.02853922, 0.0156162 , 0.01460726, 0.8059658 , 0.09990495,\n",
       "         0.03536658], dtype=float32),\n",
       "  array([0.29989403, 0.01520776, 0.05263981, 0.38462627, 0.20213011,\n",
       "         0.04550198], dtype=float32),\n",
       "  array([0.02664419, 0.02468137, 0.04554788, 0.11302575, 0.76225716,\n",
       "         0.02784366], dtype=float32),\n",
       "  array([0.03549332, 0.0221472 , 0.05346144, 0.06512269, 0.8002067 ,\n",
       "         0.02356863], dtype=float32),\n",
       "  array([0.01866983, 0.01957081, 0.02394855, 0.09284006, 0.8117318 ,\n",
       "         0.03323895], dtype=float32),\n",
       "  array([0.06361298, 0.02997413, 0.0411749 , 0.18605657, 0.61201036,\n",
       "         0.06717109], dtype=float32),\n",
       "  array([0.0647988 , 0.02620526, 0.08735283, 0.07267182, 0.7155161 ,\n",
       "         0.03345518], dtype=float32),\n",
       "  array([0.07449813, 0.02359877, 0.06532031, 0.09455757, 0.7225895 ,\n",
       "         0.01943569], dtype=float32),\n",
       "  array([0.05676743, 0.0300647 , 0.04686157, 0.12891473, 0.7050273 ,\n",
       "         0.03236424], dtype=float32),\n",
       "  array([0.02967036, 0.01970013, 0.04252458, 0.07537368, 0.81170005,\n",
       "         0.02103124], dtype=float32),\n",
       "  array([0.3830431 , 0.0833829 , 0.25080502, 0.05721579, 0.16476521,\n",
       "         0.06078804], dtype=float32),\n",
       "  array([0.35655484, 0.13564052, 0.08801424, 0.07306105, 0.16491751,\n",
       "         0.18181187], dtype=float32),\n",
       "  array([0.16218296, 0.03313476, 0.03959274, 0.29602143, 0.3404512 ,\n",
       "         0.12861696], dtype=float32),\n",
       "  array([0.1155387 , 0.25107703, 0.16211621, 0.05623501, 0.24685329,\n",
       "         0.16817972], dtype=float32),\n",
       "  array([0.03609922, 0.03796807, 0.0096498 , 0.01890149, 0.00546191,\n",
       "         0.8919195 ], dtype=float32),\n",
       "  array([0.34810004, 0.02032167, 0.03106158, 0.5197933 , 0.02638919,\n",
       "         0.05433427], dtype=float32),\n",
       "  array([0.07358843, 0.03191531, 0.01501801, 0.2542225 , 0.01681372,\n",
       "         0.60844207], dtype=float32),\n",
       "  array([0.05223273, 0.02187833, 0.01204026, 0.7840976 , 0.02083123,\n",
       "         0.10891986], dtype=float32),\n",
       "  array([0.03947556, 0.01522475, 0.01590316, 0.8584989 , 0.04012745,\n",
       "         0.03077026], dtype=float32),\n",
       "  array([0.2646481 , 0.02111533, 0.03064745, 0.51712835, 0.04736746,\n",
       "         0.11909337], dtype=float32),\n",
       "  array([0.03111695, 0.02228964, 0.01174916, 0.7755721 , 0.02952147,\n",
       "         0.12975076], dtype=float32),\n",
       "  array([0.03614637, 0.0146573 , 0.01284308, 0.8559074 , 0.04880184,\n",
       "         0.03164407], dtype=float32),\n",
       "  array([0.02548098, 0.01316316, 0.01107798, 0.8926122 , 0.03139712,\n",
       "         0.02626859], dtype=float32),\n",
       "  array([0.02409513, 0.01201051, 0.00951311, 0.89570355, 0.02631001,\n",
       "         0.03236768], dtype=float32),\n",
       "  array([0.03841034, 0.01503208, 0.01058517, 0.86266935, 0.02630426,\n",
       "         0.04699881], dtype=float32),\n",
       "  array([0.17685118, 0.0359625 , 0.02255666, 0.24227837, 0.02462442,\n",
       "         0.49772686], dtype=float32),\n",
       "  array([0.07671805, 0.0142223 , 0.01381424, 0.83751297, 0.02975941,\n",
       "         0.02797298], dtype=float32),\n",
       "  array([0.06939028, 0.01538175, 0.01405221, 0.82364327, 0.02546275,\n",
       "         0.05206978], dtype=float32),\n",
       "  array([0.01502992, 0.01830313, 0.01025834, 0.893445  , 0.03009323,\n",
       "         0.03287043], dtype=float32),\n",
       "  array([0.09783994, 0.02316216, 0.01138033, 0.58283883, 0.02398889,\n",
       "         0.26078987], dtype=float32),\n",
       "  array([0.05959608, 0.01895762, 0.01213328, 0.77493775, 0.02514035,\n",
       "         0.10923495], dtype=float32),\n",
       "  array([0.06789136, 0.02082422, 0.01143995, 0.69911724, 0.02865964,\n",
       "         0.17206754], dtype=float32),\n",
       "  array([0.02446924, 0.01336119, 0.01069213, 0.88087624, 0.02395679,\n",
       "         0.04664441], dtype=float32),\n",
       "  array([0.04580278, 0.04031628, 0.01056101, 0.00477796, 0.00398318,\n",
       "         0.8945588 ], dtype=float32),\n",
       "  array([0.03305353, 0.02708779, 0.00785166, 0.0087743 , 0.00558293,\n",
       "         0.91764975], dtype=float32),\n",
       "  array([0.5571184 , 0.01451675, 0.02126612, 0.00702027, 0.00401324,\n",
       "         0.3960652 ], dtype=float32),\n",
       "  array([0.03026582, 0.02368822, 0.0085136 , 0.02121944, 0.00684667,\n",
       "         0.9094662 ], dtype=float32),\n",
       "  array([0.92826515, 0.00493803, 0.01804439, 0.0041372 , 0.00274446,\n",
       "         0.04187077], dtype=float32),\n",
       "  array([0.03078383, 0.05718936, 0.01422083, 0.00730891, 0.00456275,\n",
       "         0.8859343 ], dtype=float32),\n",
       "  array([0.03786063, 0.03361506, 0.00768896, 0.00717859, 0.00402101,\n",
       "         0.9096357 ], dtype=float32),\n",
       "  array([0.04021221, 0.02040157, 0.00741828, 0.010676  , 0.00415882,\n",
       "         0.91713315], dtype=float32),\n",
       "  array([0.03520025, 0.03132629, 0.00865876, 0.00829591, 0.00566444,\n",
       "         0.91085434], dtype=float32),\n",
       "  array([0.03693523, 0.0317344 , 0.00919012, 0.00915442, 0.00589441,\n",
       "         0.9070914 ], dtype=float32),\n",
       "  array([0.05553723, 0.12048231, 0.46308225, 0.02527568, 0.12113538,\n",
       "         0.21448714], dtype=float32),\n",
       "  array([0.1392382 , 0.02351353, 0.01383301, 0.01188801, 0.00905221,\n",
       "         0.802475  ], dtype=float32),\n",
       "  array([0.03531376, 0.02759984, 0.00910251, 0.00921569, 0.00530539,\n",
       "         0.9134629 ], dtype=float32),\n",
       "  array([0.1291825 , 0.01672698, 0.01213432, 0.11584999, 0.02755206,\n",
       "         0.6985541 ], dtype=float32),\n",
       "  array([0.13848624, 0.02156556, 0.03045317, 0.00701354, 0.00717332,\n",
       "         0.7953081 ], dtype=float32),\n",
       "  array([0.02895203, 0.03033767, 0.00986005, 0.00597948, 0.00526826,\n",
       "         0.9196026 ], dtype=float32),\n",
       "  array([0.06815669, 0.11498279, 0.04221107, 0.01038033, 0.00671278,\n",
       "         0.7575564 ], dtype=float32),\n",
       "  array([0.04220616, 0.03171955, 0.00964045, 0.00473465, 0.00415298,\n",
       "         0.90754616], dtype=float32),\n",
       "  array([0.05012478, 0.02970512, 0.01039606, 0.00521217, 0.00389795,\n",
       "         0.9006639 ], dtype=float32),\n",
       "  array([0.02360346, 0.04645961, 0.0095814 , 0.00798348, 0.00553874,\n",
       "         0.9068333 ], dtype=float32),\n",
       "  array([0.03272596, 0.04548562, 0.01182704, 0.00634396, 0.00388367,\n",
       "         0.8997337 ], dtype=float32),\n",
       "  array([0.06115243, 0.02323466, 0.0082952 , 0.02922961, 0.00694692,\n",
       "         0.8711412 ], dtype=float32),\n",
       "  array([0.19446118, 0.01710705, 0.01165284, 0.00700256, 0.00411019,\n",
       "         0.7656662 ], dtype=float32),\n",
       "  array([0.49848008, 0.00941812, 0.01583834, 0.00942576, 0.00622824,\n",
       "         0.46060944], dtype=float32),\n",
       "  array([0.37084293, 0.01586095, 0.017819  , 0.00649343, 0.00391219,\n",
       "         0.5850715 ], dtype=float32),\n",
       "  array([0.02790382, 0.06936025, 0.01302223, 0.00906436, 0.00754421,\n",
       "         0.8731051 ], dtype=float32),\n",
       "  array([0.03551291, 0.24185985, 0.03339471, 0.02148451, 0.02214775,\n",
       "         0.64560026], dtype=float32),\n",
       "  array([0.49127465, 0.01470708, 0.0143917 , 0.00989058, 0.00441849,\n",
       "         0.4653175 ], dtype=float32),\n",
       "  array([0.03846804, 0.02814671, 0.00801666, 0.00709756, 0.00410383,\n",
       "         0.9141672 ], dtype=float32),\n",
       "  array([0.02499594, 0.51536554, 0.03851559, 0.00852641, 0.0107198 ,\n",
       "         0.4018768 ], dtype=float32),\n",
       "  array([0.0226013 , 0.5186655 , 0.09959655, 0.00848861, 0.01294241,\n",
       "         0.3377057 ], dtype=float32),\n",
       "  array([0.9346851 , 0.00491566, 0.01562248, 0.00372673, 0.00235231,\n",
       "         0.03869756], dtype=float32),\n",
       "  array([0.04808464, 0.01892947, 0.00645181, 0.0063637 , 0.00360758,\n",
       "         0.9165628 ], dtype=float32),\n",
       "  array([0.049082  , 0.03367215, 0.01531088, 0.00774083, 0.00678952,\n",
       "         0.8874047 ], dtype=float32),\n",
       "  array([0.03051531, 0.3150501 , 0.06792545, 0.00832559, 0.01000339,\n",
       "         0.56818014], dtype=float32),\n",
       "  array([0.05519397, 0.02470867, 0.00802026, 0.0081153 , 0.00524096,\n",
       "         0.8987208 ], dtype=float32),\n",
       "  array([0.04034768, 0.03546342, 0.00929453, 0.00439776, 0.00393218,\n",
       "         0.9065645 ], dtype=float32),\n",
       "  array([0.04877498, 0.04521902, 0.01352453, 0.00431271, 0.00369083,\n",
       "         0.8844779 ], dtype=float32),\n",
       "  array([0.03638065, 0.02138721, 0.00821337, 0.00663523, 0.00358327,\n",
       "         0.9238003 ], dtype=float32),\n",
       "  array([0.16255948, 0.03660212, 0.02626199, 0.01103314, 0.00501402,\n",
       "         0.75852925], dtype=float32),\n",
       "  array([0.0267824 , 0.23742919, 0.02393988, 0.00614681, 0.00687777,\n",
       "         0.698824  ], dtype=float32),\n",
       "  array([0.2805139 , 0.07954641, 0.5197502 , 0.01502712, 0.02111125,\n",
       "         0.08405118], dtype=float32),\n",
       "  array([0.73357517, 0.01968149, 0.19036649, 0.00985153, 0.01102285,\n",
       "         0.03550234], dtype=float32),\n",
       "  array([0.5687801 , 0.02950898, 0.31824473, 0.01150349, 0.01620738,\n",
       "         0.05575534], dtype=float32),\n",
       "  array([0.07509477, 0.08889218, 0.72661364, 0.01325954, 0.04857682,\n",
       "         0.047563  ], dtype=float32),\n",
       "  array([0.84192777, 0.01556785, 0.07752682, 0.01038552, 0.02523335,\n",
       "         0.02935872], dtype=float32),\n",
       "  array([0.5358747 , 0.02587255, 0.25363788, 0.00972364, 0.01335899,\n",
       "         0.16153225], dtype=float32),\n",
       "  array([0.08494707, 0.10009126, 0.38372046, 0.01878007, 0.03826277,\n",
       "         0.37419838], dtype=float32),\n",
       "  array([0.5821819 , 0.02933845, 0.12764953, 0.01325807, 0.01435507,\n",
       "         0.23321702], dtype=float32),\n",
       "  array([0.43825454, 0.01139115, 0.01867119, 0.05012613, 0.00958402,\n",
       "         0.47197294], dtype=float32),\n",
       "  array([0.06821244, 0.01654734, 0.01918168, 0.8069044 , 0.06482983,\n",
       "         0.02432438], dtype=float32),\n",
       "  array([0.10973515, 0.02290932, 0.01436553, 0.72046804, 0.02267722,\n",
       "         0.1098448 ], dtype=float32),\n",
       "  array([0.09483215, 0.01414851, 0.00823131, 0.00947258, 0.00435425,\n",
       "         0.86896116], dtype=float32),\n",
       "  array([0.5959344 , 0.01792612, 0.05042201, 0.24053782, 0.03813854,\n",
       "         0.05704114], dtype=float32),\n",
       "  array([0.09614288, 0.02678788, 0.01219915, 0.06518941, 0.01364387,\n",
       "         0.7860368 ], dtype=float32),\n",
       "  array([0.46256256, 0.0194598 , 0.03059272, 0.01469636, 0.00833522,\n",
       "         0.4643533 ], dtype=float32),\n",
       "  array([0.92587364, 0.00469733, 0.01451596, 0.00647621, 0.00305964,\n",
       "         0.04537709], dtype=float32),\n",
       "  array([0.07577579, 0.02638626, 0.01145955, 0.00789117, 0.00427716,\n",
       "         0.8742101 ], dtype=float32),\n",
       "  array([0.26349676, 0.01980268, 0.01862157, 0.44442213, 0.0476601 ,\n",
       "         0.20599681], dtype=float32),\n",
       "  array([0.02837384, 0.4463459 , 0.3452475 , 0.01270661, 0.0340141 ,\n",
       "         0.133312  ], dtype=float32),\n",
       "  array([0.03018894, 0.02492769, 0.00761157, 0.00690938, 0.00429591,\n",
       "         0.9260665 ], dtype=float32),\n",
       "  array([0.10947665, 0.03435938, 0.04431351, 0.01151932, 0.01361495,\n",
       "         0.78671616], dtype=float32),\n",
       "  array([0.06289135, 0.48456824, 0.17901826, 0.00961374, 0.02984427,\n",
       "         0.23406418], dtype=float32),\n",
       "  array([0.02843961, 0.51618004, 0.07708658, 0.00861389, 0.01217105,\n",
       "         0.35750878], dtype=float32),\n",
       "  array([0.03115023, 0.05552572, 0.01142468, 0.00680097, 0.006006  ,\n",
       "         0.8890924 ], dtype=float32),\n",
       "  array([0.01108438, 0.6345309 , 0.03103572, 0.01230808, 0.01583095,\n",
       "         0.29521003], dtype=float32),\n",
       "  array([0.00978338, 0.77056175, 0.04810062, 0.01449885, 0.02840401,\n",
       "         0.12865141], dtype=float32),\n",
       "  array([0.01864061, 0.7193874 , 0.05730512, 0.0087657 , 0.01741734,\n",
       "         0.17848368], dtype=float32),\n",
       "  array([0.01866851, 0.60325384, 0.05050969, 0.00842938, 0.01241771,\n",
       "         0.30672082], dtype=float32),\n",
       "  array([0.0069608 , 0.8132686 , 0.07722043, 0.00979073, 0.0228321 ,\n",
       "         0.06992742], dtype=float32),\n",
       "  array([0.0290375 , 0.02810225, 0.04027875, 0.1117963 , 0.7616843 ,\n",
       "         0.02910086], dtype=float32),\n",
       "  array([0.1155387 , 0.25107703, 0.16211621, 0.05623501, 0.24685329,\n",
       "         0.16817972], dtype=float32),\n",
       "  array([0.577908  , 0.01810957, 0.1260758 , 0.07851572, 0.16964099,\n",
       "         0.02974994], dtype=float32),\n",
       "  array([0.02651382, 0.0259765 , 0.06215047, 0.06990755, 0.79310066,\n",
       "         0.022351  ], dtype=float32),\n",
       "  array([0.06247194, 0.0246812 , 0.06328845, 0.07293918, 0.7458304 ,\n",
       "         0.03078881], dtype=float32),\n",
       "  array([0.9384616 , 0.00579067, 0.02058581, 0.00577096, 0.00322282,\n",
       "         0.02616801], dtype=float32),\n",
       "  array([0.88259685, 0.00526762, 0.01259854, 0.00536989, 0.00342755,\n",
       "         0.0907396 ], dtype=float32),\n",
       "  array([0.93834233, 0.00506699, 0.01632428, 0.00543623, 0.00361885,\n",
       "         0.03121132], dtype=float32),\n",
       "  array([0.94304526, 0.00527883, 0.01546973, 0.00572081, 0.00319584,\n",
       "         0.02728953], dtype=float32),\n",
       "  array([0.9310342 , 0.00667763, 0.02368177, 0.01035637, 0.00648078,\n",
       "         0.02176933], dtype=float32),\n",
       "  array([0.9356371 , 0.0051615 , 0.01953829, 0.00465339, 0.00324216,\n",
       "         0.03176751], dtype=float32),\n",
       "  array([0.9398995 , 0.00450856, 0.01429514, 0.00582224, 0.00305644,\n",
       "         0.03241801], dtype=float32),\n",
       "  array([0.89032555, 0.00846072, 0.03044106, 0.00636952, 0.00449928,\n",
       "         0.05990391], dtype=float32),\n",
       "  array([0.07560872, 0.02173184, 0.00794996, 0.00751501, 0.00333406,\n",
       "         0.8838604 ], dtype=float32),\n",
       "  array([0.01767947, 0.6511751 , 0.15992533, 0.01583863, 0.02481783,\n",
       "         0.13056366], dtype=float32),\n",
       "  array([0.21854247, 0.05764975, 0.58619016, 0.01617002, 0.05583638,\n",
       "         0.06561125], dtype=float32),\n",
       "  array([0.03884872, 0.26525915, 0.5731335 , 0.02955849, 0.07000767,\n",
       "         0.02319249], dtype=float32),\n",
       "  array([0.86294544, 0.01949789, 0.04614236, 0.00783258, 0.00511998,\n",
       "         0.05846172], dtype=float32),\n",
       "  array([0.92485654, 0.00669299, 0.02760885, 0.00705388, 0.00494033,\n",
       "         0.02884727], dtype=float32),\n",
       "  array([0.90968734, 0.01039748, 0.03025934, 0.01630601, 0.00592406,\n",
       "         0.02742576], dtype=float32),\n",
       "  array([0.39178348, 0.01502824, 0.02095093, 0.03548024, 0.01847773,\n",
       "         0.5182794 ], dtype=float32),\n",
       "  array([0.0736183 , 0.02346364, 0.01012218, 0.01205237, 0.00443271,\n",
       "         0.8763108 ], dtype=float32),\n",
       "  array([0.69054943, 0.02512255, 0.13092266, 0.06781904, 0.04300821,\n",
       "         0.04257816], dtype=float32),\n",
       "  array([0.8441713 , 0.01179   , 0.08893212, 0.01831318, 0.01633478,\n",
       "         0.02045857], dtype=float32),\n",
       "  array([0.84934133, 0.00738453, 0.0207888 , 0.00639847, 0.00326468,\n",
       "         0.11282218], dtype=float32),\n",
       "  array([0.87534684, 0.01086619, 0.03786835, 0.02604588, 0.01127188,\n",
       "         0.03860098], dtype=float32),\n",
       "  array([0.93577397, 0.00452071, 0.01289637, 0.00512711, 0.00234715,\n",
       "         0.03933469], dtype=float32),\n",
       "  array([0.9341303 , 0.00686205, 0.0233431 , 0.00721864, 0.0038558 ,\n",
       "         0.02459006], dtype=float32),\n",
       "  array([0.93436664, 0.00570559, 0.02085407, 0.0059266 , 0.00310404,\n",
       "         0.03004308], dtype=float32),\n",
       "  array([0.88408816, 0.01316399, 0.05632755, 0.0082954 , 0.00721022,\n",
       "         0.03091463], dtype=float32),\n",
       "  array([0.9409133 , 0.00547228, 0.01825963, 0.00533067, 0.00301322,\n",
       "         0.02701078], dtype=float32),\n",
       "  array([0.9243952 , 0.00764992, 0.02873888, 0.00897894, 0.00577112,\n",
       "         0.02446599], dtype=float32),\n",
       "  array([0.9365591 , 0.00587485, 0.02116485, 0.00749152, 0.0040041 ,\n",
       "         0.02490562], dtype=float32),\n",
       "  array([0.02362957, 0.45018172, 0.30941573, 0.01264859, 0.02804724,\n",
       "         0.17607717], dtype=float32),\n",
       "  array([0.5346839 , 0.03087391, 0.1923499 , 0.00857812, 0.01750521,\n",
       "         0.21600902], dtype=float32),\n",
       "  array([0.21467301, 0.0672996 , 0.60629743, 0.01275312, 0.04707335,\n",
       "         0.0519034 ], dtype=float32),\n",
       "  array([0.1388291 , 0.03128282, 0.02520821, 0.00683487, 0.00849566,\n",
       "         0.7893493 ], dtype=float32),\n",
       "  array([0.84099907, 0.01281444, 0.08941185, 0.00538398, 0.00524177,\n",
       "         0.04614896], dtype=float32),\n",
       "  array([0.03012335, 0.26178557, 0.05416205, 0.01172388, 0.00971388,\n",
       "         0.6324913 ], dtype=float32),\n",
       "  array([0.5228541 , 0.01665173, 0.02043115, 0.00534561, 0.00432646,\n",
       "         0.430391  ], dtype=float32),\n",
       "  array([0.57712424, 0.01934229, 0.0642481 , 0.00647243, 0.00526974,\n",
       "         0.32754314], dtype=float32),\n",
       "  array([0.9377564 , 0.00531511, 0.01468383, 0.00602467, 0.00318406,\n",
       "         0.03303584], dtype=float32),\n",
       "  array([0.936481  , 0.00539951, 0.01481184, 0.0061767 , 0.00361266,\n",
       "         0.0335183 ], dtype=float32),\n",
       "  array([0.0721679 , 0.01796513, 0.00916009, 0.00824677, 0.00491604,\n",
       "         0.88754404], dtype=float32),\n",
       "  array([0.9398984 , 0.005831  , 0.01857429, 0.00434144, 0.00286905,\n",
       "         0.02848591], dtype=float32),\n",
       "  array([0.0721679 , 0.01796513, 0.00916009, 0.00824677, 0.00491604,\n",
       "         0.88754404], dtype=float32),\n",
       "  array([0.09348969, 0.09341086, 0.66349465, 0.01438317, 0.04532834,\n",
       "         0.08989341], dtype=float32),\n",
       "  array([0.45035028, 0.01271513, 0.01261446, 0.01207116, 0.00576977,\n",
       "         0.5064792 ], dtype=float32),\n",
       "  array([0.9314324 , 0.00681995, 0.02057236, 0.00545024, 0.00402199,\n",
       "         0.03170307], dtype=float32),\n",
       "  array([0.8841675 , 0.00713659, 0.01498578, 0.00488019, 0.00293554,\n",
       "         0.08589438], dtype=float32),\n",
       "  array([0.886213  , 0.01127666, 0.0647968 , 0.00637197, 0.00587116,\n",
       "         0.02547031], dtype=float32),\n",
       "  array([0.6063136 , 0.03038326, 0.16430278, 0.00521546, 0.00764405,\n",
       "         0.18614087], dtype=float32),\n",
       "  array([0.03669738, 0.02748032, 0.00836217, 0.0078058 , 0.00467941,\n",
       "         0.9149749 ], dtype=float32),\n",
       "  array([0.6684394 , 0.01248401, 0.01839296, 0.00536112, 0.00410845,\n",
       "         0.29121408], dtype=float32),\n",
       "  array([0.01066552, 0.68384194, 0.05351   , 0.01196755, 0.01571416,\n",
       "         0.22430079], dtype=float32),\n",
       "  array([0.08010644, 0.09927049, 0.22719796, 0.01549925, 0.03239743,\n",
       "         0.5455284 ], dtype=float32),\n",
       "  array([0.04372195, 0.02767424, 0.0079999 , 0.0148272 , 0.00512997,\n",
       "         0.9006468 ], dtype=float32),\n",
       "  array([0.7437567 , 0.01237292, 0.04433203, 0.00540228, 0.00467591,\n",
       "         0.18946014], dtype=float32),\n",
       "  array([0.03785712, 0.0212015 , 0.00732313, 0.00880716, 0.00532675,\n",
       "         0.9194843 ], dtype=float32),\n",
       "  array([0.04309295, 0.03167911, 0.00811938, 0.00576062, 0.00380731,\n",
       "         0.9075407 ], dtype=float32),\n",
       "  array([0.06529321, 0.10797048, 0.7058408 , 0.0150775 , 0.06360287,\n",
       "         0.04221515], dtype=float32),\n",
       "  array([0.3150365 , 0.01877804, 0.01488398, 0.00499733, 0.00499919,\n",
       "         0.64130497], dtype=float32),\n",
       "  array([0.9239015 , 0.01029635, 0.0313075 , 0.00688206, 0.00437323,\n",
       "         0.02323934], dtype=float32),\n",
       "  array([0.05473092, 0.01860058, 0.01044372, 0.00566624, 0.00503528,\n",
       "         0.90552324], dtype=float32),\n",
       "  array([0.05869661, 0.37448782, 0.13154972, 0.02147068, 0.02769379,\n",
       "         0.38610142], dtype=float32),\n",
       "  array([0.8780877 , 0.00655062, 0.01393233, 0.01080764, 0.00441516,\n",
       "         0.08620659], dtype=float32),\n",
       "  array([0.714535  , 0.00908554, 0.01641675, 0.00598647, 0.0036477 ,\n",
       "         0.25032848], dtype=float32),\n",
       "  array([0.93324655, 0.00724682, 0.02659745, 0.0066635 , 0.00431079,\n",
       "         0.02193478], dtype=float32),\n",
       "  array([0.2625689 , 0.0586013 , 0.14354235, 0.01718785, 0.03201261,\n",
       "         0.48608696], dtype=float32),\n",
       "  array([0.01273733, 0.707375  , 0.11760668, 0.01198519, 0.02491613,\n",
       "         0.1253797 ], dtype=float32),\n",
       "  array([0.01861362, 0.06470423, 0.01080591, 0.00751594, 0.00501769,\n",
       "         0.8933426 ], dtype=float32),\n",
       "  array([0.84779847, 0.01278159, 0.0517864 , 0.00534913, 0.00393929,\n",
       "         0.07834508], dtype=float32),\n",
       "  array([0.08777889, 0.03730196, 0.01525185, 0.01047835, 0.00648395,\n",
       "         0.8427051 ], dtype=float32),\n",
       "  array([0.01847827, 0.6712192 , 0.16725244, 0.01986304, 0.04603275,\n",
       "         0.07715426], dtype=float32),\n",
       "  array([0.33381805, 0.04367368, 0.07471309, 0.02259257, 0.02660142,\n",
       "         0.4986012 ], dtype=float32),\n",
       "  array([0.05789692, 0.03197615, 0.01058706, 0.0592864 , 0.0158819 ,\n",
       "         0.8243716 ], dtype=float32),\n",
       "  array([0.02826479, 0.03182573, 0.01394103, 0.02517368, 0.01291038,\n",
       "         0.8878844 ], dtype=float32),\n",
       "  array([0.73926353, 0.01034969, 0.0145268 , 0.00559381, 0.00362311,\n",
       "         0.22664322], dtype=float32),\n",
       "  array([0.87653166, 0.00644088, 0.01559539, 0.00650885, 0.00298925,\n",
       "         0.09193396], dtype=float32),\n",
       "  array([0.02668032, 0.02894837, 0.00751709, 0.0072833 , 0.00344783,\n",
       "         0.9261231 ], dtype=float32),\n",
       "  array([0.6631515 , 0.00799939, 0.01414716, 0.01922503, 0.00532923,\n",
       "         0.29014766], dtype=float32),\n",
       "  array([0.92429525, 0.00581383, 0.01695552, 0.00583221, 0.00296451,\n",
       "         0.04413871], dtype=float32),\n",
       "  array([0.15490852, 0.01800336, 0.00871417, 0.08721051, 0.00790315,\n",
       "         0.7232602 ], dtype=float32),\n",
       "  array([0.79603523, 0.00962243, 0.02678118, 0.05735074, 0.01201183,\n",
       "         0.09819851], dtype=float32),\n",
       "  array([0.7227568 , 0.00883593, 0.01541165, 0.01210513, 0.00375856,\n",
       "         0.23713198], dtype=float32),\n",
       "  array([0.19001347, 0.01890564, 0.01539437, 0.08100486, 0.01408016,\n",
       "         0.6806015 ], dtype=float32),\n",
       "  array([0.13185343, 0.01401604, 0.01179948, 0.00726954, 0.00336251,\n",
       "         0.831699  ], dtype=float32),\n",
       "  array([0.04865664, 0.04795959, 0.0094609 , 0.01094247, 0.00596975,\n",
       "         0.8770107 ], dtype=float32),\n",
       "  array([0.9313472 , 0.0058687 , 0.02570061, 0.005754  , 0.00337021,\n",
       "         0.02795938], dtype=float32),\n",
       "  array([0.8932776 , 0.00865753, 0.02750313, 0.02695148, 0.00800636,\n",
       "         0.03560404], dtype=float32),\n",
       "  array([0.9341096 , 0.00641553, 0.02657158, 0.00532043, 0.00339921,\n",
       "         0.02418368], dtype=float32),\n",
       "  array([0.930599  , 0.0052041 , 0.01811513, 0.00565977, 0.0025595 ,\n",
       "         0.03786258], dtype=float32),\n",
       "  array([0.29787368, 0.06551289, 0.09146591, 0.01144769, 0.00935326,\n",
       "         0.5243466 ], dtype=float32),\n",
       "  array([0.08181564, 0.12844448, 0.5421434 , 0.01124657, 0.04098582,\n",
       "         0.19536407], dtype=float32),\n",
       "  array([0.90040463, 0.00914381, 0.03318177, 0.00512679, 0.00471516,\n",
       "         0.04742771], dtype=float32),\n",
       "  array([0.6105809 , 0.01335728, 0.02212069, 0.00554896, 0.00280366,\n",
       "         0.34558848], dtype=float32),\n",
       "  array([0.48159856, 0.03004255, 0.4027303 , 0.01017351, 0.01573233,\n",
       "         0.05972268], dtype=float32),\n",
       "  array([0.06222421, 0.02569851, 0.0094451 , 0.00563882, 0.00411304,\n",
       "         0.8928803 ], dtype=float32),\n",
       "  array([0.1001185 , 0.03809223, 0.00970471, 0.00987456, 0.00387119,\n",
       "         0.8383388 ], dtype=float32),\n",
       "  array([0.10483091, 0.06142405, 0.02086041, 0.01929608, 0.01302341,\n",
       "         0.7805651 ], dtype=float32),\n",
       "  array([0.24724275, 0.02120488, 0.0182928 , 0.49890098, 0.01497078,\n",
       "         0.19938786], dtype=float32),\n",
       "  array([0.93354326, 0.00646623, 0.02148858, 0.00455407, 0.00278759,\n",
       "         0.03116018], dtype=float32),\n",
       "  array([0.47640866, 0.01273408, 0.01569644, 0.0087255 , 0.00382019,\n",
       "         0.48261502], dtype=float32),\n",
       "  array([0.07111564, 0.021152  , 0.01278871, 0.0125727 , 0.00795123,\n",
       "         0.8744198 ], dtype=float32),\n",
       "  array([0.44132116, 0.01389462, 0.01882873, 0.01186788, 0.00501188,\n",
       "         0.50907576], dtype=float32),\n",
       "  array([0.9210621 , 0.00563991, 0.01387487, 0.00526702, 0.00311852,\n",
       "         0.05103755], dtype=float32),\n",
       "  array([0.19857399, 0.08765181, 0.5578839 , 0.01732023, 0.03568254,\n",
       "         0.10288747], dtype=float32),\n",
       "  array([0.9092719 , 0.00711578, 0.02610463, 0.00430466, 0.00247384,\n",
       "         0.05072908], dtype=float32),\n",
       "  array([0.03678661, 0.18292782, 0.01995376, 0.01769922, 0.00932005,\n",
       "         0.73331255], dtype=float32),\n",
       "  array([0.92909455, 0.00589651, 0.01645778, 0.00422541, 0.00269187,\n",
       "         0.04163404], dtype=float32),\n",
       "  array([0.91222036, 0.00624835, 0.02233334, 0.00546673, 0.0028995 ,\n",
       "         0.05083171], dtype=float32),\n",
       "  array([0.90995306, 0.0071257 , 0.03619892, 0.00735683, 0.00346923,\n",
       "         0.03589622], dtype=float32),\n",
       "  array([0.39290518, 0.01372993, 0.05864935, 0.04466352, 0.08656288,\n",
       "         0.40348914], dtype=float32),\n",
       "  array([0.46149805, 0.01699155, 0.01852375, 0.0060901 , 0.00403147,\n",
       "         0.49286515], dtype=float32),\n",
       "  array([0.90629554, 0.00467588, 0.01118484, 0.00462191, 0.00292744,\n",
       "         0.07029438], dtype=float32),\n",
       "  array([0.9344003 , 0.0072582 , 0.02209418, 0.00805334, 0.00396778,\n",
       "         0.02422617], dtype=float32),\n",
       "  array([0.9369674 , 0.00647173, 0.02202088, 0.00766472, 0.00447678,\n",
       "         0.02239853], dtype=float32),\n",
       "  array([0.90415794, 0.00949279, 0.02669935, 0.01488585, 0.00596936,\n",
       "         0.03879475], dtype=float32),\n",
       "  array([0.338961  , 0.01288319, 0.01613366, 0.0254864 , 0.00707388,\n",
       "         0.59946185], dtype=float32),\n",
       "  array([0.28539073, 0.01318486, 0.01083303, 0.01143699, 0.00460093,\n",
       "         0.6745534 ], dtype=float32),\n",
       "  array([0.9309194 , 0.00794558, 0.02302375, 0.00885791, 0.00414464,\n",
       "         0.02510873], dtype=float32),\n",
       "  array([0.03809079, 0.02061732, 0.00907317, 0.00828162, 0.00452067,\n",
       "         0.91941637], dtype=float32),\n",
       "  array([0.9314499 , 0.00529231, 0.01423434, 0.00661013, 0.00318941,\n",
       "         0.03922383], dtype=float32),\n",
       "  array([0.27203554, 0.01765935, 0.02282086, 0.5300919 , 0.05536634,\n",
       "         0.10202603], dtype=float32),\n",
       "  array([0.42851657, 0.03711969, 0.4180246 , 0.02326458, 0.05209246,\n",
       "         0.04098211], dtype=float32),\n",
       "  array([0.9351193 , 0.00628257, 0.02089437, 0.00769781, 0.004333  ,\n",
       "         0.02567287], dtype=float32),\n",
       "  array([0.04553469, 0.0213888 , 0.00725654, 0.00694741, 0.00365671,\n",
       "         0.9152159 ], dtype=float32),\n",
       "  array([0.75492644, 0.02289312, 0.15277927, 0.01281175, 0.01794144,\n",
       "         0.03864807], dtype=float32),\n",
       "  array([0.05152356, 0.01422272, 0.00701272, 0.0083242 , 0.00537893,\n",
       "         0.91353786], dtype=float32),\n",
       "  array([0.08834004, 0.01408937, 0.0089529 , 0.00723118, 0.0046715 ,\n",
       "         0.876715  ], dtype=float32),\n",
       "  array([0.08354419, 0.07722143, 0.01630778, 0.00585496, 0.00722078,\n",
       "         0.8098508 ], dtype=float32),\n",
       "  array([0.8479876 , 0.00849652, 0.01862012, 0.01051833, 0.00568764,\n",
       "         0.10868985], dtype=float32),\n",
       "  array([0.03808216, 0.02727752, 0.00858354, 0.00803702, 0.00429502,\n",
       "         0.9137247 ], dtype=float32),\n",
       "  array([0.17809509, 0.01504068, 0.01280504, 0.00851653, 0.00364208,\n",
       "         0.7819006 ], dtype=float32),\n",
       "  array([0.65144145, 0.01509134, 0.06543399, 0.0061367 , 0.0057611 ,\n",
       "         0.25613546], dtype=float32),\n",
       "  array([0.73703176, 0.00774678, 0.01509778, 0.00733505, 0.00483254,\n",
       "         0.22795601], dtype=float32),\n",
       "  array([0.0600218 , 0.02077829, 0.00855503, 0.0109993 , 0.00519903,\n",
       "         0.89444655], dtype=float32),\n",
       "  array([0.03649481, 0.02478097, 0.00884649, 0.00829621, 0.00405662,\n",
       "         0.9175249 ], dtype=float32),\n",
       "  array([0.8888037 , 0.00922151, 0.0282486 , 0.00376243, 0.00418282,\n",
       "         0.06578095], dtype=float32),\n",
       "  array([0.03342116, 0.01961011, 0.00734892, 0.00969336, 0.00554   ,\n",
       "         0.9243865 ], dtype=float32),\n",
       "  array([0.90230364, 0.00673577, 0.01515897, 0.00534577, 0.00335361,\n",
       "         0.06710216], dtype=float32),\n",
       "  array([0.02704282, 0.03312074, 0.00933438, 0.00549121, 0.00450549,\n",
       "         0.9205054 ], dtype=float32),\n",
       "  array([0.48689497, 0.01539574, 0.01974335, 0.12193908, 0.01118917,\n",
       "         0.34483773], dtype=float32),\n",
       "  array([0.61938953, 0.01798274, 0.13197398, 0.00674899, 0.01880865,\n",
       "         0.20509613], dtype=float32),\n",
       "  array([0.81404245, 0.00690202, 0.01316203, 0.00950496, 0.00337981,\n",
       "         0.1530089 ], dtype=float32),\n",
       "  array([0.9373756 , 0.00498038, 0.0141286 , 0.00462074, 0.00251585,\n",
       "         0.03637892], dtype=float32),\n",
       "  array([0.14479269, 0.01570941, 0.01019555, 0.00742491, 0.0041414 ,\n",
       "         0.8177361 ], dtype=float32),\n",
       "  array([0.10363915, 0.02920142, 0.00915263, 0.00747228, 0.00505128,\n",
       "         0.8454833 ], dtype=float32),\n",
       "  array([0.7738243 , 0.0076558 , 0.01434288, 0.00417416, 0.00307826,\n",
       "         0.19692463], dtype=float32),\n",
       "  array([0.4688213 , 0.01564672, 0.06493724, 0.01169217, 0.01135135,\n",
       "         0.42755127], dtype=float32),\n",
       "  array([0.62698334, 0.00899481, 0.01638222, 0.00612375, 0.00387397,\n",
       "         0.33764195], dtype=float32),\n",
       "  array([0.39109355, 0.01009701, 0.01504161, 0.01133023, 0.00565648,\n",
       "         0.56678104], dtype=float32),\n",
       "  array([0.04174672, 0.01953183, 0.00652315, 0.00689083, 0.00359627,\n",
       "         0.9217112 ], dtype=float32),\n",
       "  array([0.15406637, 0.04335617, 0.05685557, 0.0122481 , 0.00910207,\n",
       "         0.72437173], dtype=float32),\n",
       "  array([0.08120907, 0.02835364, 0.01128623, 0.00694077, 0.00367605,\n",
       "         0.86853427], dtype=float32),\n",
       "  array([0.1355909 , 0.2773954 , 0.4393413 , 0.0116418 , 0.01953098,\n",
       "         0.11649968], dtype=float32),\n",
       "  array([0.07336213, 0.1428704 , 0.03869321, 0.03233689, 0.02489843,\n",
       "         0.687839  ], dtype=float32),\n",
       "  array([0.13407761, 0.01791197, 0.01070137, 0.02335377, 0.00591504,\n",
       "         0.8080402 ], dtype=float32),\n",
       "  array([0.67808616, 0.02583782, 0.13463181, 0.00770008, 0.00803542,\n",
       "         0.14570872], dtype=float32),\n",
       "  array([0.90462935, 0.00630155, 0.02243332, 0.00485815, 0.00268149,\n",
       "         0.0590961 ], dtype=float32),\n",
       "  array([0.69219756, 0.05250473, 0.04958337, 0.00723959, 0.0046358 ,\n",
       "         0.19383894], dtype=float32),\n",
       "  array([0.4965729 , 0.01514769, 0.01950055, 0.00689081, 0.00346737,\n",
       "         0.45842072], dtype=float32),\n",
       "  array([0.11724899, 0.02001436, 0.01242416, 0.00722095, 0.00455311,\n",
       "         0.83853847], dtype=float32),\n",
       "  array([0.68963903, 0.00902152, 0.01412514, 0.00961593, 0.0048298 ,\n",
       "         0.27276847], dtype=float32),\n",
       "  array([0.08468898, 0.02745968, 0.01316348, 0.01015322, 0.0085142 ,\n",
       "         0.8560204 ], dtype=float32),\n",
       "  array([0.02799356, 0.04823703, 0.00939095, 0.00615613, 0.0058178 ,\n",
       "         0.9024045 ], dtype=float32),\n",
       "  array([0.02584073, 0.03614134, 0.00837925, 0.00530633, 0.00384728,\n",
       "         0.9204851 ], dtype=float32),\n",
       "  array([0.02377486, 0.0811253 , 0.01222527, 0.00541665, 0.0057328 ,\n",
       "         0.8717251 ], dtype=float32),\n",
       "  array([0.14583862, 0.101633  , 0.5974512 , 0.02860256, 0.05444408,\n",
       "         0.0720305 ], dtype=float32),\n",
       "  array([0.06325939, 0.0227572 , 0.01368241, 0.59779096, 0.02493377,\n",
       "         0.27757624], dtype=float32),\n",
       "  array([0.03910277, 0.04076386, 0.01776923, 0.49657395, 0.05753818,\n",
       "         0.34825197], dtype=float32),\n",
       "  array([0.0295815 , 0.02352125, 0.00836487, 0.03803474, 0.00695997,\n",
       "         0.8935377 ], dtype=float32),\n",
       "  array([0.04221148, 0.02202215, 0.00812137, 0.03546774, 0.00624292,\n",
       "         0.8859344 ], dtype=float32),\n",
       "  array([0.032426  , 0.03903228, 0.01184836, 0.07711217, 0.01107028,\n",
       "         0.8285109 ], dtype=float32),\n",
       "  array([0.09317553, 0.01426927, 0.01000299, 0.03959838, 0.01503331,\n",
       "         0.8279205 ], dtype=float32),\n",
       "  array([0.02210959, 0.06203229, 0.01717056, 0.00902002, 0.00466072,\n",
       "         0.88500684], dtype=float32),\n",
       "  array([0.05261843, 0.02835756, 0.01143161, 0.25400072, 0.02090796,\n",
       "         0.6326837 ], dtype=float32),\n",
       "  array([0.04380695, 0.01687997, 0.00785444, 0.03013996, 0.00672855,\n",
       "         0.8945902 ], dtype=float32),\n",
       "  array([0.04525772, 0.02742613, 0.00981251, 0.08486927, 0.00867079,\n",
       "         0.8239635 ], dtype=float32),\n",
       "  array([0.03744394, 0.0163791 , 0.0125911 , 0.82377565, 0.02757181,\n",
       "         0.08223845], dtype=float32),\n",
       "  array([0.08514543, 0.02101873, 0.01088539, 0.09887884, 0.01048514,\n",
       "         0.7735865 ], dtype=float32),\n",
       "  array([0.02704762, 0.0244685 , 0.00691314, 0.0173525 , 0.00475119,\n",
       "         0.9194671 ], dtype=float32),\n",
       "  array([0.03679483, 0.03216568, 0.01240643, 0.00688491, 0.00476079,\n",
       "         0.90698737], dtype=float32),\n",
       "  array([0.0530331 , 0.03755757, 0.01302486, 0.01022193, 0.00386733,\n",
       "         0.88229525], dtype=float32),\n",
       "  array([0.09994525, 0.14219354, 0.09884757, 0.00945537, 0.01559926,\n",
       "         0.63395905], dtype=float32),\n",
       "  array([0.02690025, 0.01536352, 0.01573635, 0.8460391 , 0.04243991,\n",
       "         0.05352094], dtype=float32),\n",
       "  array([0.03726187, 0.01852374, 0.00722277, 0.01296241, 0.00484472,\n",
       "         0.91918445], dtype=float32),\n",
       "  array([0.04016682, 0.04204984, 0.01137127, 0.00582863, 0.00411605,\n",
       "         0.8964673 ], dtype=float32),\n",
       "  array([0.15418644, 0.01926039, 0.01054724, 0.04078351, 0.01179939,\n",
       "         0.763423  ], dtype=float32),\n",
       "  array([0.27267325, 0.01787781, 0.02288725, 0.01071546, 0.00541628,\n",
       "         0.6704299 ], dtype=float32),\n",
       "  array([0.0347655 , 0.02216739, 0.00856165, 0.00755159, 0.00478155,\n",
       "         0.92217237], dtype=float32),\n",
       "  array([0.12813316, 0.01465105, 0.01935224, 0.76374274, 0.0453434 ,\n",
       "         0.02877736], dtype=float32),\n",
       "  array([0.8212091 , 0.01106238, 0.11139198, 0.01356894, 0.01722718,\n",
       "         0.02554045], dtype=float32),\n",
       "  array([0.45805869, 0.04324948, 0.39067197, 0.0149083 , 0.02922482,\n",
       "         0.06388672], dtype=float32),\n",
       "  array([0.19417915, 0.01979031, 0.01681505, 0.6546487 , 0.02688045,\n",
       "         0.0876863 ], dtype=float32),\n",
       "  array([0.82130945, 0.02005716, 0.09956067, 0.00574404, 0.00799675,\n",
       "         0.04533194], dtype=float32),\n",
       "  array([0.5995773 , 0.01797516, 0.05572158, 0.0972966 , 0.1629033 ,\n",
       "         0.06652611], dtype=float32),\n",
       "  array([0.10823299, 0.10761201, 0.05842784, 0.00689845, 0.00575286,\n",
       "         0.7130759 ], dtype=float32),\n",
       "  array([0.09410982, 0.04111452, 0.01430406, 0.08494668, 0.01332777,\n",
       "         0.75219715], dtype=float32),\n",
       "  array([0.13519911, 0.01848988, 0.04422273, 0.4674452 , 0.24757014,\n",
       "         0.08707297], dtype=float32),\n",
       "  array([0.8310183 , 0.00697966, 0.01205383, 0.00953895, 0.00362206,\n",
       "         0.13678722], dtype=float32),\n",
       "  array([0.05837478, 0.05967804, 0.69875056, 0.01967106, 0.09055444,\n",
       "         0.07297112], dtype=float32)],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  0,\n",
       "  2],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inteventions_labels_model.evaluate_model(test_interventions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
